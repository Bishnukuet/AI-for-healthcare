{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f5efb70",
   "metadata": {},
   "source": [
    "# Graph Neural Networks\n",
    "\n",
    "---\n",
    "**Lernziele**\n",
    "* Sie verstehen, wie Moleküle für den Computer als Graph dargestellt werden können. \n",
    "* Sie verstehen, wie Graph Neural Networks funktionieren.\n",
    "* Sie können ein Graph Neural Network als Pytorch Klasse schreiben.\n",
    "---\n",
    "\n",
    "Graph Neural Networks sind noch eine relativ neue Methode. Intuitiv können wir sehen, dass sich Moleküle sehr gut als (mathematischen) Graph darstellen lassen. Dabei entsprechen die Bindungen im Molekül den Kanten (edges) des Graph und die Atome  den Knoten (nodes).<br>Für den Computer sind jedoch Graphen nicht so leicht zu lesen wie zum Beispiel ein SMILES string. Wir stellen die Moleküle als zwei Matrizen dar. Zum einen die Adjacency-Matrix, die die Atomverknüpfung (also die Bindungen) darstellt. Dazu kommen dann noch die Feature Matrix. Für das Machine Learning One-Hot encoden wir hier die Atome.<br><br>\n",
    "<center>\n",
    "<img src=\"https://www.researchgate.net/profile/Jorge_Galvez2/publication/236018587/figure/fig1/AS:299800013623305@1448489301609/The-chemical-graph-and-adjacency-matrix-of-the-isopentane.png\" style=\"width: 600px;\">\n",
    "</center>\n",
    "<h8><center>Galvez et. al. 2010</center></h8><br><br>\n",
    "Wir nehmen nochmal die Daten aus der Tox21 Challenge. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdc9870f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.rdmolops import GetAdjacencyMatrix\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils import data\n",
    "import math\n",
    "from sklearn.metrics import roc_auc_score\n",
    "%run ../utils/onehotencoder.py\n",
    "np.set_printoptions(linewidth=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2024983d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OC(=O)[C@H](O)[C@@H](O)[C@H](O)C(=O)CO</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C[C@]12CC[C@H]3[C@@H](CCc4cc(O)ccc43)[C@@H]1CC...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CC(C)(C)c1cc(O)ccc1O</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CN(C)c1ccc(cc1)C(c1ccccc1)=C1C=CC(C=C1)=[N+](C)C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NC(Cc1ccccc1)C(O)=O</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              smiles  activity\n",
       "0             OC(=O)[C@H](O)[C@@H](O)[C@H](O)C(=O)CO         0\n",
       "1  C[C@]12CC[C@H]3[C@@H](CCc4cc(O)ccc43)[C@@H]1CC...         1\n",
       "2                               CC(C)(C)c1cc(O)ccc1O         1\n",
       "3   CN(C)c1ccc(cc1)C(c1ccccc1)=C1C=CC(C=C1)=[N+](C)C         1\n",
       "4                                NC(Cc1ccccc1)C(O)=O         0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Laden der Daten\n",
    "data_tox = pd.read_csv(\"../data/toxicity/sr-mmp.tab\", sep = \"\\t\")\n",
    "data_tox = data_tox.iloc[:,1:] #alle Spalten bis auf die erste (index 0) werden ausgewählt\n",
    "data_tox.columns = [\"smiles\", \"activity\"]\n",
    "data_tox.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1321a720",
   "metadata": {},
   "source": [
    "## Adjacency Matrix und One-Hot Encoded Feature Matrix\n",
    "Mit den Smiles können wir jetzt leider noch nicht so viel anfangen. Aber zum Glück gibt es in RDKit direkt eine Funktion, um die Adjacency Matrix zu erstellen. Diese haben wir oben schon importiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "120a224f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "mols = [Chem.MolFromSmiles(x) for x in data_tox['smiles']]\n",
    "A = [GetAdjacencyMatrix(x) for x in mols]\n",
    "print(A[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c0e03f",
   "metadata": {},
   "source": [
    "Um die Atome zu One-Hot Encoden benutzen wir die vorgeschriebene `onehotencode()` Funktion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e9fb9b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat = onehotencode(mols)\n",
    "feat[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2fd903",
   "metadata": {},
   "source": [
    "Vielleicht ist ihnen aufgefallen, dass auf der Diagonalen der Adjacency Matrix noch Nullen stehen. In einer Graph Convolution sollen aber nicht nur die Features der benachbarten, sondern auch des zentralen Atoms mit in die Rechnung genommen werden. Dafür werden Einsen auf der Diagonalen der Adjacency-Matrix benötigt. \n",
    "Die Funktion `np.fill_diagonal(matrix, value)` erlaubt es Ihnen die Werte der Diagonalen einer Matrix zu ändern. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c81e5e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 1]]\n"
     ]
    }
   ],
   "source": [
    "for matrix in A:\n",
    "    np.fill_diagonal(matrix, 1)\n",
    "print(A[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362ff2ee",
   "metadata": {},
   "source": [
    "## Graph Convolution\n",
    "Jetzt wollen wir die Informationen der Knoten an die Nachbarknoten entlang der Kanten weiterzugeben, was als (Graph) Convolution bezeichnet wird. Hierfür werden während des forward pass diese Mathematischen Operationen des ausgeführ: $$\\hat{X} = \\hat{D}^{-1}\\hat{A}XW$$\n",
    "Hier ist $\\hat{A}$ unsere Adjacency Matrix mit Einsen auf der Diagonalen. $X$ ist die Feature-Matrix und $W$ sind die Weights, die pytorch initialisiert. Es fehlt noch $D$, die Degree Matrix. Diese Matrix enthält die Anzahl der Verbindungen, die jedes Atom im Molekül hat. Diese Werte werden in der Degree-Matrix auf der Diagonalen platziert. Die Anzahl der Verbindung jedes Moleküls lässt sich leicht aus der Adjacency-Matrix berechnen. Dafür müssen Sie die Summe der Reihe oder Spalten der$\\hat{A}$ Matrix berechnen. Diese Summe gibt die Degrees eines Atom an. Um genau zu sein, ist es der Degree + 1 des Atoms, da Sie die Diagonale der Adjacency-Matrix bereits mit Einsen gefüllt haben.\n",
    "Um die Degree-Matrix zu erstellen, müssen Sie die Summen der Reihen in jeder Adjacency-Matrix berechnen und dieses auf die Diagonale einer neuen Matrix platzieren.\n",
    "\n",
    "\n",
    "Dieser Prozess ist relativ simpel mit `numpy`. `np.sum(A[i], axis=0)` berechnet die Summe pro Spalte und `np.diag()` erstellt aus einem 1D-Array eine Matrix mit den Werten des 1D Arrays auf der Diagonalen. Sie können die beiden Funktion in Kombination benutzen, um die Degree-Matrizen zu erstellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c61bef88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3]]\n"
     ]
    }
   ],
   "source": [
    "D =[]\n",
    "for matrix in A:\n",
    "    D.append(np.diag(np.sum(matrix, axis=1)))\n",
    "print(D[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb2560b",
   "metadata": {},
   "source": [
    "Bevor wir anfangen ein Netzwerk zu bauen und es mit unseren Daten zu füttern, können wir noch einen Schritt durchführen um einiges an Rechenaufwand zu sparen, denn $\\hat{D}^{-1}\\hat{A}$ kann schon vor dem Trainieren des Netzwerk berechnet werden. Dadurch kann Zeit gespart werden, da dieser Schritt nicht ständig im Netzwerk wiederholt werden muss.\n",
    "\n",
    "`np.linalg.matrix_power` wird benötigt, um das Invers der Matrix `D` zu berechnen. Ansonsten ist dieser Schritt eine einfache Matrixmultiplikation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0159329",
   "metadata": {},
   "outputs": [],
   "source": [
    "DA = []\n",
    "for i in range(len(D)):\n",
    "    DA.append(np.matmul(np.linalg.matrix_power(D[i], -1),A[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "040c982e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DA = [torch.tensor(x,dtype=torch.float32) for x in DA] # Konvertieren der Arrays zu Tensoren\n",
    "feat = [torch.tensor(x,dtype=torch.float32) for x in feat] # Konvertieren der Arrays zu Tensoren\n",
    "labels = [torch.tensor([x], dtype=torch.float32) for x in data_tox['activity']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bd3802",
   "metadata": {},
   "source": [
    "## Graph Convolution Layer\n",
    "Wir wollen uns für die Graph Convolution die Sturktur von PyTorch zunutze machen. Wie schon letzte Woche verwenden wir dafür Klassen. Unser Ziel ist es, so etwas wie nn.Linear() zu programmieren, sodass wir unser Repertoire an Hidden Layers (Linear, RNN, GRU, Dropout, ...) um eine Graph Convolution Layer erweitern.<br>Auch dafür können wir die nn.Module Klasse als Basis für unsere GraphConvolution verwenden. Wir fangen mit dem minimalen Grundgerüst an:\n",
    "```python\n",
    "class GraphConvolution(nn.Module):\n",
    "    pass\n",
    "```\n",
    "Damit wir richtig auf die Funktionen der übergeordneten nn.Module Klasse zugreifen können müssen wir diese mit `super().__init__()` initialisieren. Unsere Convolutional Layer muss natürlich wissen, wie groß der input ist, und wie groß der output werden soll. Außerdem müssen wir hier selbst die Weights und Biases initialiseren.\n",
    "```python\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.in_featuers = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(in_features, out_features))\n",
    "        self.bias = nn.Parameter(torch.FloatTensor(out_features))\n",
    "```\n",
    "Dann können wir auch schon die forward() Funktion programmieren. Hier passiert die eigentliche convolution, bei der die Knoten mit den Features `x` durch Matrixmultiplikation mit der Adjacency Matrix `adj` über ihre Nachbarknoten lernen. Indem wir noch die lernbaren `weights` dazwischenschalten, können wir das ganze später optimieren.\n",
    "```python\n",
    "    def forward(self, x, adj):\n",
    "        support = torch.mm(x, self.weight)\n",
    "        output = torch.mm(adj, support)\n",
    "        return output + self.bias\n",
    "```\n",
    "Damit würde unsere GraphConvolution Klasse auch schon funktionieren. Wir initialisieren die weights aber noch etwas optimiert mit der Funktion `reset_parameters()`. Und mit der Funktion `__repr__()` können wir uns die Layer noch richtig anzeigen lassen. Unsere finale Klasse sieht dann so aus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34e85d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphConvolution(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(in_features, out_features))\n",
    "        self.bias = nn.Parameter(torch.FloatTensor(out_features))\n",
    "        self.reset_parameters()\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.weight.size(1))\n",
    "        self.weight.data.uniform_(0, stdv)\n",
    "        self.bias.data.uniform_(-stdv, stdv)\n",
    "        \n",
    "    def forward(self, x, adj):\n",
    "        support = torch.mm(x, self.weight)\n",
    "        output = torch.mm(adj, support)\n",
    "        return output + self.bias\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + ' (' \\\n",
    "               + 'in_features=' + str(self.in_features) + ', ' \\\n",
    "               + 'out_features=' + str(self.out_features) + ')'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8d289f",
   "metadata": {},
   "source": [
    "Wir können eine einzelne Graph Convolution Layer auch schon verwenden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc2d1fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: torch.Size([29, 25])\n",
      "DA: torch.Size([29, 29])\n",
      "\n",
      "Output: torch.Size([29, 100])\n"
     ]
    }
   ],
   "source": [
    "feat_beispiel = feat[1]\n",
    "adj_beispiel = DA[1]\n",
    "print('Features:', feat_beispiel.shape)\n",
    "print('DA:', adj_beispiel.shape)\n",
    "\n",
    "conv = GraphConvolution(feat[1].shape[1], 100)\n",
    "output = conv(feat_beispiel, adj_beispiel)\n",
    "print('\\nOutput:', output.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9417a666",
   "metadata": {},
   "source": [
    "## Graph Neural Network\n",
    "Um jetzt ein Netz zu bauen, können wir wieder die nn.Module Basisklasse verwenden. \n",
    "\n",
    "# Hier\n",
    "# noch \n",
    "# Text \n",
    "# und\n",
    "# Erklärungen\n",
    "hardcoded hidden layer shapes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63ed67d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphNN(nn.Module):\n",
    "    def __init__(self):#in_features, out_features, size_labels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GraphConvolution(25, 100)\n",
    "        self.conv2 = GraphConvolution(100, 100)\n",
    "        self.lin = nn.Linear(100, 1)\n",
    "        # self.lin2 (and add relu if forward)\n",
    "        \n",
    "    def aggregate(self, convoluted_graph): # we use mean aggregation, max or min could also be used as hyperparameter\n",
    "        return torch.mean(convoluted_graph, dim=0)\n",
    "        \n",
    "    def forward(self, x, adj):\n",
    "        x = self.conv1(x, adj)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, adj)\n",
    "        x = F.relu(x)\n",
    "        x = self.aggregate(x)\n",
    "        x = self.lin(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e5a6c7",
   "metadata": {},
   "source": [
    "## Training und Evaluation\n",
    "\n",
    "# Testset\n",
    "# Fehlt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3b44562",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn = GraphNN()\n",
    "loss_funktion= nn.BCEWithLogitsLoss()\n",
    "optimizer=optim.Adam(gnn.parameters(), lr =0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90700c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2246\n",
      "2246\n",
      "2246\n"
     ]
    }
   ],
   "source": [
    "print(len(feat))\n",
    "print(len(DA))\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a75bda0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Test Loss: 0.67 Test Accuracy: 0.58\n",
      "1 Test Loss: 0.64 Test Accuracy: 0.63\n",
      "2 Test Loss: 0.63 Test Accuracy: 0.64\n",
      "3 Test Loss: 0.62 Test Accuracy: 0.66\n",
      "4 Test Loss: 0.62 Test Accuracy: 0.67\n",
      "5 Test Loss: 0.61 Test Accuracy: 0.68\n",
      "6 Test Loss: 0.61 Test Accuracy: 0.68\n",
      "7 Test Loss: 0.61 Test Accuracy: 0.68\n",
      "8 Test Loss: 0.60 Test Accuracy: 0.68\n",
      "9 Test Loss: 0.60 Test Accuracy: 0.68\n",
      "10 Test Loss: 0.60 Test Accuracy: 0.68\n",
      "11 Test Loss: 0.60 Test Accuracy: 0.68\n",
      "12 Test Loss: 0.60 Test Accuracy: 0.69\n",
      "13 Test Loss: 0.60 Test Accuracy: 0.69\n",
      "14 Test Loss: 0.60 Test Accuracy: 0.69\n",
      "15 Test Loss: 0.60 Test Accuracy: 0.69\n",
      "16 Test Loss: 0.59 Test Accuracy: 0.69\n",
      "17 Test Loss: 0.59 Test Accuracy: 0.69\n",
      "18 Test Loss: 0.59 Test Accuracy: 0.70\n",
      "19 Test Loss: 0.59 Test Accuracy: 0.70\n",
      "20 Test Loss: 0.59 Test Accuracy: 0.70\n",
      "21 Test Loss: 0.59 Test Accuracy: 0.70\n",
      "22 Test Loss: 0.59 Test Accuracy: 0.70\n",
      "23 Test Loss: 0.59 Test Accuracy: 0.70\n",
      "24 Test Loss: 0.58 Test Accuracy: 0.70\n",
      "25 Test Loss: 0.58 Test Accuracy: 0.70\n",
      "26 Test Loss: 0.58 Test Accuracy: 0.70\n",
      "27 Test Loss: 0.58 Test Accuracy: 0.70\n",
      "28 Test Loss: 0.58 Test Accuracy: 0.70\n",
      "29 Test Loss: 0.58 Test Accuracy: 0.70\n",
      "30 Test Loss: 0.58 Test Accuracy: 0.70\n",
      "31 Test Loss: 0.58 Test Accuracy: 0.70\n",
      "32 Test Loss: 0.57 Test Accuracy: 0.70\n",
      "33 Test Loss: 0.57 Test Accuracy: 0.71\n",
      "34 Test Loss: 0.57 Test Accuracy: 0.71\n",
      "35 Test Loss: 0.57 Test Accuracy: 0.71\n",
      "36 Test Loss: 0.57 Test Accuracy: 0.71\n",
      "37 Test Loss: 0.57 Test Accuracy: 0.71\n",
      "38 Test Loss: 0.57 Test Accuracy: 0.71\n",
      "39 Test Loss: 0.57 Test Accuracy: 0.71\n",
      "40 Test Loss: 0.57 Test Accuracy: 0.71\n",
      "41 Test Loss: 0.57 Test Accuracy: 0.71\n",
      "42 Test Loss: 0.56 Test Accuracy: 0.71\n",
      "43 Test Loss: 0.56 Test Accuracy: 0.71\n",
      "44 Test Loss: 0.56 Test Accuracy: 0.71\n",
      "45 Test Loss: 0.56 Test Accuracy: 0.71\n",
      "46 Test Loss: 0.56 Test Accuracy: 0.71\n",
      "47 Test Loss: 0.56 Test Accuracy: 0.71\n",
      "48 Test Loss: 0.56 Test Accuracy: 0.71\n",
      "49 Test Loss: 0.56 Test Accuracy: 0.71\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "\n",
    "for i in range(EPOCHS):\n",
    "    loss_list = []\n",
    "    acc_list= []\n",
    "    for k in range(len(feat)):\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        output=gnn(feat[k], DA[k])\n",
    "\n",
    "        loss=loss_funktion(output,labels[k])\n",
    "        loss.backward()\n",
    "        loss_list.append(loss.item())\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Evaluierung nach dem EPOCH an Hand des Testsets\n",
    "    #acc_list= []\n",
    "    #for k in range(len(feat)):\n",
    "        #output=gnn(feat[k], DA[k])#\n",
    "        acc_list.append(np.sum((torch.round(torch.sigmoid(output)) == labels[k]).detach().numpy()))\n",
    "        \n",
    "        \n",
    "    print(i,\"Test Loss: %.2f Test Accuracy: %.2f\"\n",
    "        % (np.mean(loss_list), np.sum(acc_list)/(len(feat))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d732ba",
   "metadata": {},
   "source": [
    "PyG hat schon Convolutional, Pooling etc Layers und Batching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe796496",
   "metadata": {},
   "source": [
    "## Übungsaufgabe: ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23046cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
