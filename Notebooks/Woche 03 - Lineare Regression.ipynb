{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28aa56c8",
   "metadata": {},
   "source": [
    "# Einführung Statistik\n",
    "\n",
    "Wir werden heuten ein paar wenige Grundlagen zur Statistik anschauen.\n",
    "Die Statistik woll uns helfen Daten einfach zu beschrieben und erklären. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "30ff49e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%matplotlib inline\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e402ffe7",
   "metadata": {},
   "source": [
    "Wir können uns zum Beispiel die Abi Noten einer bestimmten Klasse anschauen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1b2a350",
   "metadata": {},
   "outputs": [],
   "source": [
    "abi_klasse = [1.64, 2.35, 1.88, 2.48, 2.16, 3.92, 2.16, 2.  , 1.76, 2.82, 1.81,\n",
    "       2.59, 3.03, 1.7 , 2.87, 3.21, 2.65, 1.97, 1.2, 1.67, 1.77, 1.98,\n",
    "       3.4 , 1.31, 1.72, 2.05, 1.12 , 1.56, 2.01, 2.1 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf298879",
   "metadata": {},
   "source": [
    "Allerdings ist es sehr schwer nur über die Daten eine Übersicht zubekommen.\n",
    "Einfach ist es sich die Noten aufzuzeichnen.\n",
    "<img src='Img/intro_stats/noten_1.png'></img>\n",
    "\n",
    "Obwohl Sie jetzt eine bessere gesamt Übersicht haben, könnte es ihnen schwer fallen zwei Klassen miteinander zu vergleichen.\n",
    "<img src='Img/intro_stats/noten_2.png'></img>\n",
    "\n",
    "Oft reicht eine rein visuelle Inspektion nicht um eindeutige Entscheidungen zu treffen.\n",
    "Hierfür werden Metriken benögt, die die Verteilung von Datenpunkten, wie die Abinoten, beschreiben.\n",
    "\n",
    "Am wohlbekanntesten ist der Mittelwert, genauer gesagt das arithmetisches Mittel. Es beschreibt den Durchschnitt einer Verteilung von Datenpunkten. \n",
    "Und das arithmetische Mittel zu berechnen wird die Summe aller Werte durch die Anzahl der Werte geteilt.\n",
    "\n",
    "\n",
    "$$\\bar{x} = \\frac{1}{n}\\sum_{i=1}^n x_i$$\n",
    "\n",
    "Der mittelwert wird oft durch $\\bar{x}$ beschrieben.\n",
    "Berechnen Sie das arithmetische Mittel in Python für die Abiklasse aus. *Ohne dabei Numpy zu benutzen*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "babafe84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2486535905.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_160668/2486535905.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    mean_abiklasse = # Formel für den Mittelwert\u001b[0m\n\u001b[0m                                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "mean_abiklasse = _____________# Formel für den Mittelwert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f37e5b",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Lösung:</b></summary>\n",
    "    \n",
    "```python \n",
    "mean_abiklasse = sum(abi_klasse)/len(abi_klasse)\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc7cc52",
   "metadata": {},
   "source": [
    "Doch der Mittelwert reicht nicht um eine Verteilung von Werten adequate zu beschrieben. Zum Beispiel, haben die beiden [Normal Verteilungen](https://de.statista.com/statistik/lexikon/definition/95/normalverteilung/) im Beispiel den gleichen Mittelwert und trotzdem sind Sie nicht identisch Verteilt. \n",
    "<img src='Img/intro_stats/noten_3.png'></img>\n",
    "\n",
    "Wir können sehen, dass die orangene Verteilung viel schmaller ist als die blaue. Das heißt die Werte der orangenen Gruppe liegen näher an ihrem Durchschnitt als bei der blauen Gruppe.\n",
    "Die breite einer Verteilung wird durch die Varianz gemessen. Die Varianz misst den durchschnittlichen Abstand der Werte zu ihrem Mittelwert. \n",
    "\n",
    "Die Varianze ($s^2$) wird wie folgt berechnet:\n",
    "\n",
    "$$s^2 = \\frac{1}{n}\\sum_{i=1}^n(x_i-\\bar{x})^2$$\n",
    "\n",
    "Beachtet das nicht die Different ($x_i-\\bar{x}$) sondern das Quadrat ($x_i -\\bar{x})^2$ der Differnenz summiert wird. Somit haben größere Abstände einen größeren Einfluß auf die Varianz. \n",
    "\n",
    "Berechnet die Varianz der `abi_klasse`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71817d5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42147433333333323"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varianz_abiklasse = ________________ /(len(abi_klasse)# Ihr braucht wahrscheinlich einen for-loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277014b6",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Lösung:</b></summary>\n",
    "    \n",
    "```python\n",
    "sum([(x - mean_abiklasse)**2 for x in abi_klasse])/(len(abi_klasse))\n",
    "```\n",
    "</details>    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e076b435",
   "metadata": {},
   "source": [
    "\n",
    "<details>\n",
    "    <summary><b>Lösung: for-loop ausgeschrieben</b></summary>\n",
    "```python\n",
    "quadrate = 0\n",
    "for x in abi_klasse:\n",
    "    quadrate = quadrate +((x-mean_abiklasse)**2)\n",
    "varianz_abiklasse = quadrate/len(abi_klasse) \n",
    "```\n",
    "</details>   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23f3b1a",
   "metadata": {},
   "source": [
    "Oft wird auch die Standard Abweichung als Maß für die *Breite* eine Verteilung benutzt. Die Standard Abweichung erhält man durch das nehmen der Wurzel der Varianz. Damit wird das Maß der Varianz auf die Skala der ursprünglichen Verteilung gebracht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f0084b",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_abiklasse = __________ #Berechnen Sie die Standardabweichung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e619ea1",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Lösung:</b></summary>\n",
    "    \n",
    "```python\n",
    "std_abiklasse= varianz_abiklasse**(0.5)\n",
    "```\n",
    "</details>    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267f998a",
   "metadata": {},
   "source": [
    "Natürlich gibt es alle Funktionen auch schon in numpy: `np.mean()`,`np.std()`,`np.var()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "033a21bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mittelwert:  2.1629999999999994\n",
      "Varianz:  0.4214743333333333\n",
      "Standard Abweichung:  0.6492105462277499\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(\"Mittelwert: \", np.mean(abi_klasse))\n",
    "print(\"Varianz: \", np.var(abi_klasse))\n",
    "print(\"Standard Abweichung: \", np.std(abi_klasse))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5670c0d7",
   "metadata": {},
   "source": [
    "Mit dem Maß der Varianz/Standard und dem Mittelwert können wir schon einige Verteilung beschreiben. Natürlich nicht alle, z.B. z.B. bei multimodalen Verteilungen bräuchte man noch mehr Informationen. \n",
    "\n",
    "<img src='Img/intro_stats/noten_4.png'></img>\n",
    "\n",
    "\n",
    "Allerdings wollen wir nicht immer nur Daten beschreiben sondern wir wollen auch Informationen von diesen Daten gewinnen. \n",
    "Mit hilfe der Korrelation können wir zum Beispiel den Zusammenhang von Körergröße zu Gewicht beschrieben. Je größere ein Mensch ist desto schwerer ist er. Dieses Model ist natürlich nicht perfekt, das Körpergewicht ist ntürlich nicht vur von der Körpergröße abhängig. Es gibt große leichte Menschen und kleine schwerere. Aber es gibt eine zu Grunde liegende Tendenz. \n",
    "\n",
    "<table><tr>\n",
    "<td> <img src='Img/intro_stats/gewichtvsgröße.png' alt=\"Drawing\" style=\"width: 250px;\"/> </td>\n",
    "<td> <img src='Img/intro_stats/gewichtvsgröße2.png' alt=\"Drawing\" style=\"width: 250px;\"/> </td>\n",
    "</tr></table>\n",
    "\n",
    "Wir können die Beziehung mit einer linearen Regression beschreiben.\n",
    "Sie kennen vielleicht noch aus der Schule die geraden Glecihung $y = mx+t$ (oder $y = ax+b$). \n",
    "<br>\n",
    "\n",
    "\n",
    "\n",
    "- $x$ ist die Input Variable, in unserem Falle die Körpergröße\n",
    "- $y$ ist die zu vorher sagende Variable (Körpergewicht)\n",
    "- $m$ beschreibt die Steigung der Geraden\n",
    "- $t$ gibt den y-Achsen Abschnitt an, der Wert von $y$ wenn $x=0$\n",
    "\n",
    "<img src='Img/intro_stats/reg1.png' alt=\"Drawing\" width=\"500\"/>\n",
    "\n",
    "Angenommen die Gleichung der Regressiongeraden wäre $y=0.3x+21$ dann wäre zum Beispield as Gewicht einer Person mit einer Größe von 180cm, 75kg ($0.3\\cdot180+21)$.\n",
    "\n",
    "Natürlich wiegt nicht jede 180cm große Person 66 kg. Das ist nur der vorhergesagte Wert unsere Regressionsgleichung. Um das eindeutig zu kennzeichnen, schreiben wir $\\hat{y}$ anstatt $y$.\n",
    "Dadurch wird die Geradegleichung zu $hat{y}=mx+t$. \n",
    "\n",
    "---\n",
    "\n",
    "Schreiben Sie eine Funktion, die das Gewicht an Hand der oben beschriebenen Geradengleichung berechnet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "f34082ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg(x,m,t):\n",
    "    _________# Was soll diese Funktion ausgeben?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8dc8f11",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Lösung:</b></summary>\n",
    "    \n",
    "```python\n",
    "def reg(größe):\n",
    "    return m*x+t\n",
    "```\n",
    "</details>    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8282754",
   "metadata": {},
   "source": [
    "Die Variable `x` enthält die Größen in cm von 5 Personen. Für diese fünf Personen brechnen Sie das Gewicht mit Hilfe der Funktion `gewicht_reg`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7a90fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [182,167,198,132,178]\n",
    "y_hat = [reg(__,__,__) for ___ in _____ ]\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40ce95a",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Lösung:</b></summary>\n",
    "    \n",
    "```python\n",
    "y_hat = [gewicht_reg(gewicht) for gewicht in x ]\n",
    "```\n",
    "</details>    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a19876",
   "metadata": {},
   "source": [
    "Die Werte sind natürlich nur eine Schätzung des Gewichtes, und weichen von dem tatsächlichen Gewicht der Person ab. Um zu beurteilen wie gut unsere Model das Gewicht bestimmen kann, brauchen wir auch das tatsächliche gemessene Gewicht der Personen. Diese sind in `y` gegeben. Wir können zum Beispiel die Differenz von `y_hat` und `y` berechnen. Dafür müssenw ir aber erst einmal die Listen zu `numpy` arrays konvertieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d11797e4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '____' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_66709/2092107416.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m78.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m68.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m81.0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m70.1\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_hat\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0m____\u001b[0m \u001b[0;31m# was ziehen wir von y_hat ab?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name '____' is not defined"
     ]
    }
   ],
   "source": [
    "y = np.array([78.2,68.3, 81.0,64.3, 70.1 ])\n",
    "y_hat = np.array(y_hat)\n",
    "residual = y - y_hat # was ziehen wir von y ab?\n",
    "residual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb42e18",
   "metadata": {},
   "source": [
    "Diese Differenz zwischen dem tatsächlichen und dem vorhergesagten Wert($y - \\hat{y}$) wird auch als Residuum bezeichnet. Als Symbol für das Residuum wird meisten das kleine Epsilion ($\\epsilon$) verwendet, hiermit wird die Größe des Fehlers (**E**rror) der Vorhersage gemessen. \n",
    "\n",
    "<img src='Img/intro_stats/reg_2.png' alt=\"Drawing\" width=\"500\"/>\n",
    "\n",
    "Um Einschätzen zu können wie gut unsere Model insgesamt ist können wir zum Beispiel die Residuen einfach summieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7939582d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.20000000000000995"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(residual)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9642580f",
   "metadata": {},
   "source": [
    "Wie Sie sehen ist der Wert sehr nahe bei Null. Eigentlich ein sehr gerinnger Fehler. Das Problem ist aber, dass Residuen sowohl positve als auch negativ sein können. Das heißt beim summieren gleichen Sie sich aus, und man wird immer Werte in der Nähe von Null erhalten. Um das zu umgehen summieren deswegen nicht die Residuen sonder, wie bei der Varianz, die Quadrate der Residuen. $\\sum_{i=1}^{n}(y_i-\\hat{y}_i)^2$. \n",
    "\n",
    "Die Summe alleine, würde aber dazu führen das Modelle die mehr Datenpunkte haben, also ein größeres $n$, automatische größere Summen haben werden. Deswegen nehmen wir nicht die Summe sondern den Mittelwert der Quadrate: $\\frac{1}{n}\\sum_{i=1}^{n}(y_-\\hat{y}_i)^2$. Dieser Wert, *Mean Squared Error* (MSE) genannt, eignet sich um die Güte der vorhersagen zu beurteieln. Wenn ein Model ein kleinen MSE hat, können Sie daraus schlussfolgern, dass die Residuen klein sein müssen also die Unterschiede zwischen vorhergesagten um wahren Wert klein sind. \n",
    "\n",
    "So wie bei der varianz und Standard Abweichung gibt es auch den Root Mean Squared Error (RMSE). Wie Sie sich denken können, wird einfach die Wurzel vom MSE genommen. Schreiben Sie eine Funktion, die den RMSE berechnen kann. Sie dürfen `numpy` benutzen, das heißt Sie brauchen keinen for-loop.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6ad3d6a8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__________________' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_66709/3257105821.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m    \u001b[0mMSE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__________________\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_____\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Hier wird der MSE berechnet,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0m___________\u001b[0m \u001b[0;31m# Wir wollen nicht den MSE sonder den RMSE. Konvertieren Sie den MSE zum RMSE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mRMSE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_hat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_66709/3257105821.py\u001b[0m in \u001b[0;36mRMSE\u001b[0;34m(y, y_hat)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mRMSE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m    \u001b[0mMSE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__________________\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_____\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Hier wird der MSE berechnet,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m    \u001b[0;32mreturn\u001b[0m \u001b[0m___________\u001b[0m \u001b[0;31m# Wir wollen nicht den MSE sonder den RMSE. Konvertieren Sie den MSE zum RMSE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mRMSE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_hat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name '__________________' is not defined"
     ]
    }
   ],
   "source": [
    "def RMSE(y,y_hat):\n",
    "   MSE = np.sum(__________________) /len(_____) #Hier wird der MSE berechnet, \n",
    "   return ___________ # Wir wollen nicht den MSE sonder den RMSE. Konvertieren Sie den MSE zum RMSE\n",
    "RMSE(y, y_hat)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a09e08",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Lösung:</b></summary>\n",
    "    \n",
    "```python\n",
    "def RMSE(y,y_hat):\n",
    "   MSE = np.sum((y-y_hat)**2)/len(y)\n",
    "   return np.sqrt(MSE) \n",
    "```\n",
    "</details>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "e14e9b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(y,y_hat):\n",
    "   MSE = np.sum((y-y_hat)**2)/len(y)\n",
    "   return np.sqrt(MSE) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318c6e25",
   "metadata": {},
   "source": [
    "Im machinellen Lernen, oder allgemeine im Feld der Optimizierung, werden Funktionen wie den RMSE auch als Loss Funktion bezeichnet. Sie messen wie gut ein Model, dessen Parameter, zu den Daten passen. Den Loss, berechnet durch die Loss Funktion, gilt es zu minimieren. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b7ce4c2",
   "metadata": {},
   "source": [
    "# Beispiel\n",
    "\n",
    "Bis jetzt haben Sie immer die Parameter `m` und `t` vorgegeben bekommen. In der Realität müssen Sie diese selber berechnen (lassen). Im folgenden Beispiel werden wir uns mit der Vorhersage von Siedepunkt befassen. Dafür benutzen wir einen Datensatz des amerikanischen *National Institute of Standards and Technology*. Im Datensatz sind die Siedetemperaturen für 72 einfache Alkohole aufgezeichnet. Dazu wrd noch das molekolare Gewicht und die Anzahl der Kohlenstoffe angegeben. \n",
    "Der Datensatz befindet sich im Ordner `../data/boilingpoints/`\n",
    "\n",
    "Wir benutzen diesmal `numpy` um unseren Datensatz einzulesen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "6a5f2e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Größe der Daten:  (72, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[338.  ,  32.04,   1.  ],\n",
       "       [351.  ,  46.07,   2.  ],\n",
       "       [371.  ,  60.1 ,   3.  ],\n",
       "       [356.  ,  60.1 ,   3.  ],\n",
       "       [391.  ,  74.12,   4.  ],\n",
       "       [372.  ,  74.12,   4.  ],\n",
       "       [381.  ,  74.12,   4.  ],\n",
       "       [355.  ,  74.12,   4.  ],\n",
       "       [411.  ,  88.15,   5.  ],\n",
       "       [404.  ,  88.15,   5.  ]])"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.genfromtxt('../data/boilingpoints/bp.csv', delimiter=',', skip_header =True)\n",
    "print(\"Größe der Daten: \",data.shape)\n",
    "data[:10,:] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40c8402",
   "metadata": {},
   "source": [
    "Der Datensatz besteht aus 72 Reihen und 7 Spalten. Jede Reihe representiert einen Alkohol und die 7 Spalten sind 7 Deskriptoren. Die erste Spalte enthält die Schmelzpunkte, die zweite das molekulare Gewicht und die dritte Spalte die Anzahl der Kohlenstoffe. \n",
    "\n",
    "Unsere Ziel ist es mit Hilfe des molekularen Gewichtes den Schmelzpunkt vorher zusagen.\n",
    "zunächst speichern wir die erste Spalte(Schmelzpunkte) in die Variable `y` und die die zweite Spalte in die Variable `x`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eeb2a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[:,0] # y ist unsere zuvorhersagende Variable (schmelzpunkte)\n",
    "x = data[:,1:2] # Wir könnten auch data[:,1] benutzen, verhält sich leicht anders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "52c80deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32.04 46.07 60.1  60.1  74.12]\n",
      "[[32.04]\n",
      " [46.07]\n",
      " [60.1 ]\n",
      " [60.1 ]\n",
      " [74.12]]\n"
     ]
    }
   ],
   "source": [
    "print(data[:5,1])\n",
    "print(data[:5,1:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e596e7a",
   "metadata": {},
   "source": [
    "Sie können sehen, dass wir die selben Werte auswählen, allerdings reduzieren wir die Spalte in der ersten Variante zu einem 1-dimensionales Array der Größe `(72)`. Also einem Vektor der Länge 72. Mancher der Funktionen notwenig für eine lineare Regression erwarten, dass sich unsere `x` Variable in Form eines 2-dimensionalen Array befindet. Deswegen wählen wir die Spalte mit `data[:,1:2]` aus.\n",
    "\n",
    "\n",
    "Sie können die Daten auch graphisch darstellen, dafür benutzen wir die Libary `matplotlib`. Mit der `plt.plot()` Funktion können Sie schnell einfache Graphen erstellen. Hierbei müssen Sie nur angeben welche Werte auf die x-Achse angeben (erste Position in der Funktion), dann geben Sie an was auf die y-Achse gehört (zweite Position). Als letztes können Sie spezifizieren ob die einzelnen Werte als Punkt `\"o\"` oder mit einer Linie verbunden werden soll `\"-\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "4c484731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f6788de29d0>]"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(x, y, \"o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eccb26d",
   "metadata": {},
   "source": [
    "Wir können klar sehen, dass mit steigendem Gewicht auch der Siedepunkt der Alkohole steigt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "a5361ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(x,y) # berechnet die Regressions Gerade\n",
    "m = model.coef_ # Wir können m und t aus model() erhalten.\n",
    "t = model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "1af3aa36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.999551972730536"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = reg(data[:,1],m,t)\n",
    "y_hat\n",
    "\n",
    "RMSE(y, y_hat) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "a9af376a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.141295332704825"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = reg(data[:,1],1.9,208)\n",
    "\n",
    "RMSE(y, y_hat) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157f3694",
   "metadata": {},
   "source": [
    "# Logistische Regression\n",
    "\n",
    "Es gibt auch Probleme in dene nicht exakte Werte vorhergesagt werden sollen. Wir wollen zum Beispiel entscheiden, ob ein Patient auf die Intensivstation muss oder nicht. Hierbei muss nur zwischen `JA` oder `NEIN` entschieden werden. In mathematischen Termen würden wir aber von `1` oder `0` sprechen. Wir sprechen von eine binären Klassifizierung, wenn ein Datenpunkt zu einer von zwei Gruppen gehören kann. \n",
    "\n",
    "Hier haben wir ein Beispiel von einem Basketballspieler der auf den Korb aus verschiedenen Distanzen wirft. \n",
    "Macht er einen Korb wird dieser Wurf mit einer `1` gekennzeichnet. Trifft er nicht wird diesem Wurf eine `0` zugeordnet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "d17ea319",
   "metadata": {},
   "outputs": [],
   "source": [
    "körbe = np.array([1,1,1,1,1,1,0,1,0,1,1,0,0,1,1,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0])    \n",
    "distanz = np.array([0.,1.,2.,3.,4.,5.,6.,7.,8.,9.,10.,11.,12.,13.,14.,\n",
    "                    15.,16.,17.,18.,19.,20.,21.,22.,23.,24.,25.,26.,27.,28.,29.])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00807d75",
   "metadata": {},
   "source": [
    "Es ist zwar möglich eine simple Regressionsgerade zu berechnen, diese passt aber auf Grund der binären $y$ Variable nicht sehr gut zu den Daten. Ein Lösung ist die logistische Regression. Hier wird \"nach\" der lineare Regression eine Sigmoid Funktion benutz um die vorhergesagten Werte zu transformieren. \n",
    "\n",
    "<table><tr>\n",
    "<td> <img src='Img/intro_stats/log1.png' alt=\"Drawing\" style=\"width: 250px;\"/> </td>\n",
    "<td> <img src='Img/intro_stats/log2.png' alt=\"Drawing\" style=\"width: 250px;\"/> </td>\n",
    "<td> <img src='Img/intro_stats/log3.png' alt=\"Drawing\" style=\"width: 250px;\"/> </td>\n",
    "</tr></table>\n",
    "\n",
    "<center>\n",
    "<h2>Sigmoid Funktion</h2>\n",
    "</center>\n",
    "\n",
    "Die Sigmoid Funktion ist eine nicht lineare Funktion. Mathamtische wird die Sigmoid Funktion so geschrieben:\n",
    "$$sigmoid(z)= \\frac{1}{1+e^{-z}}$$\n",
    "\n",
    "\n",
    "Um zu verstehen was sie genau macht kann man sich das Beispiel anschauen.\n",
    "\n",
    "<td> <img src='Img/intro_stats/sigmoid.png' alt=\"Drawing\" style=\"width: 250px;\"/> \n",
    "    \n",
    "Auf der x-Achse sind Werte zwischen -6 und 6 **bevor** die Sigmoid Funktion auf diese Werte angewendet wird. Auf der y-Achse befinden sich die selben Werte aber diesmal nachdem die Sigmoid Funktion angewendet worden ist. \n",
    "Alle Werte befinden sich jetzt zwischen 0 und 1. Werte die voher sehr weit entfernt waren von 0 werden sehr nah zu `0` oder `1` gesetzt.\n",
    "    \n",
    "Die Form dieser Funktion passt schon viel besser zu einer binären Klassifizierung.\n",
    "\n",
    "Um eine logistische Regression durchzuführen, können wir schon auf das Gelernte von der linearen Regression bauen.\n",
    "Wir haben die slebe Situation, wir wollen mit Hilfe von unserem Input `x`, eine Vorhersage für `y` machen.     \n",
    "Dafür werden die Werte aus der linearen Regression einfach in die Sigmoid Funktion gesetzt.\n",
    "$$ z = mx+t $$\n",
    "$$\\hat{y} = sigmoid(z) = \\frac{1}{1+e^{-z}} = \\frac{1}{1+e^{-(mx+t)}} $$    \n",
    "\n",
    "Berechnet nun z in dem ihr die reg_treffer auf die Werte Distanz anwendent. Da Sie jetzt numpy benutzen können brauchen Sie keinen for-loop mehr.\n",
    "Für das Beispiel mit dem Basketballer sind folgende Parameter vorgegeben:\n",
    "- `m` = -0.8\n",
    "- `t` = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6146ff70",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Lösung:</b></summary>\n",
    "    \n",
    "```python\n",
    "def reg_treffer(distanz):\n",
    "    return -0.8*distanz+7\n",
    "```\n",
    "</details>    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d3f00a",
   "metadata": {},
   "source": [
    "Berechnet nun `z` in dem ihr die `reg_treffer` auf die Werte Distanz anwendent.\n",
    "Da Sie jetzt `numpy` benutzen können brauchen Sie keinen for-loop mehr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "4c98c6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = reg(______) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7222122",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Lösung:</b></summary>\n",
    "\n",
    "```python\n",
    "z = reg_treffer(distanz) \n",
    "```\n",
    "</details>    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50f6d2c",
   "metadata": {},
   "source": [
    "Als nächstes benötigen Sie die Sigmoid Funkion. Schreiben Sie mit Hilfe von `numpy` eine Funktion in Pythondafür. $e^(x)$ kann mit Hilfe von `numpy` als `np.exp(x)` geschrieben werden.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "70736234",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(wert):\n",
    "    return 1/(___________) #Hier den Nenner der sigmoid Funktion einfügen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f743cae",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Lösung:</b></summary>\n",
    "    \n",
    "```python\n",
    "def sigmoid(wert):\n",
    "    return 1/(1+np.exp(-wert))\n",
    "```\n",
    "</details>    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c450c4e",
   "metadata": {},
   "source": [
    "Im letzten Schritt berechnen Sie `y_hat` mit Hilfe von `z` und der `sigmoid` Funktion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d3ef04d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '_____' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_66709/706716774.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_____\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m# welchen Input bracuht die Sigmoid Funktion?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_hat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name '_____' is not defined"
     ]
    }
   ],
   "source": [
    "y_hat = sigmoid(_____)# welchen Input bracuht die Sigmoid Funktion?\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b464f8",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Lösung:</b></summary>\n",
    "    \n",
    "```python\n",
    "y_hat = sigmoid(z)\n",
    "```\n",
    "</details>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "79e26289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99908895, 0.99797468, 0.99550373, 0.9900482 , 0.97811873,\n",
       "       0.95257413, 0.90024951, 0.80218389, 0.64565631, 0.450166  ,\n",
       "       0.26894142, 0.14185106, 0.06913842, 0.03229546, 0.01477403,\n",
       "       0.00669285, 0.00301842, 0.00135852, 0.00061088, 0.00027458,\n",
       "       0.00012339, 0.00005545, 0.00002492, 0.0000112 , 0.00000503,\n",
       "       0.00000226, 0.00000102, 0.00000046, 0.00000021, 0.00000009])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849a99e8",
   "metadata": {},
   "source": [
    "Wir Sie sehen können befinden sich nun alle Werte zwischen `0` und `1`. Eigentlich wollten wir Werte die `0` oder `1` sind, nicht Werte dazwischen. Tatsächlich können die Werte von `y_hat` als eine Art von Wahrscheinlichkeit verstanden werden. Eine vorhergesagter Wert von `0.99908895` bedeutet, das, laut dem Model, der Basketball zu 0.99% einen Korb macht. Andersrum eine Wert von `0.00135852` zeigt an, das, laut dem Model, nur eine Wahrscheinlichkeit von 0.14% besteht, einen Korb zu werfen.\n",
    "Im folgenden Bild sind die vorhergesagten Werte zusammen mit den vorhergesagten Bildern gezeigt. \n",
    "<img src='Img/intro_stats/log4.png' alt=\"Drawing\" width= \"500px\"/> \n",
    "\n",
    "Normalerweise werden die Wahrscheinlichkeiten so interpretiert, dass ab einen Wert `>0.5` das Model eine `1` vorhersagt und darunter eine `0`.\n",
    "\n",
    "Somit können wir die Genauigkeit des Models an Hand des Prozentsatz an richtig klassifizierten Würfen beurteilen. \n",
    "zunächt runden wir `y_hat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "7dcd66b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = np.round(y_hat)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71b1428",
   "metadata": {},
   "source": [
    "Sie können auch vergleichen ob `pred` mit der ursprünglichen `y` Variable `körbe` übereinstimmt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "ff63e2f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True, False,  True, False,\n",
       "       False, False,  True,  True, False, False,  True,  True,  True,\n",
       "       False,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "        True,  True,  True])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred==körbe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89568776",
   "metadata": {},
   "source": [
    "Schreiben Sie eine Funktion, die die Accuracy berechnet (prozentualen Anteil von korrekt klassfizierten Würfen). Denken Sie daran, dass `booleans`, also `True` und `False`, auch als `1` und `0` in Python gelten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "8a1fc921",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (428290641.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_66709/428290641.py\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    return _____ y_true==y_pred __ / ________\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    return _____ y_true==y_pred __ / ________ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72eda8af",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Lösung:</b></summary>\n",
    "    \n",
    "```python\n",
    "def accuracy(y_true, y_pred):\n",
    "    return np.sum(y_true==y_pred)/len(y_true)\n",
    "```\n",
    "</details> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "c9e3bce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7333333333333333"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(körbe, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae337378",
   "metadata": {},
   "source": [
    "## Cross Entropy Loss\n",
    "\n",
    "Eine Accuarcy von 0.73 bedeutet, dass das Model in 73% der Fälle das richtige Ergebnis vorhergesagt hat. Ähnlich wie der RMSE ist eine Metrik um ein zuschätzen wie gut unsere Model ist.\n",
    "\n",
    "Oft wird aber nicht nur eine Metrik benutzt. Der Vorteil der Accuarcy ist, das sie sehr leicht zu interpretieren ist. Aber manche mathematischen Eigenschaften der Accuarcy machen sie ungeignet für bestimmte Prozesse bei machinellen Lernen. Deswegen werden meistens mindesten zwei verschiedenen Metriken angeschaut. \n",
    "\n",
    "Die Metrik die bei Klassifizierung benutzt wird ist der **Cross Entropy** Loss. Im Falle eines binären Klassifizierungsproblem reden wir dann meistens vom  **Binary Cross Entropy** Loss. \n",
    "\n",
    "$$Loss =-\\frac{1}{n}\\sum_{i=0}^n[y_i\\cdot log\\hat{y}_i + (1-y_i)\\cdot log(1-\\hat{y}_i)]$$\n",
    "\n",
    "Die Formel sieht zunächst sehr kompliziert aus, ist aber relativ einfach an Hand von Beispielen zu verstehn.\n",
    "Angenommen wir wollen den Loss nur für einen einzigen Datenpunkt berechnen zum Beispiel einen einzigen Wurf des Basketballers. Dann bbrauchen wir zunächst nur diese Formel:\n",
    "\n",
    "$$Loss =-[y_i\\cdot log(\\hat{y}_i) + (1-y_i)\\cdot log(1-\\hat{y}_i)]$$\n",
    "\n",
    "Angenommen der Basketballer der Basketballer hat den Wurf nicht getroffen, dann ist $y_i=0$.\n",
    "\n",
    "Daraus resultiert:\n",
    "$$Loss =-0\\cdot log(\\hat{y}_i) + (1-0)\\cdot log(1-\\hat{y}_i)$$\n",
    "$$Loss =-log(1-\\hat{y}_i)$$\n",
    "\n",
    "Das heißt der Loss für diesen Wurf ergibt sich aus dem $log$ der Differenz von 1 und $\\hat{y}$ (der vorhergesagten Wahrscheinlichkeit) \n",
    "\n",
    "Sie können ausprobieren was mit dem Loss passiert für unterschiedliche Wahrscheinlichkeiten. Denken Sie daran, dass der wahre Wert $y_i=0$ ist. Also ein gute Model würde ein geringe Wahrscheinlichkeit vorhersagen, also ist ein geringer Los zu erwarten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "b4219256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0010005003335835344"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setzen Sie verschieden Wahrscheinlichkeiten in die Formel unten ein und schauen Sie was mit dem Loss passiert.\n",
    "\n",
    "np.log(1 - 0.___ ) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02dff21f",
   "metadata": {},
   "source": [
    "Zunächst fäll auf das der Loss immer negativ ist, deswegen ist in der eigentlichen Formlen von oben noch ein minus um den Loss wieder postiv zu machen. \n",
    "\n",
    "Sie können erkennen, dass wenn besonders hohe Wahrscheinlichkeiten vorhergesagten werden  entfernt sich der Loss von Null. Wenn besonders kleine Wahrscheinlichkeiten eingesetzt werden, nähert sich der Loss Null. Das heißt also je \"falscher\" unsere Model ist desto größer wird der Loss, also genau das was wir wollen.\n",
    "\n",
    "Angenommen unser Baskebtaller hat den Wurf getroffen, dann ist $y_i=1$\n",
    "\n",
    "$$Loss =-1\\cdot log(\\hat{y}_i) + (1-1)\\cdot log(1-\\hat{y}_i)$$\n",
    "$$Loss =-log(\\hat{y}_i)$$\n",
    "\n",
    "Diesmal bleibt ein andere aber immer noch simpler Teil der Formel übrig.\n",
    "Probieren Sie auch diesem Term mit verschiedene Wahrscheinlichkeiten aus. \n",
    "Diesmal wäre eine Wahrscheinlichkeit nahe 1 richtig, sollte also zu einem geringem Loss führen.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "b1cdc717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0010005003335835344"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-np.log(0.___)# setzen Sie hier verschiedene Wahrscheinlichkeiten ein"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809bc7a2",
   "metadata": {},
   "source": [
    "Auch hier wird der Loss größer, wenn die Wahrscheinlcihkeit sich vom wahren Wert entfernt. \n",
    "\n",
    "Der Loss ist also nur so komplex um sowohl einen wahren Wert von `1` also auch von `0` abzudecken. Der `log` wird benutzt damit Werte die weiter entfernt vom wahren Wert sind, einen überproportionalen Einfluss auf den Loss haben. Der ursprüngliche Teil $\\frac{1}{n}\\sum_{i=1}^n$ berechnet nur ne Durchschnitt über alle Datenpunkt im Datensatz. \n",
    "Unten wird die Formel für den BCE mit `numpy` definiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "5f4e4fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BCE(y_true, y_hat):\n",
    "    return -np.mean(y_true*np.log(y_hat) +(1-y_true)* np.log(1-y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "47774f2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1082363405105524"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BCE(körbe, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "05bfd6f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "9fad5c87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "5c47acd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.409420839653209"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e7e355",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
