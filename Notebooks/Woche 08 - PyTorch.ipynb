{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"https://venturebeat.com/wp-content/uploads/2019/06/pytorch-e1576624094357.jpg?w=1200&strip=all\" style=\"width: 800px;\">\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch\n",
    "\n",
    "Letze Woche haben Sie ein einfaches neuronales Netzwerk selber programmiert. Wie schon erwähnt, ist es aber nicht nötig jedes Netzwerk selber zu programmieren. Bestimmte Softwarepackte übernehemen viele der Unannehmlichkeiten, die beim erstellen und trainieren von Netzwerken auftreten.\n",
    "\n",
    "Grundätzlich gibt es zwei Libraries die benutzt werden können PyTorch und Tensorflow. Tensorflow wird von Google entwickelt. Tensorflow ist die populärere Wahl, vorallem in der Industrie. PyTorch hingegen, hat sich vorallem in der wissenschaftlichen Welt durchgesetzt. Grundsätzlich gilt PyTorch als das leichter zu lernende Framework ist insgesamt benutzerfreundlicher. \n",
    "\n",
    "Während es früher noch große Unterschiede gab, werden die beiden Libraries heute immer ähnlicher in ihrer Funktionalität..\n",
    "\n",
    "Als letztes gibt es noch Keras und PyTorch Lightning. Beide haben das Ziel das Erstellen von Neuronale Netzwerke noch einfach zu machen. Keras benutzt im Hintergrund Tensorflow, macht es aber vorallem Anfänger leichter Netzwerke zu trainieren. Das selbe gilt für PyTorch Lightning und PyTorch.\n",
    "\n",
    "In der Chemieinformatik bietet sich aber PyTorch an, da es spezielle Libraries für Graph Neural Networks nur für PyTorch gibt/gegeben hat.\n",
    "\n",
    "\n",
    "Ein essentieller Bestandteil von PyTorch ist **autograd**. Autograd is eine Library, die wie der Name erahnen lässt, die Gradienten automatisch berechenen und sammeln kann. Dadurch müssen die Ableitungen nicht mehr selber berechnen werden.\n",
    "Auch gibt es viele Funktionen, wie z.B. Activationfunctions oder Lineare Transformationen, die schon in PyTorch implementiert sind. \n",
    "\n",
    "*Tensorflow hat diese Funktionalitäten natürlich auch*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Während Sie gestern mit Numpy Arrays gerechnet haben, benutzen wir heute `Tensors`, genauer gesagst PyTorchs `tensors`. \n",
    "\n",
    "**Was ist der Unterschied?**\n",
    "\n",
    "Erst einmal keiner. Arrays und Tensors sind sich in vielen Punkten ähnlich. Beide speichern Zahlen/Werte in einer stukturierte Form. So können Sie in Numpy Matrizen in einem 2D-Array speichern, Sie können aber die gleich Matrix auch in einem 2D-Tensor speichern.\n",
    "Auch lassen sich Tensors in Arrays und Arrays in Tensors umwandeln.\n",
    "\n",
    "Der Unterschied zwischen den beiden \"Speichermöglichkeiten\" ist, dass PyTorch Tensor von PyTorch entwickelt worden sind. Und Numpy Arrays wurden von den Entwicklern von Numpy entwickelt. \n",
    "Viele Funktionen, die Numpy bietet gibt es auch von PyTorch für deren Tensors (heißen dann aber eventuell anders). \n",
    "PyTorch hat ihre Tensors entwickelt, um mathematische Operationen schneller durchführen zukönnen. Zudem kann man Tensors auch auf die Graphikkarte \"laden\", was die Geschwindigkeit von Operation um ein Vielfaches verbessert."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit Tensors zu rechenen ist fast identisch zu Rechnung mit Arrays. Aber die Funktionen tragen eventuell andere Namen. `torch.mm()` ist zum Beispiel die Funktion für Matrixmultiplikation und `.t()` ist das Transpose einer Matrix. Ähnlich wie mit `np.array()` Arrays erstellt werden, so werden mit `torch.tensor()` Tensors erstellt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch # lädt PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  57,  976],\n",
       "        [ 138, 1984]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([[1,2,3],\n",
    "                [4,5,6]])\n",
    "\n",
    "W = torch.tensor([[8,9,10],\n",
    "                 [11,12,313]])\n",
    "\n",
    "b = torch.tensor([1,2])\n",
    "\n",
    "torch.mm(X,W.t())+b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das ist die lineare Transformation, die Sie auch schon von gestern kennen.<br>\n",
    "PyTorch vereinfacht diesen Schritt aber. \n",
    "So gibt es ein ein Module in PyTorch mit dem Namen `nn`, diese enthält viele Funktionen die hilfreich sind für das Erstellen von Neuronalen Netzwerken.\n",
    "\n",
    "Wir können das Module `nn` mit `from torch import nn` laden. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neuronales Netzwerk mit PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorchs `nn` stellt unter anderm die Funktion `nn.Linear` zur Verfügung. Diese führt die Linear Transformation $xW^T +b $ aus.\n",
    "Als Input nimmt die Funktion: \n",
    "* `in_features`  die Anzahl der Features die der Input hat vor der Transformation hat, oder auch die Größe der Input Layer. Gestern hatten die Bilder 784 Pixel also 784 Features\n",
    "* `out_features`  wie viele Features der Input nach der Transformation haben soll. `out_features` legt also die Größe der Hidden Layer fest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_1=nn.Linear(in_features = 784, out_features=200, bias=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fehlt den nicht der Input für die Layer?\n",
    "\n",
    "Stimmt, bis jetzt haben Sie auch keine lineare Transformation durchgeführt, sondern nur eine Variable  `layer_1` erstellt. Diese kann dann die lineare Transformation für durchführen.\n",
    "Praktisch ist vorallem, dass die Weights dieser Transformation automatisch von PyTorch initialisiert werden. Das nimmt Ihnen schon ein wenig Arbeit ab.\n",
    "Die Weights $W$ dieser Layer können auch angeschaut werden.\n",
    "\n",
    "Dafür benutzen Sie `list(layer_1.parameters())[0]`\n",
    "Wenn Sie die genaue Größe der Weightmatrix in Erfahrung bringen wollen, können Sie wie bei Numpy `.shape` benutzen: `list(layer_1.parameters())[0].shape` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0315, -0.0226, -0.0356,  ...,  0.0275, -0.0225,  0.0054],\n",
       "        [-0.0113, -0.0114,  0.0144,  ...,  0.0021, -0.0322,  0.0177],\n",
       "        [-0.0130,  0.0066,  0.0298,  ..., -0.0220,  0.0076, -0.0148],\n",
       "        ...,\n",
       "        [ 0.0139,  0.0192, -0.0268,  ..., -0.0275,  0.0195, -0.0049],\n",
       "        [-0.0254, -0.0010, -0.0126,  ...,  0.0337, -0.0207,  0.0198],\n",
       "        [ 0.0056,  0.0173, -0.0260,  ..., -0.0245, -0.0044,  0.0079]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(layer_1.parameters())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200, 784])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(layer_1.parameters())[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sie sehen, die Weightmatrix hat die gleichen Dimensionen wie die Matrix von letzter Woche. Sie können auch sehen, dass die Matrix tatsächlich Weights beinhaltet.\n",
    "Sie brauchen jetzt nur einen Input (Bilder), die Sie mit dieser linearen Transformation verändern wollen. \n",
    "Dazu wird der Trainingsdatensatz von gestern mit Numpy geladen.\n",
    "Zusätzlich müssen die Bilder noch in einen Tensor umgewandelt werden. Das geht mit `torch.tensor()`\n",
    "\n",
    "Sie müssen natürlich auch wieder die Daten skalieren. Dafür benutzen Sie den Min-Max Scaler von gestern.\n",
    "In PyTorch muss genauer auf die Datentypen geachtet werden. \n",
    "Deswegen legen wir den Datentyp `dtype` festgelegt. Die Datenart für unsere Bilder ist `float32`. `float` kennt ihr noch von gestern, die `32` legt fest wie genau diese Zahl sein kann.\n",
    "`long` sagt Ihnen vielleicht nichts, ist aber einfach einer der `torch` Begriffe für Integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 784])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "def min_max(x):\n",
    "    return (x - np.min(x)) / (np.max(x) - np.min(x))\n",
    "\n",
    "\n",
    "train_data = np.genfromtxt('../data/mnist/mnist_train.csv', delimiter=',', skip_header =False) #genfromtxt reads .txt files if we chose delimiter =\",\" the function can read also .csv files  (comma seperated values)\n",
    "\n",
    "train_images = min_max(train_data[:,1:])\n",
    "train_images = torch.tensor(train_images, dtype = torch.float32)\n",
    "train_labels=torch.tensor(train_data[:,0].astype(int), dtype = torch.long) \n",
    "\n",
    "train_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Datensatz umfasst 60000 Bilder mit jeweils 784 Pixeln.\n",
    "Diese können Sie jetzt als Input für die lineare Transformation benutzen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0388,  0.1240, -0.1960,  ...,  0.2702,  0.5457, -0.3153],\n",
      "        [ 0.0382, -0.0691, -0.2583,  ...,  0.0971,  0.2431, -0.4642],\n",
      "        [-0.0118, -0.0990, -0.1204,  ...,  0.0985,  0.0498, -0.0121],\n",
      "        ...,\n",
      "        [ 0.0241,  0.4946, -0.2626,  ..., -0.1371,  0.1223, -0.0196],\n",
      "        [-0.0556, -0.1955, -0.1134,  ...,  0.1895, -0.0340, -0.0536],\n",
      "        [ 0.0538,  0.1251, -0.1751,  ..., -0.4330,  0.1150, -0.0716]],\n",
      "       grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 200])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_1=layer_1(train_images)\n",
    "print(z_1)\n",
    "z_1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die `layer_1` gibt den Output (`z_1`) aus. Dieser hat die `shape` `[60000,200]`. Also immer noch 60000 Bilder, aber diesmal hat jedes nur jeweils 200 Features (Größe der Hidden Layer). So wie es auch bei der Definition der `layer_1` bestimmt wurde.\n",
    "\n",
    "Was Ihnen auffallen sollte: am Ende des Tensors `z_1` steht `grad_fn=<AddmmBackward>`. Dies zeigt an, dass ***autograd** die Gradienten für diese Transformation erfasst hat. Wenn man will, kann man auch erkennen, dass wir eine Matrixmultiplikation `mm` und eine Addition `Add` durchgeführt haben.\n",
    "\n",
    "Was Ihnen jetzt noch fehlt ist die Activationfunction. Auch hier kann PyTorch helfen. \n",
    "PyTorchs `nn` hat ein Submodul `functional`. Hier sind viele zusätzliche mathematische Funktionen enthalten unter anderem auch die `relu` Funktion.\n",
    "`functional` lässt sich wie folgt importieren: `from torch.nn import functional as F`. Wir nennen `functional` zu `F` um, quasi einen Norm wenn man mit Pytorch arbeitet.\n",
    "\n",
    "`F.relu()` kann jetzt benutzt werden um die ReLU Funktion anzuwenden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0388, 0.1240, 0.0000,  ..., 0.2702, 0.5457, 0.0000],\n",
      "        [0.0382, 0.0000, 0.0000,  ..., 0.0971, 0.2431, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0985, 0.0498, 0.0000],\n",
      "        ...,\n",
      "        [0.0241, 0.4946, 0.0000,  ..., 0.0000, 0.1223, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.1895, 0.0000, 0.0000],\n",
      "        [0.0538, 0.1251, 0.0000,  ..., 0.0000, 0.1150, 0.0000]],\n",
      "       grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import functional as F\n",
    "\n",
    "a_1 = F.relu(z_1)\n",
    "print(a_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wenn Sie `a_1` mit `z_1` vergleichen können Sie sehen, dass alle Werte die vorher negative waren Null wurden und alle Werte die positive waren unverändert sind.\n",
    "Auch kann man im `grad fn` sehen, dass eine ReLU angewandt wurde. Also auch das hat *autograd* mit aufgezeichnet. \n",
    "\n",
    "Der erste Teil der Forwardpropagation ist geschafft. \n",
    "Für den zweiten Schritt können wir einfach eine zweite Layer erstellen, die `a_1` als Input nimmt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_2 = nn.Linear(200,10) # 10 ist die Anzahl der out_features, da wir 10 Ziffern haben.\n",
    "z_2=layer_2(a_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auch hier brauchen Sie wieder eine Activationfunction. Diesmal aber die `softmax` - Funktion um die Wahrscheinlichkeiten zu erhalten.\n",
    "`nn.functional` hat auch eine `softmax()` Funktion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = F.softmax(z_2,dim=1) # die dim Funktion legt fest ob über Spalten oder Reihen die Softmax funktion angewandt wird."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In PyTorch kann man auch verschiedene Layers zusammenfassen. Mit `nn.Sequential` können Sie die linearen Transformation und Activationfunction direkt hintereinander schalten. Der der Input wird automatisch durch jeder der Layers weitergeleitet.\n",
    "Das macht Ihren Code überschichtlicher und einfacher zu schreiben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=784, out_features=200, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=200, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netzwerk = nn.Sequential(nn.Linear(784,200), \n",
    "                         nn.ReLU(), \n",
    "                         nn.Linear(200,10))\n",
    "netzwerk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie Sie sehen können, wurde ein Netzwerk mit einer Hiddenlayer erstellt. Was Ih aufallen sollte ist, dass anstatt `F.relu` `nn.ReLU` benutzt wurde. Wenn eine eine `relu` Funktion innerhalb von `Sequential()` benutzt werden soll müssen Sie immer `nn.ReLU` benutzen. \n",
    "\n",
    "Das `netzwerk` könnte nun die Bilder klassifizieren:\n",
    "Mit `netzwerk(input)` kann der Input z.B. unsere Bilder durch das Netzwerk geführt werden.\n",
    "An Hand der Tensorgröße des Outputs können Sie sehen, dass tatsächlich am Ende 60000 Bilder mit jeweils 10 Features (den 10 Ziffern bekommen) als Output herausgegeben werden.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 10])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output=netzwerk(train_images)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ein weitere Veränderung ist, dass Sie nicht mehr die letzte Activationfunktion benutzt haben. PyTorch wählt die Activationfunktion automatisch. Die Entscheidung welche Activationfunction in der letzte Layer benutzt werden soll hängt von der Wahl der Lossfunktion ab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Funktion\n",
    "\n",
    "Auch mit der Lossfunktion kann `nn` helfen. Die häufigsten Lossfunktionen sind nämlich schon in PyTorch enthalten.\n",
    "Sie können einfach eine neue Variable erstellen und dieser die `nn.CrossEntropyLoss()` Funktion zuorden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_funktion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`loss_funktion` kann nun den Loss aurechnen und wendet dabei automatisch die Softmax-Funktion an.\n",
    "Dazu müssen Sie einfach nur `y_hat` und die `train_labels` in die Funktion geben. Hier zeigt sich ein weitere Vorteil, Sie brachen die Labels nicht noch `one-hot` codieren, auch das macht PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3052, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss=loss_funktion(output, train_labels)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back Propagation\n",
    "\n",
    "Als letzen Schritt können müssen Sie noch die Back Propagation durchführen. Dank *autograd* geht das einfach mit dem Befehl `loss.backward()`. Dieser berechnet die Gradienten für alle Weightmatrizen.\n",
    "\n",
    "Dannach müssen die Weightmatrizen nur noch geupdated werden. Wie Sie sich denken können nimmt Ihnen auch das Python ab.\n",
    "Pytorch stellt sogar eine Vielzahl von Algorithmen zu Verfügung. Viele dieser funktionieren besser als der einfache Gradient Descent.\n",
    "Für das Updaten der Weights wird ein neues Module von PyTorch benötigt.\n",
    "Dafür laden Sie `from torch import optim`. `optim` enthält Optimizer, also Funktionen die für uns das Netzwerk optimieren - die Weights updaten.\n",
    "\n",
    "Ähnlich wie bei der Loss Funktion, können Sie auch hier einfach eine Variable erstellen und ihr Updatefuktion zuordnen. \n",
    "Sie können jetzt den `optim.SGD()` zum updaten benutzen. SGD = Stochastic Gradient Descent.  In der Funktion selber definieren Sie welche Parameter (Weights) verändert werden sollen. Auch legen Sie hier die Lernrate fest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward() #sammelt die Gradienten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "weights_updaten=optim.SGD(netzwerk.parameters(), lr=0.01) # Sie legen fest welche Parameter und mit welche Lernrate diese verändert werden sollen\n",
    "\n",
    "weights_updaten.step() # mit- step() verändert Sie ein die Weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetzt haben Sie alles was man für ein Netzwerk braucht.\n",
    "\n",
    "Sie können wieder einen for-loop benutzen, um das Training zu automatisieren.\n",
    "\n",
    "Es fällt euch eventuell auf, dass wir noch `updaten.zero_grad()` benutzen. Dieses Funktion wird benutzt um die gesammelten Gradienten zu löschen. Wird das nicht gamcht, so würde der Optimizer alle Gradienten aus allen Epochs zusammen zählen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 2.31 Training Accuracy: 0.08\n",
      "Training Loss: 2.26 Training Accuracy: 0.28\n",
      "Training Loss: 2.21 Training Accuracy: 0.47\n",
      "Training Loss: 2.16 Training Accuracy: 0.58\n",
      "Training Loss: 2.10 Training Accuracy: 0.65\n",
      "Training Loss: 2.03 Training Accuracy: 0.68\n",
      "Training Loss: 1.96 Training Accuracy: 0.69\n",
      "Training Loss: 1.88 Training Accuracy: 0.70\n",
      "Training Loss: 1.79 Training Accuracy: 0.72\n",
      "Training Loss: 1.69 Training Accuracy: 0.73\n",
      "Training Loss: 1.59 Training Accuracy: 0.74\n",
      "Training Loss: 1.50 Training Accuracy: 0.75\n",
      "Training Loss: 1.40 Training Accuracy: 0.76\n",
      "Training Loss: 1.31 Training Accuracy: 0.77\n",
      "Training Loss: 1.23 Training Accuracy: 0.78\n",
      "Training Loss: 1.15 Training Accuracy: 0.79\n",
      "Training Loss: 1.08 Training Accuracy: 0.79\n",
      "Training Loss: 1.02 Training Accuracy: 0.80\n",
      "Training Loss: 0.97 Training Accuracy: 0.81\n",
      "Training Loss: 0.92 Training Accuracy: 0.82\n",
      "Training Loss: 0.88 Training Accuracy: 0.82\n",
      "Training Loss: 0.84 Training Accuracy: 0.82\n",
      "Training Loss: 0.81 Training Accuracy: 0.83\n",
      "Training Loss: 0.78 Training Accuracy: 0.83\n",
      "Training Loss: 0.75 Training Accuracy: 0.84\n",
      "Training Loss: 0.73 Training Accuracy: 0.84\n",
      "Training Loss: 0.71 Training Accuracy: 0.84\n",
      "Training Loss: 0.69 Training Accuracy: 0.84\n",
      "Training Loss: 0.67 Training Accuracy: 0.85\n",
      "Training Loss: 0.65 Training Accuracy: 0.85\n",
      "Training Loss: 0.64 Training Accuracy: 0.85\n",
      "Training Loss: 0.62 Training Accuracy: 0.85\n",
      "Training Loss: 0.61 Training Accuracy: 0.86\n",
      "Training Loss: 0.60 Training Accuracy: 0.86\n",
      "Training Loss: 0.59 Training Accuracy: 0.86\n",
      "Training Loss: 0.58 Training Accuracy: 0.86\n",
      "Training Loss: 0.57 Training Accuracy: 0.86\n",
      "Training Loss: 0.56 Training Accuracy: 0.86\n",
      "Training Loss: 0.55 Training Accuracy: 0.87\n",
      "Training Loss: 0.54 Training Accuracy: 0.87\n",
      "Training Loss: 0.53 Training Accuracy: 0.87\n",
      "Training Loss: 0.52 Training Accuracy: 0.87\n",
      "Training Loss: 0.52 Training Accuracy: 0.87\n",
      "Training Loss: 0.51 Training Accuracy: 0.87\n",
      "Training Loss: 0.50 Training Accuracy: 0.87\n",
      "Training Loss: 0.50 Training Accuracy: 0.87\n",
      "Training Loss: 0.49 Training Accuracy: 0.88\n",
      "Training Loss: 0.49 Training Accuracy: 0.88\n",
      "Training Loss: 0.48 Training Accuracy: 0.88\n",
      "Training Loss: 0.48 Training Accuracy: 0.88\n"
     ]
    }
   ],
   "source": [
    "## Definieren des Netzwerkes,LossFunktion und Update Algorithmus\n",
    "netzwerk = nn.Sequential(nn.Linear(784,200), \n",
    "                         nn.ReLU(), \n",
    "                         nn.Linear(200,10))\n",
    "\n",
    "loss_funktion = nn.CrossEntropyLoss()\n",
    "updaten = optim.SGD(netzwerk.parameters(), lr=0.3)\n",
    "EPOCHS = 50\n",
    "\n",
    "## Trainings Loop\n",
    "for i in range(50):\n",
    "    updaten.zero_grad()\n",
    "    output = netzwerk(train_images) # Forward Propagation\n",
    "    \n",
    "    loss   = loss_funktion(output, train_labels)\n",
    "    loss.backward()\n",
    "    acc=((output.max(dim=1)[1]==train_labels).sum()/float(output.shape[0])).item()\n",
    "    print(\n",
    "        \"Training Loss: %.2f Training Accuracy: %.2f\"\n",
    "        % (loss.item(), acc)\n",
    "    )\n",
    "    \n",
    "    updaten.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sie können sehen, dass Sie mit viel weniger Aufwand ein neuronales Netzwerk trainieren können. Sie können auch ohne großen Aufwand ein zweite oder dritte Hiddenlayer zu Ihrem Model hinzufügen.\n",
    "Einfach eine `nn.ReLU` und eine `nn.Linear` Layer in `Sequential` hinzufügen und **autograd** kann auch für diese Layers die Gradienten berechen. Alles andere bleibt gleich. Denken Sie nur daran, dass die Dimensionen von einer zu nächsten Layer passen müssen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=784, out_features=200, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=200, out_features=10, bias=True)\n",
      ")\n",
      "Training Loss: 2.30 Training Accuracy: 0.11\n",
      "Training Loss: 2.29 Training Accuracy: 0.14\n",
      "Training Loss: 2.28 Training Accuracy: 0.15\n",
      "Training Loss: 2.27 Training Accuracy: 0.20\n",
      "Training Loss: 2.25 Training Accuracy: 0.27\n",
      "Training Loss: 2.24 Training Accuracy: 0.37\n",
      "Training Loss: 2.22 Training Accuracy: 0.43\n",
      "Training Loss: 2.20 Training Accuracy: 0.46\n",
      "Training Loss: 2.18 Training Accuracy: 0.50\n",
      "Training Loss: 2.16 Training Accuracy: 0.53\n",
      "Training Loss: 2.12 Training Accuracy: 0.55\n",
      "Training Loss: 2.09 Training Accuracy: 0.56\n",
      "Training Loss: 2.04 Training Accuracy: 0.58\n",
      "Training Loss: 1.99 Training Accuracy: 0.59\n",
      "Training Loss: 1.93 Training Accuracy: 0.59\n",
      "Training Loss: 1.86 Training Accuracy: 0.60\n",
      "Training Loss: 1.78 Training Accuracy: 0.62\n",
      "Training Loss: 1.69 Training Accuracy: 0.63\n",
      "Training Loss: 1.60 Training Accuracy: 0.65\n",
      "Training Loss: 1.50 Training Accuracy: 0.68\n",
      "Training Loss: 1.41 Training Accuracy: 0.70\n",
      "Training Loss: 1.32 Training Accuracy: 0.73\n",
      "Training Loss: 1.23 Training Accuracy: 0.74\n",
      "Training Loss: 1.15 Training Accuracy: 0.76\n",
      "Training Loss: 1.08 Training Accuracy: 0.77\n",
      "Training Loss: 1.01 Training Accuracy: 0.78\n",
      "Training Loss: 0.96 Training Accuracy: 0.79\n",
      "Training Loss: 0.91 Training Accuracy: 0.80\n",
      "Training Loss: 0.86 Training Accuracy: 0.80\n",
      "Training Loss: 0.82 Training Accuracy: 0.81\n",
      "Training Loss: 0.80 Training Accuracy: 0.80\n",
      "Training Loss: 0.84 Training Accuracy: 0.77\n",
      "Training Loss: 1.22 Training Accuracy: 0.54\n",
      "Training Loss: 2.39 Training Accuracy: 0.40\n",
      "Training Loss: 2.17 Training Accuracy: 0.48\n",
      "Training Loss: 1.37 Training Accuracy: 0.48\n",
      "Training Loss: 1.06 Training Accuracy: 0.66\n",
      "Training Loss: 0.91 Training Accuracy: 0.75\n",
      "Training Loss: 0.81 Training Accuracy: 0.79\n",
      "Training Loss: 0.74 Training Accuracy: 0.82\n",
      "Training Loss: 0.69 Training Accuracy: 0.83\n",
      "Training Loss: 0.65 Training Accuracy: 0.84\n",
      "Training Loss: 0.63 Training Accuracy: 0.84\n",
      "Training Loss: 0.60 Training Accuracy: 0.84\n",
      "Training Loss: 0.59 Training Accuracy: 0.84\n",
      "Training Loss: 0.62 Training Accuracy: 0.81\n",
      "Training Loss: 0.76 Training Accuracy: 0.72\n",
      "Training Loss: 1.25 Training Accuracy: 0.60\n",
      "Training Loss: 1.26 Training Accuracy: 0.57\n",
      "Training Loss: 0.87 Training Accuracy: 0.71\n"
     ]
    }
   ],
   "source": [
    "## Definieren Sie das Netzwerk, Loss Funktion und Update Algorithmus\n",
    "netzwerk = nn.Sequential(nn.Linear(784,200), \n",
    "                         nn.ReLU(), \n",
    "                         nn.Linear(200,200),\n",
    "                         nn.ReLU(), \n",
    "                         nn.Linear(200,10))\n",
    "print(netzwerk)\n",
    "loss_funktion = nn.CrossEntropyLoss()\n",
    "updaten = optim.SGD(netzwerk.parameters(), lr=0.3)\n",
    "EPOCHS = 50\n",
    "\n",
    "## Trainings Loop\n",
    "for i in range(50):\n",
    "    updaten.zero_grad()\n",
    "    output = netzwerk(train_images) # Forward Propagation\n",
    "    \n",
    "    loss   = loss_funktion(output, train_labels)\n",
    "    loss.backward()\n",
    "    \n",
    "    acc=((output.max(dim=1)[1]==train_labels).sum()/float(output.shape[0])).item()\n",
    "    print(\n",
    "        \"Training Loss: %.2f Training Accuracy: %.2f\"\n",
    "        % (loss.item(), acc)\n",
    "    )\n",
    "    \n",
    "    updaten.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "Sie haben vielleicht schon gemerkt, dass wir als Optimizer (Weights updaten) den Stochastic Gradient Descent benutzen. Gestern wurde nur von dem Gradient Descent gesprochen.\n",
    "Tatsächlich wird der Gradient Descent, so wie gestern erklärt eigentlich nicht mehr benutzt, sondern als Alternatve der Stochastic Gradient Descent. \n",
    "\n",
    "Der Unterschied:<br>\n",
    "Im Stochastic Gradient Descent wird der Datensatz nicht auf einmal durch das Netz geschickt, sondern der Datensatz wird in kleineren Teilen (**minibatch**) durch das Netzwerk gebracht. <br>\n",
    "In diesem Datensatz gibt es insgesamt 60000 Bilder. Beim Gradient Descent, werden wird der Forwardpass mit 60000 Bilder berechnet, für die 60000 Bilder der Loss brechnet. Danach werden die Bilder einmal upgedated.\n",
    "Dann wiederholt sich der Schritt. \n",
    "\n",
    "Es wäre doch effizienter, wenn nicht erst nach allen 60000 Bilder ein Update passiert. Sondern schon nach 200 oder auch nur 100.  Dadurch kann das Netzwerk viel schneller lernen\n",
    "Genau das macht Stochastic Gradient Descent.  Nicht alle Bilder, sondern nur z.B. 32 Bilder werden auf einmal durch das Netzwerk geschickt. Für diese 32 wird dann der Loss berechnet und die Updates durchgeführt.\n",
    "Dann wird das wiederholt, aber diesmal mit 32 neuen Bilder. So können innerhalb eines Epochs viel öften die Weights geupdated werden.\n",
    "Die Batchsize gibt an wie groß ein Minibatch (der kleine Teil der Daten der durchs Netzwerk geht) sein soll und kann auch die Performance des Modelles beeinflussen.\n",
    "<center>\n",
    "<img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcT0TVrYkk0A0FfPvnzYTe747F0qPLG2rU2Bmg&usqp=CAU\" style=\"width: 600px;\">\n",
    "</center>\n",
    "<h8><center>Source: Insu Han and Jongheon Jeong, http://alinlab.kaist.ac.kr/resource/Lec2_SGD.pdf</center></h8>\n",
    "\n",
    "\n",
    "Vorteile:<br>\n",
    "* schneller\n",
    "* braucht weniger Speicherplatz (auf der Graphikkarte)\n",
    "\n",
    "Nachteile: <br>\n",
    "* kann nicht das Optimum finden (kann aber auch gut sein, um overfitting zu verhindern)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um Minibatches aus den Daten zu machen, können Sie auch PyTorch benutzen. Dafür gibt es ein weiteres Submodule `torch.utils.data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `torch.utils.data` gibt es zwei Funktionen die Sie brauchen:\n",
    "\n",
    "* `data.TensorDataset(input,labels)` erstellt ein PyTorch Dataset aus den Daten\n",
    "* `data.DataLoader(Dataset, batch_size)`  erstellt Minibatches der angegeben Größe aus einem Datensatz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=data.TensorDataset(train_images, train_labels) # input sind unsere Tensors die einmal die Bilder und einmal die Labels beinhalten\n",
    "loader = data.DataLoader(train_data, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875\n"
     ]
    }
   ],
   "source": [
    "print(len(loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Variable `loader` enthält nun 1875 Minibatches mit jeweils 32 Bilder und deren 32 Labels. In der nächsten Zelle, können Sie den Inhalt des ersten Batches sehen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " tensor([5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5, 3, 6, 1, 7, 2, 8, 6, 9, 4, 0, 9, 1,\n",
       "         1, 2, 4, 3, 2, 7, 3, 8])]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(loader)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um alles zusammen zu bringen, brauchen Sie einen zweiten `for-loop`, der innerhalb des ersten `for-loops` die Minibatches nach einander auswählt und durch das Netzwerk führt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.25 Training Accuracy: 0.96\n",
      "Training Loss: 0.09 Training Accuracy: 0.97\n"
     ]
    }
   ],
   "source": [
    "## Definieren des Netzwerkes,LossFunktion und Update Algorithmus\n",
    "netzwerk = nn.Sequential(nn.Linear(784,200), \n",
    "                         nn.ReLU(), \n",
    "                         nn.Linear(200,200),\n",
    "                         nn.ReLU(), \n",
    "                         nn.Linear(200,10))\n",
    "loss_funktion = nn.CrossEntropyLoss()\n",
    "updaten = optim.SGD(netzwerk.parameters(), lr=0.3)\n",
    "EPOCHS = 2\n",
    "\n",
    "## Trainings Loop\n",
    "for i in range(EPOCHS):\n",
    "    loss_list = [] # diese Liste speichter den Loss jedes Minibatches\n",
    "                   # damit können wir am Ende den Durschnittslost innerhalb des Epochs berechnen\n",
    "    for minibatch in loader: # for-loop geht durch alle minibatches\n",
    "        images, labels = minibatch # minibatch wird in Bilder und Labels geteilt\n",
    "        \n",
    "        updaten.zero_grad()\n",
    "        output = netzwerk(images) # Forward Propagation\n",
    "    \n",
    "        loss   = loss_funktion(output, labels)\n",
    "        loss.backward()\n",
    "        loss_list.append(loss.item())\n",
    "        updaten.step()\n",
    "        \n",
    "    output = netzwerk(train_images)\n",
    "    acc=((output.max(dim=1)[1]==train_labels).sum()/float(output.shape[0])).item()\n",
    "    print(\n",
    "        \"Training Loss: %.2f Training Accuracy: %.2f\"\n",
    "        % (np.mean(loss_list), acc)\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nach nur zwei Epochs ist die Accuracy viel niedriger als jemals zuvor. Dafür schicken wir noch einmal das ganze Dataset durch das Netzwerk und berechnen die Genauigkeit. Der einzelne Epoch dauert viel länger, aber die Trainingszeit verkürzt sich insgesamt.\n",
    "Um die Genauigkeit auszurchenen wird, nachdem all Minibatches durch das Netzwerk gegangen sind, noch einmal der ganze Datensatz durch das Netzwerk geschickt (ohne die Weights zu verändern) und die Genauigkeit berechnet. Der Epochloss ist der durchschnittliche Loss der Minibatches.\n",
    "\n",
    "Tipp: Wenn man den Wert eines Tensors und nicht den Tensor weitergebe will, kann man `tensor.item()` benutzen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aufgabe \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
