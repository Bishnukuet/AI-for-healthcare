{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"https://venturebeat.com/wp-content/uploads/2019/06/pytorch-e1576624094357.jpg?w=1200&strip=all\" style=\"width: 800px;\">\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch\n",
    "\n",
    "Letzte Woche haben Sie ein einfaches neuronales Netzwerk selber programmiert. Wie schon erwähnt, ist es aber nicht nötig jedes Netzwerk selber zu programmieren. Bestimmte Softwarepackete übernehmen viele der Unannehmlichkeiten, die beim Erstellen und Trainieren von Netzwerken auftreten.\n",
    "\n",
    "Grundsätzlich gibt es zwei Libraries, die benutzt werden können, PyTorch und TensorFlow. TensorFlow wird von Google entwickelt. TensorFlow ist die populärere Wahl, vor allem in der Industrie. PyTorch hingegen, hat sich vor allem in der wissenschaftlichen Welt durchgesetzt. Grundsätzlich gilt PyTorch als das leichter zu lernende Framework ist insgesamt benutzerfreundlicher. \n",
    "\n",
    "Während es früher noch große Unterschiede gab, werden die beiden Libraries heute immer ähnlicher in ihrer Funktionalität.\n",
    "\n",
    "Als Letztes gibt es noch Keras und PyTorch Lightning. Beide haben das Ziel das Erstellen von Neuronale Netzwerke noch einfach zu machen. Keras benutzt im Hintergrund TensorFlow, macht es aber vor allem Anfänger leichter Netzwerke zu trainieren. Dasselbe gilt für PyTorch Lightning und PyTorch.\n",
    "\n",
    "In der Chemieinformatik bietet sich aber PyTorch an, da es spezielle Libraries für Graph Neural Networks nur für PyTorch gibt/gegeben hat.\n",
    "\n",
    "\n",
    "Ein essenzieller Bestandteil von PyTorch ist **autograd**. Autograd ist eine Library, die, wie der Name erahnen lässt, die Gradienten automatisch berechnen und sammeln kann. Dadurch müssen die Ableitungen nicht mehr selber berechnen werden.\n",
    "Auch gibt es viele Funktionen, wie z. B. Activationfunctions oder lineare Transformationen, die schon in PyTorch implementiert sind. \n",
    "\n",
    "*TensorFlow hat diese Funktionalitäten natürlich auch.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors\n",
    "\n",
    "Während Sie bis jetzt mit NumPy Arrays gerechnet haben, benutzen wir heute `Tensors`, genauer gesagt PyTorch `tensors`. \n",
    "\n",
    "**Was ist der Unterschied?**\n",
    "\n",
    "Erst einmal keiner. Arrays und Tensors sind sich in vielen Punkten ähnlich. Beide speichern Zahlen/Werte in einer strukturierten Form. So können Sie in NumPy Matrizen in einem 2D-Array speichern, Sie können aber die gleich Matrix auch in einem 2D-Tensor speichern.\n",
    "Auch lassen sich Tensors in Arrays und Arrays in Tensors umwandeln.\n",
    "\n",
    "Der Unterschied zwischen den beiden „Speichermöglichkeiten“ ist, dass PyTorch Tensor von PyTorch entwickelt worden sind. Und NumPy Arrays wurden von den Entwicklern von NumPy entwickelt. \n",
    "Viele Funktionen, die NumPy bietet, gibt es auch von PyTorch für deren Tensors (heißen dann aber eventuell anders). \n",
    "PyTorch hat ihre Tensors entwickelt, um mathematische Operationen schneller durchführen zu können. Zudem kann man Tensors auch auf die Grafikkarte „laden“, was die Geschwindigkeit von Operation um ein Vielfaches verbessert."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit Tensors zu rechnen ist fast identisch zu Rechnung mit Arrays. Aber die Funktionen tragen eventuell andere Namen. `torch.mm()` ist zum Beispiel die Funktion für Matrixmultiplikation und `.t()` ist das Transpose einer Matrix. Ähnlich wie mit `np.array()` Arrays erstellt werden, so werden mit `torch.tensor()` Tensors erstellt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch # lädt PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  57,  976],\n",
       "        [ 138, 1984]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([[1,2,3],\n",
    "                [4,5,6]])\n",
    "\n",
    "W = torch.tensor([[8,9,10],\n",
    "                 [11,12,313]])\n",
    "\n",
    "b = torch.tensor([1,2])\n",
    "\n",
    "torch.mm(X,W.t())+b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das ist die lineare Transformation, die Sie auch schon kennen.<br>\n",
    "PyTorch vereinfacht diesen Schritt aber. \n",
    "So gibt es ein Modul in PyTorch mit dem Namen `nn`, diese enthält viele Funktionen, die hilfreich sind für das Erstellen von Neuronalen Netzwerken.\n",
    "\n",
    "Wir können das Module `nn` mit `from torch import nn` laden. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neuronales Netzwerk mit PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch `nn` stellt unter anderem die Funktion `nn.Linear` zur Verfügung. Diese führt die lineare Transformation $xW^T +b $ aus.\n",
    "Als Input nimmt die Funktion: \n",
    "* `in_features`  die Anzahl der Features, die der Input hat, vor der Transformation hat, oder auch die Größe der Input Layer. Gestern hatten die Bilder 784 Pixel, also 784 Features\n",
    "* `out_features`  wie viele Features der Input nach der Transformation haben soll. `out_features` legt also die Größe der Hidden Layer fest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_1=nn.Linear(in_features = 784, out_features=200, bias=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fehlt den nicht der Input für die Layer?\n",
    "\n",
    "Stimmt, bis jetzt haben Sie auch keine lineare Transformation durchgeführt, sondern nur eine Variable  `layer_1` erstellt. Diese kann dann die lineare Transformation für uns durchführen.\n",
    "Praktisch ist vor allem, dass die Weights dieser Transformation automatisch von PyTorch initialisiert werden. Das nimmt Ihnen schon ein wenig Arbeit ab.\n",
    "Die Weights $W$ dieser Layer können auch angeschaut werden.\n",
    "\n",
    "Dafür benutzen Sie `list(layer_1.parameters())[0]`\n",
    "Wenn Sie die genaue Größe der Weightmatrix in Erfahrung bringen wollen, können Sie wie bei NumPy `.shape` benutzen: `list(layer_1.parameters())[0].shape` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0310,  0.0229, -0.0257,  ..., -0.0160, -0.0056, -0.0040],\n",
       "        [-0.0286, -0.0035, -0.0241,  ...,  0.0262,  0.0008,  0.0012],\n",
       "        [-0.0062,  0.0013, -0.0058,  ...,  0.0001, -0.0265,  0.0290],\n",
       "        ...,\n",
       "        [ 0.0121,  0.0122, -0.0201,  ...,  0.0262, -0.0173,  0.0075],\n",
       "        [ 0.0052,  0.0053,  0.0166,  ..., -0.0269,  0.0094,  0.0091],\n",
       "        [-0.0024,  0.0179,  0.0120,  ..., -0.0181, -0.0220,  0.0267]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(layer_1.parameters())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([200, 784])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(layer_1.parameters())[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sie sehen, die Weightmatrix hat die gleichen Dimensionen wie die Matrix von letzter Woche. Sie können auch sehen, dass die Matrix tatsächlich Weights beinhaltet.\n",
    "Sie brauchen jetzt nur einen Input (Bilder), die Sie mit dieser linearen Transformation verändern wollen. \n",
    "Dazu wird der Trainingsdatensatz von letzter Woche mit NumPy geladen.\n",
    "Zusätzlich müssen die Bilder noch in einen Tensor umgewandelt werden. Das geht mit `torch.tensor()`\n",
    "\n",
    "Sie müssen natürlich auch wieder die Daten skalieren. Dafür benutzen Sie den Min-Max Scaler.\n",
    "In PyTorch muss genauer auf die Datentypen geachtet werden. \n",
    "Deswegen legen wir den Datentyp `dtype` festgelegt. Die Datenart für unsere Bilder ist `float32`. `float` kennt ihr noch von gestern, die `32` legt fest wie genau diese Zahl sein kann.\n",
    "`long` sagt Ihnen vielleicht nichts, ist aber einfach einer der `torch` Begriffe für Integers.\n",
    "\n",
    "\n",
    "\n",
    "<br>\n",
    "<details>\n",
    "<summary><strong>Besonders Interessierte HIER KLICKEN:</strong></summary>\n",
    "\n",
    "Im letzten Notebook wurde angeschnitten, warum wir die Weightmatrix genau so initialisieren.\n",
    "Tatsächlich werden in TensorFlow die Weightmatrizen so erstellt, dass eine Matrixmultiplikation auch ohne `transpose` auskommt.\n",
    "    \n",
    "Hier ist die Beschreibung des Codes für den Forwardpass von Tensorflow.\n",
    "    \n",
    "    \n",
    "```python\n",
    "  `Dense` implements the operation:\n",
    "  `output = activation(dot(input, kernel) + bias)`\n",
    "  where `activation` is the element-wise activation function\n",
    "  passed as the `activation` argument, `kernel` is a weights matrix\n",
    "  created by the layer, and `bias` is a bias vector created by the layer\n",
    "  (only applicable if `use_bias` is `True`). These are all attributes of\n",
    "  `Dense`.\n",
    "```\n",
    "Für PyTorch ist diese [hier](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html) zu finden.\n",
    "    \n",
    "PyTorch übernimmt hier die Notation, die eine größere Ähnlichkeit zu der mathematischen Notation hat.\n",
    "\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 784])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "def min_max(x):\n",
    "    return (x - np.min(x)) / (np.max(x) - np.min(x))\n",
    "\n",
    "\n",
    "train_data = np.genfromtxt('../data/mnist/mnist_train.csv', delimiter=',', skip_header =False) #genfromtxt reads .txt files if we chose delimiter =\",\" the function can read also .csv files  (comma seperated values)\n",
    "\n",
    "train_images = min_max(train_data[:,1:])\n",
    "train_images = torch.tensor(train_images, dtype = torch.float32)\n",
    "train_labels=torch.tensor(train_data[:,0].astype(int), dtype = torch.long) \n",
    "\n",
    "train_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Datensatz umfasst 60000 Bilder mit jeweils 784 Pixeln.\n",
    "Diese können Sie jetzt als Input für die lineare Transformation benutzen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0928,  0.4636,  0.2488,  ..., -0.0703, -0.1776,  0.1341],\n",
      "        [ 0.1657,  0.1012, -0.1248,  ..., -0.5124,  0.0401,  0.1205],\n",
      "        [-0.0559,  0.1749,  0.0677,  ..., -0.1446,  0.1145, -0.0859],\n",
      "        ...,\n",
      "        [ 0.0507,  0.3522,  0.1234,  ..., -0.1301,  0.1683, -0.0620],\n",
      "        [ 0.1776,  0.3217,  0.0355,  ..., -0.1141,  0.0513,  0.1434],\n",
      "        [ 0.0281,  0.1119,  0.0771,  ..., -0.2499, -0.1876,  0.0880]],\n",
      "       grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 200])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_1=layer_1(train_images)\n",
    "print(z_1)\n",
    "z_1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die `layer_1` gibt den Output (`z_1`) aus. Dieser hat die `shape` `[60000,200]`. Also immer noch 60000 Bilder, aber diesmal hat jedes nur jeweils 200 Features (Größe der Hidden Layer). So wie es auch bei der Definition der `layer_1` bestimmt wurde.\n",
    "\n",
    "Was Ihnen auffallen sollte, am Ende des Tensors `z_1` steht `grad_fn=<AddmmBackward>`. Dies zeigt an, dass ***autograd** die Gradienten für diese Transformation erfasst hat. Wenn man will, kann man auch erkennen, dass wir eine Matrixmultiplikation `mm` und eine Addition `Add` durchgeführt haben.\n",
    "\n",
    "Was Ihnen jetzt noch fehlt, ist die Activationfunction. Auch hier kann PyTorch helfen. \n",
    "PyTorchs `nn`Library hat ein Submodul `functional`. Hier sind viele zusätzliche mathematische Funktionen enthalten, unter anderem auch die `relu` Funktion.\n",
    "`functional` lässt sich wie folgt importieren: `from torch.nn import functional as F`. Wir nennen `functional` zu `F` um, quasi eine Norm, wenn man mit PyTorch arbeitet.\n",
    "\n",
    "`F.relu()` kann jetzt benutzt werden um die ReLU Funktion anzuwenden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0928, 0.4636, 0.2488,  ..., 0.0000, 0.0000, 0.1341],\n",
      "        [0.1657, 0.1012, 0.0000,  ..., 0.0000, 0.0401, 0.1205],\n",
      "        [0.0000, 0.1749, 0.0677,  ..., 0.0000, 0.1145, 0.0000],\n",
      "        ...,\n",
      "        [0.0507, 0.3522, 0.1234,  ..., 0.0000, 0.1683, 0.0000],\n",
      "        [0.1776, 0.3217, 0.0355,  ..., 0.0000, 0.0513, 0.1434],\n",
      "        [0.0281, 0.1119, 0.0771,  ..., 0.0000, 0.0000, 0.0880]],\n",
      "       grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import functional as F\n",
    "\n",
    "a_1 = F.relu(z_1)\n",
    "print(a_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wenn Sie `a_1` mit `z_1` vergleichen können Sie sehen, dass alle Werte die vorher negative waren Null wurden und alle Werte die positive waren unverändert sind.\n",
    "Auch kann man im `grad fn` sehen, dass eine ReLU angewandt wurde. Also auch das hat *autograd* mit aufgezeichnet. \n",
    "\n",
    "Der erste Teil der Forwardpropagation ist geschafft. \n",
    "Für den zweiten Schritt können wir einfach eine weitere Layer erstellen, die `a_1` als Input nimmt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_2 = nn.Linear(200,10) # 10 ist die Anzahl der out_features, da wir 10 Ziffern haben.\n",
    "z_2=layer_2(a_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auch hier brauchen Sie wieder eine Activationfunction. Diesmal aber die `softmax`-Funktion um die Wahrscheinlichkeiten zu erhalten.\n",
    "`nn.functional` hat auch eine `softmax()` Funktion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = F.softmax(z_2,dim=1) # die dim Funktion legt fest ob über Spalten oder Reihen die Softmax funktion angewandt wird."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In PyTorch kann man auch verschiedene Layers zusammenfassen. Mit `nn.Sequential` können Sie die lineare Transformation und Activationfunction direkt hintereinander schalten. Der Input wird automatisch durch jede der Layers weitergeleitet.\n",
    "Das macht Ihren Code übersichtlicher und einfacher zu schreiben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=784, out_features=200, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=200, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netzwerk = nn.Sequential(nn.Linear(784,200), \n",
    "                         nn.ReLU(), \n",
    "                         nn.Linear(200,10))\n",
    "netzwerk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie Sie sehen können, wurde ein Netzwerk mit einer Hiddenlayer erstellt. Was Ihnen ausfallen sollte ist, dass anstatt `F.relu` `nn.ReLU` benutzt wurde. Wenn eine `relu` Funktion innerhalb von `Sequential()` benutzt werden soll, müssen Sie immer `nn.ReLU` benutzen. \n",
    "\n",
    "Das `netzwerk` könnte nun die Bilder klassifizieren:\n",
    "Mit `netzwerk(input)` kann der Input z. B. unsere Bilder durch das Netzwerk geführt werden.\n",
    "Anhand der Tensorgröße des Outputs können Sie sehen, dass tatsächlich am Ende 60000 Bilder mit jeweils 10 Features (den 10 Ziffern bekommen) als Output herausgegeben werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 10])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output=netzwerk(train_images)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eine weitere Veränderung ist, dass Sie nicht mehr die letzte Activationfunktion benutzt haben. PyTorch wählt die Activationfunktion automatisch. Die Entscheidung welche Activationfunction in der letzten Layer benutzt werden soll hängt von der Wahl der Lossfunktion ab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Funktion\n",
    "\n",
    "Auch mit der Lossfunktion kann `nn` helfen. Die häufigsten Lossfunktionen sind nämlich schon in PyTorch enthalten.\n",
    "Sie können einfach eine neue Variable erstellen und dieser die `nn.CrossEntropyLoss()` Funktion zuordnen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_funktion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`loss_funktion` kann nun den Loss berechnen und wendet dabei automatisch die Softmax-Funktion an.\n",
    "Dazu müssen Sie einfach nur `y_hat` und die `train_labels` in die Funktion geben. Hier zeigt sich ein weiterer Vorteil, Sie brauchen die Labels nicht noch `one-hot` codieren, auch das macht PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3013, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss=loss_funktion(output, train_labels)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back Propagation\n",
    "\n",
    "Als letzten Schritt müssen Sie noch die Back Propagation durchführen. Dank *autograd* geht das einfach mit dem Befehl `loss.backward()`. Dieser berechnet die Gradienten für alle Weightmatrizen.\n",
    "\n",
    "Danach müssen die Weightmatrizen nur noch geupdated werden. Wie Sie sich denken können, nimmt Ihnen auch der PyTorch ab.\n",
    "PyTorch stellt sogar eine Vielzahl von Algorithmen zu Verfügung. Viele dieser funktionieren besser als der einfache Gradient Descent.\n",
    "Für das Updaten der Weights wird ein neues Modul von PyTorch benötigt.\n",
    "Dafür laden Sie `from torch import optim`. `optim` enthält Optimizer, also Funktionen, die für uns das Netzwerk optimieren - die Weights updaten.\n",
    "\n",
    "Ähnlich wie bei der Loss Funktion, können Sie auch hier einfach eine Variable erstellen und ihr Updatefunktion zuordnen. \n",
    "Sie können jetzt den `optim.SGD()` zum updaten benutzen. SGD = Stochastic Gradient Descent.  In der Funktion selber definieren Sie, welche Parameter (Weights) verändert werden sollen. Auch legen Sie hier die Lernrate fest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward() #sammelt die Gradienten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "weights_updaten=optim.SGD(netzwerk.parameters(), lr=0.01) # Sie legen fest welche Parameter und mit welche Lernrate diese verändert werden sollen\n",
    "\n",
    "weights_updaten.step() # mit- step() verändert Sie ein die Weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetzt haben Sie alles, was man für ein Netzwerk braucht.\n",
    "\n",
    "Sie können wieder einen for-loop benutzen, um das Training zu automatisieren.\n",
    "\n",
    "Es fällt euch eventuell auf, dass wir noch `updaten.zero_grad()` benutzen. Diese Funktion wird benutzt, um die gesammelten Gradienten zu löschen. Wird das nicht gemacht, so würde der Optimizer alle Gradienten aus allen Epochs zusammen zählen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 2.30 Training Accuracy: 0.15\n",
      "Training Loss: 2.24 Training Accuracy: 0.22\n",
      "Training Loss: 2.18 Training Accuracy: 0.33\n",
      "Training Loss: 2.12 Training Accuracy: 0.48\n",
      "Training Loss: 2.05 Training Accuracy: 0.59\n",
      "Training Loss: 1.97 Training Accuracy: 0.65\n",
      "Training Loss: 1.89 Training Accuracy: 0.70\n",
      "Training Loss: 1.79 Training Accuracy: 0.72\n",
      "Training Loss: 1.70 Training Accuracy: 0.74\n",
      "Training Loss: 1.60 Training Accuracy: 0.75\n",
      "Training Loss: 1.50 Training Accuracy: 0.77\n",
      "Training Loss: 1.40 Training Accuracy: 0.78\n",
      "Training Loss: 1.31 Training Accuracy: 0.79\n",
      "Training Loss: 1.23 Training Accuracy: 0.79\n",
      "Training Loss: 1.15 Training Accuracy: 0.80\n",
      "Training Loss: 1.08 Training Accuracy: 0.81\n",
      "Training Loss: 1.02 Training Accuracy: 0.81\n",
      "Training Loss: 0.96 Training Accuracy: 0.82\n",
      "Training Loss: 0.92 Training Accuracy: 0.82\n",
      "Training Loss: 0.87 Training Accuracy: 0.83\n",
      "Training Loss: 0.84 Training Accuracy: 0.83\n",
      "Training Loss: 0.80 Training Accuracy: 0.84\n",
      "Training Loss: 0.77 Training Accuracy: 0.84\n",
      "Training Loss: 0.75 Training Accuracy: 0.84\n",
      "Training Loss: 0.72 Training Accuracy: 0.85\n",
      "Training Loss: 0.70 Training Accuracy: 0.85\n",
      "Training Loss: 0.68 Training Accuracy: 0.85\n",
      "Training Loss: 0.66 Training Accuracy: 0.85\n",
      "Training Loss: 0.64 Training Accuracy: 0.85\n",
      "Training Loss: 0.63 Training Accuracy: 0.86\n",
      "Training Loss: 0.61 Training Accuracy: 0.86\n",
      "Training Loss: 0.60 Training Accuracy: 0.86\n",
      "Training Loss: 0.59 Training Accuracy: 0.86\n",
      "Training Loss: 0.58 Training Accuracy: 0.86\n",
      "Training Loss: 0.57 Training Accuracy: 0.86\n",
      "Training Loss: 0.56 Training Accuracy: 0.87\n",
      "Training Loss: 0.55 Training Accuracy: 0.87\n",
      "Training Loss: 0.54 Training Accuracy: 0.87\n",
      "Training Loss: 0.53 Training Accuracy: 0.87\n",
      "Training Loss: 0.52 Training Accuracy: 0.87\n",
      "Training Loss: 0.52 Training Accuracy: 0.87\n",
      "Training Loss: 0.51 Training Accuracy: 0.87\n",
      "Training Loss: 0.50 Training Accuracy: 0.87\n",
      "Training Loss: 0.50 Training Accuracy: 0.88\n",
      "Training Loss: 0.49 Training Accuracy: 0.88\n",
      "Training Loss: 0.49 Training Accuracy: 0.88\n",
      "Training Loss: 0.48 Training Accuracy: 0.88\n",
      "Training Loss: 0.48 Training Accuracy: 0.88\n",
      "Training Loss: 0.47 Training Accuracy: 0.88\n",
      "Training Loss: 0.47 Training Accuracy: 0.88\n"
     ]
    }
   ],
   "source": [
    "## Definieren des Netzwerkes,LossFunktion und Update Algorithmus\n",
    "netzwerk = nn.Sequential(nn.Linear(784,200), \n",
    "                         nn.ReLU(), \n",
    "                         nn.Linear(200,10))\n",
    "\n",
    "loss_funktion = nn.CrossEntropyLoss()\n",
    "updaten = optim.SGD(netzwerk.parameters(), lr=0.3)\n",
    "EPOCHS = 50\n",
    "\n",
    "## Trainings Loop\n",
    "for i in range(50):\n",
    "    updaten.zero_grad()\n",
    "    output = netzwerk(train_images) # Forward Propagation\n",
    "    \n",
    "    loss   = loss_funktion(output, train_labels)\n",
    "    loss.backward()\n",
    "    acc=((output.max(dim=1)[1]==train_labels).sum()/float(output.shape[0])).item()\n",
    "    print(\n",
    "        \"Training Loss: %.2f Training Accuracy: %.2f\"\n",
    "        % (loss.item(), acc)\n",
    "    )\n",
    "    \n",
    "    updaten.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sie können sehen, dass Sie mit viel weniger Aufwand ein neuronales Netzwerk trainieren können. Sie können auch ohne großen Aufwand ein zweite oder dritte Hiddenlayer zu Ihrem Model hinzufügen.\n",
    "Einfach eine `nn.ReLU` und eine `nn.Linear` Layer in `Sequential` hinzufügen und **autograd** kann auch für diese Layer die Gradienten berechnen. Alles andere bleibt gleich. Denken Sie nur daran, dass die Dimensionen von einer zu nächsten Layer passen müssen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=784, out_features=200, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=200, out_features=200, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=200, out_features=10, bias=True)\n",
      ")\n",
      "Training Loss: 2.30 Training Accuracy: 0.10\n",
      "Training Loss: 2.29 Training Accuracy: 0.15\n",
      "Training Loss: 2.28 Training Accuracy: 0.24\n",
      "Training Loss: 2.27 Training Accuracy: 0.31\n",
      "Training Loss: 2.26 Training Accuracy: 0.34\n",
      "Training Loss: 2.24 Training Accuracy: 0.37\n",
      "Training Loss: 2.23 Training Accuracy: 0.41\n",
      "Training Loss: 2.21 Training Accuracy: 0.46\n",
      "Training Loss: 2.19 Training Accuracy: 0.51\n",
      "Training Loss: 2.17 Training Accuracy: 0.57\n",
      "Training Loss: 2.14 Training Accuracy: 0.61\n",
      "Training Loss: 2.10 Training Accuracy: 0.64\n",
      "Training Loss: 2.06 Training Accuracy: 0.67\n",
      "Training Loss: 2.01 Training Accuracy: 0.68\n",
      "Training Loss: 1.96 Training Accuracy: 0.69\n",
      "Training Loss: 1.89 Training Accuracy: 0.69\n",
      "Training Loss: 1.81 Training Accuracy: 0.70\n",
      "Training Loss: 1.73 Training Accuracy: 0.71\n",
      "Training Loss: 1.64 Training Accuracy: 0.72\n",
      "Training Loss: 1.54 Training Accuracy: 0.72\n",
      "Training Loss: 1.44 Training Accuracy: 0.73\n",
      "Training Loss: 1.34 Training Accuracy: 0.73\n",
      "Training Loss: 1.25 Training Accuracy: 0.74\n",
      "Training Loss: 1.17 Training Accuracy: 0.75\n",
      "Training Loss: 1.09 Training Accuracy: 0.76\n",
      "Training Loss: 1.03 Training Accuracy: 0.77\n",
      "Training Loss: 0.97 Training Accuracy: 0.78\n",
      "Training Loss: 0.92 Training Accuracy: 0.78\n",
      "Training Loss: 0.87 Training Accuracy: 0.79\n",
      "Training Loss: 0.83 Training Accuracy: 0.80\n",
      "Training Loss: 0.80 Training Accuracy: 0.80\n",
      "Training Loss: 0.77 Training Accuracy: 0.81\n",
      "Training Loss: 0.75 Training Accuracy: 0.81\n",
      "Training Loss: 0.78 Training Accuracy: 0.75\n",
      "Training Loss: 1.20 Training Accuracy: 0.61\n",
      "Training Loss: 2.04 Training Accuracy: 0.43\n",
      "Training Loss: 1.64 Training Accuracy: 0.51\n",
      "Training Loss: 1.25 Training Accuracy: 0.62\n",
      "Training Loss: 1.06 Training Accuracy: 0.65\n",
      "Training Loss: 0.84 Training Accuracy: 0.77\n",
      "Training Loss: 0.75 Training Accuracy: 0.82\n",
      "Training Loss: 0.69 Training Accuracy: 0.82\n",
      "Training Loss: 0.66 Training Accuracy: 0.83\n",
      "Training Loss: 0.63 Training Accuracy: 0.83\n",
      "Training Loss: 0.61 Training Accuracy: 0.84\n",
      "Training Loss: 0.59 Training Accuracy: 0.84\n",
      "Training Loss: 0.58 Training Accuracy: 0.84\n",
      "Training Loss: 0.57 Training Accuracy: 0.83\n",
      "Training Loss: 0.58 Training Accuracy: 0.83\n",
      "Training Loss: 0.62 Training Accuracy: 0.78\n"
     ]
    }
   ],
   "source": [
    "## Definieren Sie das Netzwerk, Loss Funktion und Update Algorithmus\n",
    "netzwerk = nn.Sequential(nn.Linear(784,200), \n",
    "                         nn.ReLU(), \n",
    "                         nn.Linear(200,200),\n",
    "                         nn.ReLU(), \n",
    "                         nn.Linear(200,10))\n",
    "print(netzwerk)\n",
    "loss_funktion = nn.CrossEntropyLoss()\n",
    "updaten = optim.SGD(netzwerk.parameters(), lr=0.3)\n",
    "EPOCHS = 50\n",
    "\n",
    "## Trainings Loop\n",
    "for i in range(50):\n",
    "    updaten.zero_grad()\n",
    "    output = netzwerk(train_images) # Forward Propagation\n",
    "    \n",
    "    loss   = loss_funktion(output, train_labels)\n",
    "    loss.backward()\n",
    "    \n",
    "    acc=((output.max(dim=1)[1]==train_labels).sum()/float(output.shape[0])).item()\n",
    "    print(\n",
    "        \"Training Loss: %.2f Training Accuracy: %.2f\"\n",
    "        % (loss.item(), acc)\n",
    "    )\n",
    "    \n",
    "    updaten.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sie haben vielleicht schon gemerkt, dass wir als Optimizer (Weights updaten) den Stochastic Gradient Descent benutzen. Gestern wurde nur von dem Gradient Descent gesprochen.\n",
    "Tatsächlich wird der Gradient Descent, so wie gestern erklärt eigentlich nicht mehr benutzt, sondern als Alternative der Stochastic Gradient Descent. \n",
    "\n",
    "Der Unterschied:<br>\n",
    "Im Stochastic Gradient Descent wird der Datensatz nicht auf einmal durch das Netz geschickt, sondern der Datensatz wird in kleineren Teilen (**minibatch**) durch das Netzwerk gebracht. <br>\n",
    "In diesem Datensatz gibt es insgesamt 60000 Bilder. Beim Gradient Descent, werden wird der Forwardpass mit 60000 Bilder berechnet, für die 60000 Bilder der Loss berechnet. Danach werden die Bilder einmal upgedatet.\n",
    "Dann wiederholt sich der Schritt. \n",
    "\n",
    "Es wäre doch effizienter, wenn nicht erst nach allen 60000 Bilder ein Update passiert. Sondern schon nach 200 oder auch nur 100.  Dadurch kann das Netzwerk viel schneller lernen\n",
    "Genau das macht Stochastic Gradient Descent.  Nicht alle Bilder, sondern nur z. B. 32 Bilder werden auf einmal durch das Netzwerk geschickt. Für diese 32 wird dann der Loss berechnet und die Updates durchgeführt.\n",
    "Dann wird das wiederholt, aber diesmal mit 32 neuen Bilder. So können innerhalb eines Epochs viel öfter die Weights upgedatet werden.\n",
    "Die Batchsize gibt an, wie groß ein Minibatch (der kleine Teil der Daten, der durchs Netzwerk geht) sein soll und kann auch die Performance des Models beeinflussen.\n",
    "<center>\n",
    "<img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcT0TVrYkk0A0FfPvnzYTe747F0qPLG2rU2Bmg&usqp=CAU\" style=\"width: 600px;\">\n",
    "</center>\n",
    "<h8><center>Source: Insu Han and Jongheon Jeong, http://alinlab.kaist.ac.kr/resource/Lec2_SGD.pdf</center></h8>\n",
    "\n",
    "\n",
    "Vorteile:<br>\n",
    "* schneller\n",
    "* braucht weniger Speicherplatz (auf der Graphikkarte)\n",
    "\n",
    "Nachteile: <br>\n",
    "* kann nicht das Optimum finden (kann aber auch gut sein, um overfitting zu verhindern)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um Minibatches aus den Daten zu machen, können Sie auch PyTorch benutzen. Dafür gibt es ein weiteres Submodule `torch.utils.data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `torch.utils.data` gibt es zwei Funktionen, die Sie brauchen:\n",
    "\n",
    "* `data.TensorDataset(input,labels)` erstellt ein PyTorch Dataset aus den Daten\n",
    "* `data.DataLoader(Dataset, batch_size)`  erstellt Minibatches der angegebenen Größe aus einem Datensatz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=data.TensorDataset(train_images, train_labels) # input sind unsere Tensors die einmal die Bilder und einmal die Labels beinhalten\n",
    "loader = data.DataLoader(train_data, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875\n"
     ]
    }
   ],
   "source": [
    "print(len(loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Variable `loader` enthält nun 1875 Minibatches mit jeweils 32 Bilder und deren 32 Labels. In der nächsten Zelle können Sie den Inhalt des ersten Batches sehen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " tensor([5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5, 3, 6, 1, 7, 2, 8, 6, 9, 4, 0, 9, 1,\n",
       "         1, 2, 4, 3, 2, 7, 3, 8])]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(loader)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um alles zusammenzubringen, brauchen Sie einen zweiten `for-loop`, der innerhalb des ersten `for-loops` die Minibatches nach einander auswählt und durch das Netzwerk führt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.25 Training Accuracy: 0.96\n",
      "Training Loss: 0.10 Training Accuracy: 0.98\n"
     ]
    }
   ],
   "source": [
    "## Definieren des Netzwerkes,LossFunktion und Update Algorithmus\n",
    "netzwerk = nn.Sequential(nn.Linear(784,200), \n",
    "                         nn.ReLU(), \n",
    "                         nn.Linear(200,200),\n",
    "                         nn.ReLU(), \n",
    "                         nn.Linear(200,10))\n",
    "loss_funktion = nn.CrossEntropyLoss()\n",
    "updaten = optim.SGD(netzwerk.parameters(), lr=0.3)\n",
    "EPOCHS = 2\n",
    "\n",
    "## Trainings Loop\n",
    "for i in range(EPOCHS):\n",
    "    loss_list = [] # diese Liste speichter den Loss jedes Minibatches\n",
    "                   # damit können wir am Ende den Durschnittslost innerhalb des Epochs berechnen\n",
    "    for minibatch in loader: # for-loop geht durch alle minibatches\n",
    "        images, labels = minibatch # minibatch wird in Bilder und Labels geteilt\n",
    "        \n",
    "        updaten.zero_grad()\n",
    "        output = netzwerk(images) # Forward Propagation\n",
    "    \n",
    "        loss   = loss_funktion(output, labels)\n",
    "        loss.backward()\n",
    "        loss_list.append(loss.item())\n",
    "        updaten.step()\n",
    "        \n",
    "    output = netzwerk(train_images)\n",
    "    acc=((output.max(dim=1)[1]==train_labels).sum()/float(output.shape[0])).item()\n",
    "    print(\n",
    "        \"Training Loss: %.2f Training Accuracy: %.2f\"\n",
    "        % (np.mean(loss_list), acc)\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nach nur zwei Epochs ist die Accuracy viel niedriger als jemals zuvor. Dafür schicken wir noch einmal das ganze Dataset durch das Netzwerk und berechnen die Genauigkeit. Der einzelne Epoch dauert viel länger, aber die Trainingszeit verkürzt sich insgesamt.\n",
    "Um die Genauigkeit auszurechnen wird, nachdem all Minibatches durch das Netzwerk gegangen sind, noch einmal der ganze Datensatz durch das Netzwerk geschickt (ohne die Weights zu verändern) und die Genauigkeit berechnet. Der Epochloss ist der durchschnittliche Loss der Minibatches.\n",
    "\n",
    "Tipp: Wenn man den Wert eines Tensors und nicht den Tensor weitergeben will, kann man `tensor.item()` benutzen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Übungsaufgabe\n",
    "\n",
    "Für die Übungsaufgabe werden Sie ein Netzwerk trainieren, diesmal aber mit den Toxizitätsdaten aus Woche 5.\n",
    "Zunächst laden Sie wieder alle notwendigen Libraries und Daten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "%run ../utils/utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OC(=O)[C@H](O)[C@@H](O)[C@H](O)C(=O)CO</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C[C@]12CC[C@H]3[C@@H](CCc4cc(O)ccc43)[C@@H]1CC...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CC(C)(C)c1cc(O)ccc1O</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CN(C)c1ccc(cc1)C(c1ccccc1)=C1C=CC(C=C1)=[N+](C)C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NC(Cc1ccccc1)C(O)=O</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              smiles  activity\n",
       "0             OC(=O)[C@H](O)[C@@H](O)[C@H](O)C(=O)CO         0\n",
       "1  C[C@]12CC[C@H]3[C@@H](CCc4cc(O)ccc43)[C@@H]1CC...         1\n",
       "2                               CC(C)(C)c1cc(O)ccc1O         1\n",
       "3   CN(C)c1ccc(cc1)C(c1ccccc1)=C1C=CC(C=C1)=[N+](C)C         1\n",
       "4                                NC(Cc1ccccc1)C(O)=O         0"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tox = pd.read_csv(\"../data/toxicity/sr-mmp.tab\", sep = \"\\t\")\n",
    "data_tox = data_tox.iloc[:,1:] #alle Spalten bis auf die erste (index 0) werden ausgewählt\n",
    "data_tox.columns = [\"smiles\", \"activity\"]\n",
    "data_tox.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als Nächstes berechnen Sie die Fingerprints. Dafür steht ihnen wie in Woche 05 die Funktion `get_fingerprints` zur Verfügung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 2246/2246 [00:02<00:00, 750.66it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2039</th>\n",
       "      <th>2040</th>\n",
       "      <th>2041</th>\n",
       "      <th>2042</th>\n",
       "      <th>2043</th>\n",
       "      <th>2044</th>\n",
       "      <th>2045</th>\n",
       "      <th>2046</th>\n",
       "      <th>2047</th>\n",
       "      <th>activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2049 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4  5  6  7  8  9  ...  2039  2040  2041  2042  2043  2044  \\\n",
       "0  0  1  0  0  0  0  0  0  0  0  ...     0     0     0     0     0     0   \n",
       "1  0  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0     0   \n",
       "2  0  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0     0   \n",
       "3  0  0  0  0  0  0  0  0  0  1  ...     0     1     0     0     0     0   \n",
       "4  0  1  0  0  0  0  0  0  0  0  ...     0     0     0     0     0     0   \n",
       "\n",
       "   2045  2046  2047  activity  \n",
       "0     0     0     0         0  \n",
       "1     0     0     0         1  \n",
       "2     0     0     0         1  \n",
       "3     0     0     0         1  \n",
       "4     0     0     0         0  \n",
       "\n",
       "[5 rows x 2049 columns]"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fps = get_fingerprints(data_tox)\n",
    "fps[\"activity\"] = data_tox.activity\n",
    "fps.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bevor Sie diese in Pytorch verwenden können, müssen Sie die sowohl die Fingerprints als auch die `acitivity` in `tensors` umwandeln. Beachten Sie, dass beide im DataFrame `fps` sind. \n",
    "\n",
    "`.values` konvertiert einen Datenframe in ein `np.array`.\n",
    "\n",
    "Danach teilen Sie die Daten in Training und Testset auf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "fps = torch.tensor(_______.values, dtype=torch.float32) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test=train_test_split(______,test_size= 0.2 , train_size= 0.8, random_state=1234)\n",
    "\n",
    "\n",
    "train_x = train[__________]\n",
    "train_y = train[__________]\n",
    "test_x = test[__________]\n",
    "test_y = test[__________]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auch jetzt wollen wir wieder Minibatches benutzten. Deswegen müssen wir unsere Trainingsdaten noch in zu einem `DataLoader` konvertieren. Warum nur die Trainingsdaten? Das Benutzen von Batches ist erst einmal nur relevant für das Training. Solange ihr Computer fähig ist den Testdatensatz auf einmal durch das Netzwerk zu führen, müssen wir den Testdatensatz nicht in Batches unterteilen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=data.TensorDataset(______, _____) # input sind unsere Tensors die einmal die Fingerprints die activities\n",
    "loader=DataLoader(train_data, batch_size = 32)\n",
    "len(loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passen Sie das Netzwerk so an, dass der Input und Output die richtige Größe haben. Also die Länge der Fingerprints und die Anzahl der Klassen, die wir vorhersagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "netzwerk = nn.Sequential(nn.Linear(____,200), \n",
    "                         nn.ReLU(), \n",
    "                         nn.Linear(200,200),\n",
    "                         nn.ReLU(), \n",
    "                         nn.Linear(200,___))\n",
    "\n",
    "loss_funktion = nn.BCEWithLogitsLoss()\n",
    "updaten = optim.SGD(netzwerk.parameters(), lr=0.1)    \n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als letztes füllen Sie den `for loop`. \n",
    "\n",
    "`.squeeze` konvertiert den `(n,1)` `output` tensor zu einem 1-dimensionalen Tensor der Länge `n`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Target size (torch.Size([32])) must be the same as input size (torch.Size([32, 2]))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_393743/865560931.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetzwerk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Forward Propagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mloss\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mloss_funktion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mloss_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/intro_ki/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/intro_ki/lib/python3.7/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    714\u001b[0m                                                   \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m                                                   \u001b[0mpos_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m                                                   reduction=self.reduction)\n\u001b[0m\u001b[1;32m    717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/intro_ki/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[0;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[1;32m   2956\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2957\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2958\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Target size ({}) must be the same as input size ({})\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2960\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_enum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Target size (torch.Size([32])) must be the same as input size (torch.Size([32, 2]))"
     ]
    }
   ],
   "source": [
    "for i in range(EPOCHS):\n",
    "    loss_list = [] # diese Liste speichter den Loss jedes Minibatches\n",
    "    for minibatch in loader: # for-loop geht durch alle minibatches\n",
    "        updaten.__________\n",
    "        molecules, activity = minibatch # minibatch wird in Bilder und Labels geteilt\n",
    "        output = netzwerk(____________) # Forward Propagation\n",
    "        loss   = loss_funktion(output.squeeze(), ____________)\n",
    "        loss._______\n",
    "        loss_list.append(loss.item())\n",
    "        updaten.________\n",
    "    # Hier wird die Accuracy für den Testsatz berechnet\n",
    "    output = netzwerk(test_x)\n",
    "    acc = torch.sum((output>0).squeeze().int() == test_y)/test_y.shape[0]\n",
    "   \n",
    "    print(\n",
    "        \"Training Loss: %.2f Test Accuracy: %.2f\"\n",
    "        % (np.mean(loss_list), acc.item())\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
