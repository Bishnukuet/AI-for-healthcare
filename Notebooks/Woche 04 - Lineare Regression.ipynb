{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43ad762c",
   "metadata": {},
   "source": [
    "# Einführung Statistik\n",
    "\n",
    "Wir werden heute ein paar wenige Grundlagen zur Statistik anschauen.\n",
    "Statistik kann uns helfen Daten einfach zu beschreiben und erklären. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3d56e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import shuffle\n",
    "%matplotlib inline\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95dae544",
   "metadata": {},
   "source": [
    "Wir können uns zum Beispiel die Abinoten einer bestimmten Klasse anschauen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31b5fc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "abi_klasse = [1.64, 2.35, 1.88, 2.48, 2.16, 3.92, 2.16, 2.  , 1.76, 2.82, 1.81,\n",
    "       2.59, 3.03, 1.7 , 2.87, 3.21, 2.65, 1.97, 1.2, 1.67, 1.77, 1.98,\n",
    "       3.4 , 1.31, 1.72, 2.05, 1.12 , 1.56, 2.01, 2.1 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc5282b",
   "metadata": {},
   "source": [
    "Allerdings ist es sehr schwer nur mit Hilfe der Daten eine Übersicht zubekommen.\n",
    "Einfacher ist es sich die Noten aufzuzeichnen.\n",
    "\n",
    "\n",
    "<img src='Img/intro_stats/noten_1.png'></img>\n",
    "\n",
    "Obwohl Sie jetzt eine bessere gesamt Übersicht haben, könnte es Ihnen schwerfallen zwei Klassen miteinander zu vergleichen.\n",
    "\n",
    "<img src='Img/intro_stats/noten2.1.png'></img>\n",
    "\n",
    "Wir können **density plots** benutzen um die Verteilung einfach Darstellen. Hier wird die y-Achse benutzt, um die Dicht darzustellen. Das heißt je höher der Graph an einem Punkt ist, desto mehr der Datenpunkte befinden sich an dieser Stelle. \n",
    "\n",
    "<img src='Img/intro_stats/noten_3.1.png'></img>\n",
    "Oft reicht eine rein visuelle Inspektion nicht, um eindeutige Entscheidungen zu treffen.\n",
    "Hierfür werden Metriken benötigt, die die Verteilung von Datenpunkten, wie die Abinoten, beschreiben.\n",
    "\n",
    "Am wohl bekanntesten ist der Mittelwert, genauer gesagt das arithmetische Mittel. Es beschreibt den Durchschnitt einer Verteilung von Datenpunkten. \n",
    "Und das arithmetische Mittel zu berechnen wird die Summe aller Werte durch die Anzahl der Werte geteilt.\n",
    "\n",
    "\n",
    "$$\\bar{x} = \\frac{1}{n}\\sum_{i=1}^n x_i$$\n",
    "\n",
    "Der Mittelwert wird oft durch $\\bar{x}$ gekennzeichnet.\n",
    "Berechnen Sie das arithmetische Mittel in Python für die Klasse aus. *Ohne dabei Numpy zu benutzen*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cfb33180",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '_____________' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2472832/2113897170.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmean_abiklasse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_____________\u001b[0m\u001b[0;31m# Formel für den Mittelwert\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name '_____________' is not defined"
     ]
    }
   ],
   "source": [
    "mean_abiklasse = _____________# Formel für den Mittelwert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9722056c",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Lösung:</b></summary>\n",
    "    \n",
    "```python \n",
    "mean_abiklasse = sum(abi_klasse)/len(abi_klasse)\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5308a73",
   "metadata": {},
   "source": [
    "Doch der Mittelwert reicht nicht, um eine Verteilung von Werten adäquate zu beschrieben. Zum Beispiel, haben die beiden [Normal Verteilungen](https://de.statista.com/statistik/lexikon/definition/95/normalverteilung/) im Beispiel den gleichen Mittelwert und trotzdem sind Sie nicht identisch verteilt. \n",
    "<img src='Img/intro_stats/noten_3.png'></img>\n",
    "\n",
    "Wir können sehen, dass die orange Verteilung viel schmaler ist als die blaue. Das heißt die Werte der orangen Gruppe liegen näher an ihrem Durchschnitt als die der blauen Gruppe.\n",
    "Die Breite einer Verteilung wird durch die Varianz gemessen. Die Varianz misst den durchschnittlichen Abstand der Werte zu ihrem Mittelwert. \n",
    "\n",
    "Die Varianz ($s^2$) wird wie folgt berechnet:\n",
    "\n",
    "$$s^2 = \\frac{1}{n}\\sum_{i=1}^n(x_i-\\bar{x})^2$$\n",
    "\n",
    "Beachten Sie, dass nicht die Differenz ($x_i-\\bar{x}$), sondern das Quadrat ($x_i -\\bar{x})^2$ der Differenz summiert wird. Somit haben größere Abstände einen größeren Einfluss auf die Varianz. \n",
    "\n",
    "Berechnen Sie die Varianz der `abi_klasse`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d6e7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "varianz_abiklasse = sum(________________ )/(len(abi_klasse)# Ihr braucht wahrscheinlich einen for-loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c459acd",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Lösung:</b></summary>\n",
    "    \n",
    "```python\n",
    "sum([(x - mean_abiklasse)**2 for x in abi_klasse])/(len(abi_klasse))\n",
    "```\n",
    "</details>    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cee39ff",
   "metadata": {},
   "source": [
    "\n",
    "<details>\n",
    "<summary><b>Lösung: for-loop ausgeschrieben</b></summary>\n",
    "\n",
    " ```python\n",
    "quadrate = 0\n",
    "for x in abi_klasse:\n",
    "    quadrate = quadrate +((x-mean_abiklasse)**2)\n",
    "varianz_abiklasse = quadrate/len(abi_klasse) \n",
    "```\n",
    "</details>   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f61363e",
   "metadata": {},
   "source": [
    "Oft wird auch die Standardabweichung als Maß für die *Breite* eine Verteilung benutzt. Die Standardabweichung erhält man durch das Ziehen der Wurzel der Varianz. Damit wird das Maß der Varianz auf die Skala der ursprünglichen Verteilung gebracht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2173688",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_abiklasse = __________ #Berechnen Sie die Standardabweichung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f96c17",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Lösung:</b></summary>\n",
    "    \n",
    "```python\n",
    "std_abiklasse= varianz_abiklasse**(0.5)\n",
    "```\n",
    "</details>    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e0bcb7",
   "metadata": {},
   "source": [
    "Natürlich gibt es alle Funktionen auch schon in numpy: `np.mean()`,`np.std()`,`np.var()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e57a4e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mittelwert:  2.1629999999999994\n",
      "Varianz:  0.4214743333333333\n",
      "Standard Abweichung:  0.6492105462277499\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(\"Mittelwert: \", np.mean(abi_klasse))\n",
    "print(\"Varianz: \", np.var(abi_klasse))\n",
    "print(\"Standard Abweichung: \", np.std(abi_klasse))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1083b7e",
   "metadata": {},
   "source": [
    "Mit dem Maß der Varianz/Standard und dem Mittelwert können wir schon \n",
    "einige Verteilungen beschreiben. Natürlich nicht alle, z.B. bei \n",
    "multimodalen Verteilungen bräuchte man noch mehr Informationen. \n",
    "\n",
    "<img src='Img/intro_stats/noten_4.png'></img>\n",
    "\n",
    "## Inferentielle Statistik \n",
    "\n",
    "Allerdings wollen wir nicht immer nur Daten beschreiben, sondern wir wollen auch Informationen von diesen Daten gewinnen. \n",
    "Mithilfe\n",
    " der Korrelation können wir zum Beispiel den Zusammenhang von \n",
    "Körpergröße zu Gewicht beschrieben. Je größere ein Mensch ist, desto \n",
    "schwerer ist er. Dieses Model ist natürlich nicht perfekt, das \n",
    "Körpergewicht ist natürlich nicht nur von der Körpergröße abhängig. Es \n",
    "gibt große leichte Menschen und kleine schwerere. Aber es gibt eine \n",
    "zugrunde liegende Tendenz. \n",
    "\n",
    "<table><tr>\n",
    "<td> <img src='Img/intro_stats/reg_1.png' alt=\"Drawing\" style=\"width: 250px;\"/> </td>\n",
    "<td> <img src='Img/intro_stats/reg_2.png' alt=\"Drawing\" style=\"width: 250px;\"/> </td>\n",
    "</tr></table>\n",
    "\n",
    "Wir können die Beziehung mit einer linearen Regression beschreiben.\n",
    "Sie kennen vielleicht noch aus der Schule die Geradengleichung $y = mx+t$ (oder $y = ax+b$). \n",
    "<br>\n",
    "\n",
    "\n",
    "\n",
    "- $x$ ist die Input-Variable, in unserem Falle die Körpergröße\n",
    "- $y$ ist die zu vorher sagende Variable (Körpergewicht)\n",
    "- $m$ beschreibt die Steigung der Geraden\n",
    "- $t$ gibt den y-Achsen Abschnitt an, der Wert von $y$ wenn $x=0$\n",
    "\n",
    "<img src='Img/intro_stats/reg_3.png' alt=\"Drawing\" width=\"500\"/>\n",
    "\n",
    "Angenommen die Gleichung der Regressionsgeraden wäre $y=0,3x+21$ dann wäre zum \n",
    "Beispiel das Gewicht einer Person mit einer Größe von 180 cm, 75 kg \n",
    "($0,3\\cdot180+21)$.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Der Wert für $m$ ($0,3$) gibt an, um wie viel $y$ steigt, wenn $x$ sich um 1 erhöht.\n",
    "Also laut dem Model steigt das Körpergewicht um 0,3 kg pro 1 cm Größe. \n",
    "\n",
    "Der Wert für $t$ gibt an, wie viele eine Person wiegt, die 0 cm groß ($x=0$) ist. Im Fall der Körpergröße ergibt es wenig Sinn den Wert für $t$ zu interpretieren. Aber angenommen, wir schätzen den Wert eines Hauses anhand der Größe der Terrasse. Der Wert für $t$ gibt den Wert eines Hauses an, wenn die Terrassengröße $0$ ist. Also der Wert ohne Terrasse ist $t$.\n",
    "\n",
    "zurück zum eigentlichen Beispiel: \n",
    "\n",
    "Natürlich wiegt nicht jede 180 cm große Person 66 kg. Das ist nur der vorhergesagte Wert \n",
    "unsere Regressionsgleichung. Um das eindeutig zu kennzeichnen, schreiben wir $\\hat{y}$ anstatt $y$.\n",
    "Dadurch wird die Geradengleichung zu $hat{y}=mx+t$.\n",
    "\n",
    "---\n",
    "\n",
    "Schreiben Sie eine Funktion, die das Gewicht anhand der oben beschriebenen Geradengleichung berechnet.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c2892f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg(x,m,t):\n",
    "    _________# Was soll diese Funktion ausgeben?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5025d25",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Lösung:</b></summary>\n",
    "    \n",
    "```python\n",
    "def reg(x,m,t):\n",
    "    return m*x+t\n",
    "```\n",
    "</details>    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9aee72e",
   "metadata": {},
   "source": [
    "Die Variable `x` enthält die Größen in cm von 5 Personen. Für diese fünf Personen berechnen Sie das Gewicht mithilfe der Funktion `reg`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe730b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [182,167,198,132,178]\n",
    "y_hat = [reg(__,__,__) for ___ in _____ ]\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695e4da7",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Lösung:</b></summary>\n",
    "    \n",
    "```python\n",
    "y_hat = [reg(gewicht,0.3,21) for gewicht in x ]\n",
    "```\n",
    "</details>    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed303d31",
   "metadata": {},
   "source": [
    "Die Werte sind natürlich nur eine Schätzung des Gewichtes, und weichen von dem tatsächlichen Gewicht der Person ab. Um zu beurteilen, wie gut unsere Model das Gewicht bestimmen kann, brauchen wir auch das tatsächliche gemessene Gewicht der Personen. Diese sind in `y` gegeben. Wir können zum Beispiel die Differenz von `y_hat` und `y` berechnen. Dafür müssen wir aber erst einmal die Listen zu `numpy` Arrays konvertieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8c88b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([78.2,68.3, 81.0,64.3, 70.1 ])\n",
    "y_hat = np.array(y_hat)\n",
    "residual = y - ___ # was ziehen wir von y ab?\n",
    "residual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70269cf7",
   "metadata": {},
   "source": [
    "Diese Differenz zwischen dem tatsächlichen und dem vorhergesagten Wert($y - \\hat{y}$) wird auch als Residuum bezeichnet. Als Symbol für das Residuum wird meisten das kleine Epsilon ($\\epsilon$) verwendet, hiermit wird die Größe des Fehlers (**E**rror) der Vorhersage gemessen. \n",
    "\n",
    "<img src='Img/intro_stats/reg_4.png' alt=\"Drawing\" width=\"500\"/>\n",
    "\n",
    "Um Einschätzen zu können wie gut unsere Model insgesamt ist können wir zum Beispiel die Residuen einfach summieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08df034f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(residual)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2347da2",
   "metadata": {},
   "source": [
    "Wie Sie sehen ist der Wert sehr nahe bei null. Eigentlich ein sehr geringer Fehler. Das Problem ist aber, dass Residuen sowohl positiv als auch negativ sein können. Das heißt beim Summieren gleichen Sie sich aus. Man wird immer Werte in der Nähe von null erhalten. Um das zu umgehen, summieren deswegen nicht die Residuen, sondern, wie bei der Varianz, die Quadrate der Residuen. $$\\sum_{i=1}^{n}(y_i-\\hat{y}_i)^2$$ \n",
    "\n",
    "Die Summe alleine, würde aber dazu führen, dass Modelle die mehr Datenpunkte haben, also ein größeres $n$, automatische größere Summen haben werden. Deswegen nehmen wir nicht die Summe, sondern den Mittelwert der Quadrate: $\\frac{1}{n}\\sum_{i=1}^{n}(y_-\\hat{y}_i)^2$. Dieser Wert, *Mean Squared Error* (MSE) genannt, eignet sich, um die Güte der Vorhersagen zu beurteilen. Wenn ein Model einen kleinen MSE hat können Sie daraus schlussfolgern, dass die Residuen klein sein müssen, also die Unterschiede zwischen vorhergesagten um wahren Wert klein sind. \n",
    "\n",
    "So wie bei der Varianz und Standard Abweichung gibt es auch den Root Mean Squared Error (RMSE). Wie Sie sich denken können, wird einfach die Wurzel vom MSE genommen. Schreiben Sie eine Funktion, die den RMSE berechnen kann. Sie dürfen `numpy` benutzen, das heißt Sie brauchen keinen for-loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9194e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(y,y_hat):\n",
    "   MSE = np.sum(__________________) /len(_____) #Hier wird der MSE berechnet, \n",
    "   return ___________ # Wir wollen nicht den MSE sonder den RMSE. Konvertieren Sie den MSE zum RMSE\n",
    "RMSE(y, y_hat)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcc75a2",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Lösung:</b></summary>\n",
    "    \n",
    "```python\n",
    "def RMSE(y,y_hat):\n",
    "   MSE = np.sum((y-y_hat)**2)/len(y)\n",
    "   return np.sqrt(MSE) \n",
    "```\n",
    "</details>    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783dc4bb",
   "metadata": {},
   "source": [
    "Im maschinellen Lernen, oder allgemeine im Feld der Optimierung, werden Funktionen wie den RMSE auch als Loss Funktion bezeichnet. Sie messen wie gut ein Model, dessen Parameter, zu den Daten passen. Den Loss, berechnet durch die Loss Funktion, gilt es zu minimieren. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c671edd",
   "metadata": {},
   "source": [
    "# Beispiel\n",
    "\n",
    "Bis jetzt haben Sie immer die Parameter `m` und `t` vorgegeben bekommen. In der Realität müssen Sie diese selber berechnen (lassen). Im folgenden Beispiel werden wir uns mit der Vorhersage von Siedepunkt befassen. Dafür benutzen wir einen Datensatz des amerikanischen *National Institute of Standards and Technology*. Im Datensatz sind die Siedetemperaturen für 72 einfache Alkohole aufgezeichnet. Dazu wird noch das molekulare Gewicht und die Anzahl der Kohlenstoffe angegeben. \n",
    "Der Datensatz befindet sich im Ordner `../data/boilingpoints/`\n",
    "\n",
    "Wir benutzen diesmal `⁣`, um unseren Datensatz einzulesen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd963f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Größe der Daten:  (72, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[338.  ,  32.04,   1.  ],\n",
       "       [351.  ,  46.07,   2.  ],\n",
       "       [371.  ,  60.1 ,   3.  ],\n",
       "       [356.  ,  60.1 ,   3.  ],\n",
       "       [391.  ,  74.12,   4.  ],\n",
       "       [372.  ,  74.12,   4.  ],\n",
       "       [381.  ,  74.12,   4.  ],\n",
       "       [355.  ,  74.12,   4.  ],\n",
       "       [411.  ,  88.15,   5.  ],\n",
       "       [404.  ,  88.15,   5.  ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.genfromtxt('../data/boilingpoints/bp.csv', delimiter=',', skip_header =True)\n",
    "print(\"Größe der Daten: \",data.shape)\n",
    "data[:10,:] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d372b15",
   "metadata": {},
   "source": [
    "Der Datensatz besteht aus 72 Reihen und 3 Spalten. Jede Reihe repräsentiert einen Alkohol und die 3 Spalten sind Deskriptoren. Die erste Spalte enthält die Schmelzpunkte, die zweite das molekulare Gewicht und die dritte Spalte die Anzahl der Kohlenstoffe. \n",
    "\n",
    "Unser Ziel ist es mithilfe des molekularen Gewichtes den Schmelzpunkt vorher zusagen.\n",
    "Zunächst speichern wir die erste Spalte(Schmelzpunkte) in die Variable `y` und die zweite Spalte in die Variable `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b05aa90",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[:,0] # y ist unsere zuvorhersagende Variable (schmelzpunkte)\n",
    "x = data[:,1:2] # Wir könnten auch data[:,1] benutzen, verhält sich leicht anders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "772f0a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32.04 46.07 60.1  60.1  74.12]\n",
      "[[32.04]\n",
      " [46.07]\n",
      " [60.1 ]\n",
      " [60.1 ]\n",
      " [74.12]]\n"
     ]
    }
   ],
   "source": [
    "print(data[:5,1])\n",
    "print(data[:5,1:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7050e61",
   "metadata": {},
   "source": [
    "Sie können sehen, dass wir dieselben Werte auswählen, allerdings reduzieren wir die Spalte in der ersten Variante zu einem 1-dimensionales Array der Größe `(72)`. Also einem Vektor der Länge 72. Mancher der Funktionen notwendig für eine lineare Regression erwarten, dass sich unsere `x` Variable in Form eines 2-dimensionalen Array befindet. Deswegen wählen wir die Spalte mit `data[:,1:2]` aus.\n",
    "\n",
    "\n",
    "Sie können die Daten auch grafisch darstellen, dafür benutzen wir die Libary `matplotlib`. Mit der `plt.plot()` Funktion können Sie schnell einfache Graphen erstellen. Hierbei müssen Sie nur angeben welche Werte auf die x-Achse angeben (erste Position in der Funktion), dann geben Sie an was auf die y-Achse gehört (zweite Position). Als Letztes können Sie spezifizieren, ob die einzelnen Werte als Punkt `\"o\"` oder mit einer Linie verbunden werden soll `\"-\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1dc90b67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fece43135d0>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAboUlEQVR4nO3df5Bd9Xnf8feHZQ0rxnhFEVRaoUgkQh5kYilsSVoVAjKxKGChkDTBEzqkTkch43RcMxZox5kGp/EgW3bMH53ao7jueCIDpvyQGTEYZBTIxGMguxESEqAiAQatVLSA5ZSgKJJ4+sc9C1ere1f36t7zPfee/bxmdu4933Puvc+upEdnn+8vRQRmZlYupxQdgJmZtZ+Tu5lZCTm5m5mVkJO7mVkJObmbmZXQqUUHAHD22WfH3Llziw7DzKyrjIyMvBkRM2qd64jkPnfuXIaHh4sOw8ysq0j6ab1zLsuYmZWQk7uZWQk5uZuZlZCTu5lZCTm5m5mVUEeMljEzm2o2bBll7aM72XvgILP6+1i1bAErFg+07f2d3M3MEtuwZZShB57j4OGjAIweOMjQA88BtC3BuyxjZpbY2kd3vp/Yxx08fJS1j+5s22c4uZuZJbb3wMGm2k+Gk7uZWWKz+vuaaj8ZTu5mZomtWraAvt6eY9r6entYtWxB2z7DHapmZomNd5p6tIyZWcmsWDzQ1mQ+kcsyZmYl1NCdu6RXgf8HHAWORMSgpLXAp4B/BnYD/zEiDkiaC7wAjI/peSoibm534GZmVl8zZZkrIuLNquNNwFBEHJH0FWAIuC07tzsiFrUpRjMza9JJl2Ui4rGIOJIdPgXMbk9IZmbWqkaTewCPSRqRtLLG+c8Aj1Qdz5O0RdKTki6t9YaSVkoaljQ8NjbWZNhmZjaZRssySyJir6RzgE2SXoyIvwGQ9EXgCPC97Np9wJyIeEvSxcAGSQsj4h+q3zAi1gHrAAYHB6Md34yZmVU0dOceEXuzx/3Ag8AlAJJuAq4Ffi8iIrvmUES8lT0fodLZekH7Qzczs3pOmNwlnSHpw+PPgU8C2yVdRaUDdXlEvFt1/QxJPdnz84H5wMt5BG9mZrU1UpY5F3hQ0vj1d0XEDyXtAk6jUqaBD4Y8Xgb8maQjVIZO3hwRb+cSvZmZ1XTC5B4RLwMfr9H+S3Wuvx+4v/XQzMzsZHmGqplZCTm5m5mVkJO7mVkJObmbmZWQk7uZWQk5uZuZlZA36zCz3GzYMprrbkNWn5O7meViw5ZRhh54joOHjwIweuAgQw88B+AEn4DLMmaWi7WP7nw/sY87ePgoax/dWecV1k5O7maWi70HDjbVbu3l5G5muZjV39dUu7WXa+5mU0jKDs5VyxYcU3MH6OvtYdWyBQ2/hztkT56Tu9kUkbqDc/w9TzY5u0O2NU7uZlPEZB2ceSXLFYsHTvq9i4i3TJzczaaIbuvgTB1v2UpA7lA1myK6rYMzZbzjJaDRAwcJPigBbdgy2vbPSqWh5C7pVUnPSXpW0nDWdpakTZJeyh6nV10/JGmXpJ2SluUVvJk1btWyBfT19hzT1mwHZ0op4y3jmPxmyjJXRMSbVcergccjYo2k1dnxbZIuBG4AFgKzgB9JuiAijh7/lmZTW8pSQKsdnKmljLfbSlaNaKXmfh1wefb8u8ATVDbMvg64JyIOAa9ke61eAvykhc8yK50iRoO00sFZhFTxzurvY7RGIu/UklUjGq25B/CYpBFJK7O2cyNiH0D2eE7WPgC8XvXaPVmbmVUpYymgW3VbyaoRjd65L4mIvZLOATZJenGSa1WjLY67qPKfxEqAOXPmNBiGWXmUsRTQrbqtZNWIhpJ7ROzNHvdLepBKmeUNSTMjYp+kmcD+7PI9wHlVL58N7K3xnuuAdQCDg4PHJX+zsitjKaCbdVvJ6kROWJaRdIakD48/Bz4JbAceAm7KLrsJ+EH2/CHgBkmnSZoHzAeeaXfgZt1u1bIF9J5y7C+6vaeoq0sB1jkauXM/F3hQ0vj1d0XEDyX9HXCvpD8AXgP+PUBE7JB0L/A8cAT4rEfKmNUxsYhZq6hpdhIUUXxFZHBwMIaHh4sOwyypJWs21yzLDPT38ePVS3P5zLLNwpzqJI1ExGCtc15+wKwgRUyv90JcU4eXHzArSOrlADz0cmpxcjcryBUfndFUe6s89HJqcXI3K8jD2/Y11d6qbls4zFrj5G5WkJ+9e7ip9laVcRam1ecOVbMpooyzMK0+37mbFaS/r7epdrNmOLmbFeT25QtrzmG6ffnCXD6vHRtSbNgyypI1m5m3+mGWrNnc1ZtZlJ2Tu1lBhn/69nEr6kXWnodWh0IWsVuR/zM5eU7uZgW5++nXm2pvVatDIVOPky/j1ncpObmbFeRonaU/6rW3qtWhkKnHyXvSVWuc3M0K0qPaq4TVa29Vq0MhU4+T96Sr1ji5mxXk0796XlPtrVqxeIA7rr+Igf4+RGWBsjuuv6jhoZCpx8l70lVrPM7drCB/vuIioFJjPxpBj8Snf/W899vz0MqGFKnHya9atuCYhc7Ak66a4SV/zaxjeYniyXnJXzPrSmXb+i4lJ3ezAvnO1PLScHKX1AMMA6MRca2k7wPjxa9+4EBELJI0F3gBGB+v9FRE3Ny+kM3y9ScbnktSB/fmGZanZu7cP0claZ8JEBG/O35C0teBn1dduzsiFrUjQLOU/mTDc6x/6rX3j49GvH/c7gQ/2ThuJ3drVUNDISXNBq4Bvl3jnIDfAe5ub2hm6aWcNepx3JanRse53wncCrxX49ylwBsR8VJV2zxJWyQ9KenSWm8oaaWkYUnDY2NjTQVtlpeUs0Y9jtvydMLkLulaYH9EjNS55NMce9e+D5gTEYuBW4C7JJ058UURsS4iBiNicMaMfLYVM2tWylmj3jzD8tTInfsSYLmkV4F7gKWS1gNIOhW4Hvj++MURcSgi3sqejwC7gQvaHLdZLlLOGm11xqjZZE7YoRoRQ8AQgKTLgS9ExI3Z6SuBFyNiz/j1kmYAb0fEUUnnA/OBl9sct1kuUs8a7bZx3B662T1aHed+A8d3pF4G/JmkI8BR4OaIyGeBarMc/PmKi3JdAqCdUiZbD93sLl5+wKxLTUy2UKnZ51XaWbJmM6M1RvIM9Pfx49VL2/55dmKTLT/gVSHNulTq9c49dLO7OLmbdanUydZDN7uLk7vZBN2yb2fqZOuhm93Fyd2sSjft25k62XroZnfxqpBmVbppvZfUm2eMf2an/RysNid3syrd1mnoZGv1uCxjVsWdhlYWTu5mVdxpaGXhsoxZlSLq2GZ5cHI3m8B1bCsDJ3ezLuaFvKweJ3freE5gtXkhL5uMO1Sto3XTpKLUUq8tY93Fyd06mhNYfd02Jt/ScnK3juYEVt9H+nqbarepxcndOponFdVXb1vXHLZ7tS7UcHKX1CNpi6SN2fHtkkYlPZt9XV117ZCkXZJ2SlqWR+A2NXhSUX0H3j3cVLtNLc2Mlvkc8AJwZlXbNyLia9UXSbqQyvZ7C4FZwI8kXRARxxZOzRrQjZOKUo3umdXfV3NnJP9WY9Bgcpc0G7gG+DJwywkuvw64JyIOAa9I2gVcAvyklUBt6uqmSUUphyeuWrag5jZ7/q3GoPGyzJ3ArcB7E9r/WNI2Sd+RND1rGwBer7pmT9Z2DEkrJQ1LGh4bG2sybLPOlHJ0j9dXt8mc8M5d0rXA/ogYkXR51alvAv8NiOzx68BngFrdOcftwh0R64B1UNkgu9nAzTpR6tE93fRbjaXVSFlmCbA86zA9HThT0vqIuHH8Akl/CWzMDvcA51W9fjawt03xmnWc6ho7osatjIcnWnonLMtExFBEzI6IuVQ6SjdHxI2SZlZd9pvA9uz5Q8ANkk6TNA+YDzzT5rjNOsLEGbRR53dQD0+01FpZW+arkhZRuU95FfhDgIjYIele4HngCPBZj5SxsqpVY6/FwxMttaaSe0Q8ATyRPf8Pk1z3ZSoja8xKrdFauocnWmqeoWrWgkaStocnWhGc3M1aUGsGbW+P6O/r9fBEK5TXczdrQTfOoLWpwXfuZmYl5Dt3sxZ4NyTrVL5zN2uBNxOxTuU7dyudlHuu1lqVcbJ2s1Sc3K1UUpdJeiSO1piW2uMpqVYwl2WsVFKXSWol9snazVJxcrdSSb0q40CdSUw9EvNWP8ySNZvZsGU0l882m4yTu5VK6j1Xa01igsqde/BBWcgJ3lJzcrdSqTdj9B8PHcnlTnrihhm1au0ePWNFcIeqlcrEGaP903p555+OcOBgZVXGPDpYqzfMmLf64ZrX5FUWMqvHd+5WOisWD/Dj1Ut5Zc01TPvQqRx+79jOzTzvpFOXhczqcXK3UkvdwXrFR2c01d6qDVtGWbJmsztv7ThO7lZqqe+kN27d11R7KybuAuXOW6vWcHKX1CNpi6SN2fFaSS9K2ibpQUn9WftcSQclPZt9fSun2M1OaNWyBfSecmwnZ+8pym199fHafqPtrfDSBzaZZu7cPwe8UHW8CfhYRPwy8H+AoapzuyNiUfZ1cxviNDtpEycUlWWCUeqSk3WXhpK7pNnANcC3x9si4rGIOJIdPgXMbn94Zq25/aEdTOhP5b2otHc7d97aZBq9c78TuBV4r875zwCPVB3Py0o4T0q6tNYLJK2UNCxpeGxsrOGAzZqRskwC0N/X21R7K2qN6feWfjbuhMld0rXA/ogYqXP+i8AR4HtZ0z5gTkQsBm4B7pJ05sTXRcS6iBiMiMEZM/IZSWCW2u3LF9as8d++fGHbP2viBCpv6WfVGpnEtARYLulq4HTgTEnrI+JGSTcB1wKfiKgUMiPiEHAoez4iaTdwATCcy3dgNonp03r52bvH36VPn9b+O2lIv+1e9QQqs2onTO4RMUTWWSrpcuALWWK/CrgN+PWIeHf8ekkzgLcj4qik84H5wMs5xG52Qtf88kzWP/Vazfa8OOFaJ2hlnPt/Bz4MbJow5PEyYJukrcB9wM0R8XaLcZqdlJTjzs06SVNry0TEE8AT2fNfqnPN/cD9rQZm1g6pO1TNOoVnqJqZlZCTu5XaGR86fq31ydrNysLJ3UrtvTqzUeu1m5WF13O3Ujt4uPa8u3rt7bBhy2iyoZBm9Ti5W+6mUrIbX6lxfEGvPDYHMWuEk7vlqlayW3XfVm5/aAc/P3g492QvQa0KTI3d8NpispUandwtJSd3y1WtZHf4aOS67V21eqX1vEruo3VWZKzXbpYXd6harhpZfjbPNchTLuQFtTfInqzdLC9O7parRpefzWsN8no5Na9cW2+t+LKsIW/dw8ndclVrWdpa8lqDvNaiYZO1t8p37tYpnNwtVxOXpZ0+rfe4JXHzXIPcd+42VblD1XI3cZXElEMjU3eoDvT31ew8HfDuSJaY79zN2uiKj9beeKZeu1lefOduSaWe5HOKOG4P1fH2PPz1i7W3jKzXbpYX37lbUpNN8slDrcQ+WXur6o36yWs0kFk9Tu6WVOrkV6/WnVcNvN6on7xGA5nV03Byl9QjaYukjdnxWZI2SXope5xede2QpF2Sdkpalkfg1p0+UmfyUL32VtUaipnn6JzUn2dWTzN37p8DXqg6Xg08HhHzgcezYyRdCNwALASuAv6HJC+ebUD6oYkrFg/wWxcPvD/OvEfity7Ob4/TiUM/B/r7uOP6i7yujCXXUIeqpNnANcCXgVuy5uuAy7Pn36Wy/d5tWfs9EXEIeEXSLuAS4Cdti9q61oE6k4fqtbdqw5ZR7h8ZfX+c+dEI7h8ZZfAXzso1wTuZW9EavXO/E7gVqF4E+9yI2AeQPZ6TtQ8Ar1ddtydrO4aklZKGJQ2PjXkkwVSRuiadugPXrFOcMLlLuhbYHxEjDb5nrV+wjxubEBHrImIwIgZnzPAY4KkidU3ao1dsqmqkLLMEWC7pauB04ExJ64E3JM2MiH2SZgL7s+v3AOdVvX42sLedQVv3Gi9XpJqhOqvOjFGPXrGyO2Fyj4ghYAhA0uXAFyLiRklrgZuANdnjD7KXPATcJekvgFnAfOCZtkduXStlTfqKj85g/VOv1Ww3K7NWxrmvAX5D0kvAb2THRMQO4F7geeCHwGcj4mjddzHL0cat+5pqNyuLppYfiIgnqIyKISLeAj5R57ovUxlZY3aclAuHje/41Gi7WVl4bRkD0iVcbyBtloaXH7D3E+7ogYMEHyTcDVtG2/5ZHppoloaTuyVNuKmHJk6fVntZg3rtZmXh5G5JE27qSUx/+qmF9PYcO/Wit0f86acW5vJ5Zp3Cyd2SJtzUm1msWDzA2t/++DFrvaz97Y+7vm+l5w5VY9WyBcd0ckJ+s0aL2MzCa73YVOTkbklnjXo5ALM0nNwNSHd32z+tl5/VWAGy3x2cZm3lmrsl9U+Ha09WrtduZifHyd2SOnj4vabazezkOLmbmZWQa+4GpFt+YHqdmrsnFZm1l+/cLenyA55UZJaGk7slXX7Ak4rM0nBZxpKPPfekIrP8+c7dkq/3Ymb5a2SD7NMlPSNpq6Qdkr6UtX9f0rPZ16uSns3a50o6WHXuWzl/D9ai1JtWm1n+GinLHAKWRsQ7knqBv5X0SET87vgFkr4O/LzqNbsjYlF7Q7W8pN60OuVOTGZTVSMbZAfwTnbYm33F+HlJAn4HWJpHgJZGqjq4d2IyS6Ohmruknqzssh/YFBFPV52+FHgjIl6qapsnaYukJyVd2r5wrdt5JyazNBoaLRMRR4FFkvqBByV9LCK2Z6c/Ddxddfk+YE5EvCXpYmCDpIUR8Q/V7ylpJbASYM6cOS1+G9aqVKUSrwpplkZTQyEj4oCkJ4CrgO2STgWuBy6uuuYQlTo9ETEiaTdwATA84b3WAesABgcHAztGyrp0ylLJrP4+Rmskco/MMWuvRkbLzMju2JHUB1wJvJidvhJ4MSL2TLi+J3t+PjAfeLnNcZdayhmjkLZU4pE5Zmk0UnOfCfy1pG3A31GpuW/Mzt3AsSUZgMuAbZK2AvcBN0fE2+0KeCpIXZdOWSpZsXiAO66/6JgZqndcf5E7U83arJHRMtuAxXXO/X6NtvuB+1uObApLXZdOXSrxDFWz/HmGagdKPWPUpRKz8nFy70Cpk61LJWbl44XDOlDqGaPjn+lkblYeTu4dysnWzFrhsoyZWQk5uZuZlZCTu5lZCTm5m5mVkJO7mVkJObmbmZWQk7uZWQl5nHuH8lZ0ZtYKJ/cOVMRWdP7PxKxcXJbpQKmX/E29fryZ5c/JvQOlXvLX+5qalY+TewdKveSv9zU1Kx8n9wZt2DLKkjWbmbf6YZas2ZxrySL1kr+p/zMxs/w1sofq6ZKekbRV0g5JX8rab5c0KunZ7OvqqtcMSdolaaekZXl+AymkrkmnXl/dm3WYlU8jo2UOAUsj4h1JvcDfSnokO/eNiPha9cWSLqSyt+pCYBbwI0kXRMSxRd0uMllNOq+Em3LJ3yLWjzezfDWyh2oA72SHvdlXTPKS64B7IuIQ8IqkXcAlwE9ajLUwU6Em7fXjzcqloZq7pB5JzwL7gU0R8XR26o8lbZP0HUnTs7YB4PWql+/J2ia+50pJw5KGx8bGTv47SMA1aTPrNg0l94g4GhGLgNnAJZI+BnwT+EVgEbAP+Hp2uWq9RY33XBcRgxExOGPGjJMIPR3XpM2s2zQ1WiYiDgBPAFdFxBtZ0n8P+EsqpReo3KmfV/Wy2cDe1kMtjjeQNrNuc8Kau6QZwOGIOCCpD7gS+IqkmRGxL7vsN4Ht2fOHgLsk/QWVDtX5wDPtDz0t16TNrJs0MlpmJvBdST1U7vTvjYiNkv5K0iIqJZdXgT8EiIgdku4FngeOAJ/t5pEyZmbdSJXBMMUaHByM4eHhosMwM+sqkkYiYrDWOc9QNTMrISd3M7MScnI3Myuhrt6swxtMmJnV1rXJvYjdiszMukXXlmW8wYSZWX1dm9ynwmJeZmYnq2uTuxfzMjOrr2uTuxfzMjOrr2s7VL3BhJlZfV2b3MGLeZmZ1dO1ZRkzM6vPyd3MrISc3M3MSsjJ3cyshJzczcxKqCM265A0Bvy0oI8/G3izoM9uRCfH18mxQWfH18mxQWfH59g+8AsRMaPWiY5I7kWSNFxvJ5NO0MnxdXJs0NnxdXJs0NnxObbGuCxjZlZCTu5mZiXk5A7rig7gBDo5vk6ODTo7vk6ODTo7PsfWgClfczczKyPfuZuZlZCTu5lZCU255C6pR9IWSRuz47MkbZL0UvY4vcDY+iXdJ+lFSS9I+tedEp+kz0vaIWm7pLslnV5kbJK+I2m/pO1VbXXjkTQkaZeknZKWFRTf2uzPdpukByX1FxFfrdiqzn1BUkg6u4jYJotP0n/OYtgh6atFxFfnz3WRpKckPStpWNIlRcR2nIiYUl/ALcBdwMbs+KvA6uz5auArBcb2XeA/Zc8/BPR3QnzAAPAK0Jcd3wv8fpGxAZcBvwJsr2qrGQ9wIbAVOA2YB+wGegqI75PAqdnzrxQVX63YsvbzgEepTCg8u8N+dlcAPwJOy47P6ZSfHfAY8O+y51cDTxT1s6v+mlJ37pJmA9cA365qvo5KUiV7XJE4LAAknUnlL87/BIiIf46IA50SH5W1//sknQpMA/ZSYGwR8TfA2xOa68VzHXBPRByKiFeAXcAl5KhWfBHxWEQcyQ6fAmYXEV+dnx3AN4BbgepRFh3xswP+CFgTEYeya/YXEV+d2AI4M3v+ESr/NpLHNtGUSu7AnVT+8r5X1XZuROwDyB7PKSAugPOBMeB/ZWWjb0s6oxPii4hR4GvAa8A+4OcR8VgnxDZBvXgGgNerrtuTtRXpM8Aj2fPC45O0HBiNiK0TThUeW+YC4FJJT0t6UtK/yto7Ib7/AqyV9DqVfydDWXuhsU2Z5C7pWmB/RIwUHUsdp1L5de+bEbEY+EcqpYXCZbXr66j8ajkLOEPSjcVG1RTVaCtsDLCkLwJHgO+NN9W4LFl8kqYBXwT+a63TNdqK+NmdCkwHfg1YBdwrSXRGfH8EfD4izgM+T/bbNwXHNmWSO7AEWC7pVeAeYKmk9cAbkmYCZI/7679FrvYAeyLi6ez4PirJvhPiuxJ4JSLGIuIw8ADwbzoktmr14tlDpZ48bjYf/OqclKSbgGuB34usMEvx8f0ilf+4t2b/PmYDfy/pX3ZAbOP2AA9ExTNUfvs+u0Piu4nKvwmA/80HpZdCY5syyT0ihiJidkTMBW4ANkfEjcBDVP5wyB5/UFB8/xd4XdKCrOkTwPN0RnyvAb8maVp2t/QJ4IUOia1avXgeAm6QdJqkecB84JnUwUm6CrgNWB4R71adKjS+iHguIs6JiLnZv489wK9kfyc74mcHbACWAki6gMqAgzc7JL69wK9nz5cCL2XPi40tVc9tJ30Bl/PBaJl/ATye/YE8DpxVYFyLgGFgG5W/zNM7JT7gS8CLwHbgr6iMACgsNuBuKvX/w1SS0R9MFg+VssNuYCfZyIYC4ttFpQb7bPb1rSLiqxXbhPOvko2W6aCf3YeA9dnfv78HlnbKzw74t8AIlZExTwMXF/Wzq/7y8gNmZiU0ZcoyZmZTiZO7mVkJObmbmZWQk7uZWQk5uZuZlZCTu5lZCTm5m5mV0P8H4i2CbBExNkAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(x, y, \"o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131c0e9b",
   "metadata": {},
   "source": [
    "Wir können klar sehen, dass mit steigendem Gewicht auch der Siedepunkt der Alkohole steigt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2ff69d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-4.655498352371404 389.27698386998935\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(x,y) # berechnet die Regressions Gerade\n",
    "m = model.coef_[0] # Wir können m und t aus model() erhalten.\n",
    "t = model.intercept_\n",
    "\n",
    "print(m,t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d54d19",
   "metadata": {},
   "source": [
    "Berechnen Sie mit den Parametern `y_hat` und anschließend den `RMSE`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "27590702",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '____' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_742910/3873349992.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m___\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0m____\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mRMSE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_hat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name '____' is not defined"
     ]
    }
   ],
   "source": [
    "y_hat = reg(data[:,1], ___ , ____)\n",
    "RMSE(y, ____) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51eb5034",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Lösung:</b></summary>\n",
    "    \n",
    "```python\n",
    "y_hat = reg(data[:,1], m , t)\n",
    "RMSE(y, y_hat) \n",
    "```\n",
    "</details>    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c695c8",
   "metadata": {},
   "source": [
    "Können Sie andere Werte für `m` und `t` finden, die zu einen geringer RMSE führen? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a9cb4d20",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1350664866.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_742910/1350664866.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    y_hat = reg(data[:,1],  ,   )\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "y_hat = reg(data[:,1], ____  ,  _____  )\n",
    "RMSE(y, y_hat) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542e7ec9",
   "metadata": {},
   "source": [
    "Tatsächlich geht dies nicht. Wenn wir über eine lineare Regression sprechen, reden wir meisten von einer *ordinary least-square* Regression. Wie Sie dem Namen entnehmen können, minimiert diese Regression die \"Squares\"also den Fehler der Regressionsgerade. Das heißt die Regressionsgerade, ist die optimale Gerade, die für diesen Datensatz gefunden werden kann. Anders gesagt einer OLS Regressionsgerade minimiert den (R)MSE.\n",
    "\n",
    "## Multiple Regression\n",
    "\n",
    "Lineare Regression können auch mit mehr als nur einer $x$ Variable durchgeführt werden. Die Formel erweitert sich auf:\n",
    "\n",
    "$$\\hat{y}= \\beta_0 +\\beta_1x_1 +\\beta_2x_2$$\n",
    "\n",
    "$mx+t$ kenne Sie vielleicht noch aus der Schule, im Allgemeinen hat sich aber die Notation mit $\\beta$ druchgesetzt. Hierbei steht $\\beta_0$ für das $t$ und $\\beta_1$ für den Regressionskoefizierent der zur ersten Input-Variable $x_1$ gehört.\n",
    "\n",
    "An der Interpretation dieser Koeffizienten ändert sich aber nichts.\n",
    "\n",
    "Wir können sowohl die Anzahl der Kohlenstoffe als auch das Gewicht benutzen, um die Schmelzpunkte vorherzusagen.\n",
    "\n",
    "Damit das klappt, müssen Sie zunächst nicht nur die zweite, sondern auch die dritte Spalte von `data` in `x` auswählen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda7978a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data[:,1: ___ ] # Welche Spalten nehmen Sie mit nach x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9a28c8",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Lösung:</b></summary>\n",
    "    \n",
    "```python\n",
    "x = data[:,1:3]\n",
    "```\n",
    "</details>    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397227e8",
   "metadata": {},
   "source": [
    "Sie könnne jetzt die Regressionskoeffizienten wieder mit `LinearRegression` schätzen lassen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b1e061c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4.65549835 83.18358374] 389.27698386998935\n"
     ]
    }
   ],
   "source": [
    "model_2 = LinearRegression()\n",
    "model_2.fit(x,y) # berechnet die Regressions Gerade\n",
    "print(model_2.coef_, model_2.intercept_ ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ff9272",
   "metadata": {},
   "source": [
    "Wie Sie sehen, erhalten Sie jetzt insgesamt 3 Parameter. Der Regressionskoeffizient für das molekulare Gewicht ist `-4.65` und für die Anzahl der Kohlenstoff `83.18`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78079496",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat =model.predict(x)\n",
    "RMSE(y, y_hat) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65cd5cc6",
   "metadata": {},
   "source": [
    "# Logistische Regression\n",
    "\n",
    "Es gibt auch Probleme in dene nicht exakte Werte vorhergesagt werden sollen. Wir wollen zum Beispiel entscheiden, ob ein Patient auf die Intensivstation muss oder nicht. Hierbei muss nur zwischen `JA` oder `NEIN` entschieden werden. In mathematischen Termen würden wir aber von `1` oder `0` sprechen. Wir sprechen von eine binären Klassifizierung, wenn ein Datenpunkt zu einer von zwei Gruppen gehören kann. \n",
    "\n",
    "Hier haben wir ein Beispiel von einem Basketballspieler der auf den Korb aus verschiedenen Distanzen wirft. \n",
    "Macht er einen Korb wird dieser Wurf mit einer `1` gekennzeichnet. Trifft er nicht wird diesem Wurf eine `0` zugeordnet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3db8c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "körbe = np.array([1,1,1,1,1,1,0,1,0,1,1,0,0,1,1,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0])    \n",
    "distanz = np.array([0.,1.,2.,3.,4.,5.,6.,7.,8.,9.,10.,11.,12.,13.,14.,\n",
    "                    15.,16.,17.,18.,19.,20.,21.,22.,23.,24.,25.,26.,27.,28.,29.])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce5e068",
   "metadata": {},
   "source": [
    "Es ist zwar möglich eine simple Regressionsgerade zu berechnen, diese passt aber auf Grund der binären $y$ Variable nicht sehr gut zu den Daten. Ein Lösung ist die logistische Regression. Hier wird \"nach\" der lineare Regression eine Sigmoid Funktion benutz um die vorhergesagten Werte zu transformieren. \n",
    "\n",
    "<table><tr>\n",
    "<td> <img src='Img/intro_stats/log1.png' alt=\"Drawing\" style=\"width: 250px;\"/> </td>\n",
    "<td> <img src='Img/intro_stats/log2.png' alt=\"Drawing\" style=\"width: 250px;\"/> </td>\n",
    "<td> <img src='Img/intro_stats/log3.png' alt=\"Drawing\" style=\"width: 250px;\"/> </td>\n",
    "</tr></table>\n",
    "<br>\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "<center>\n",
    "<h2>Sigmoid Funktion</h2>\n",
    "</center>\n",
    "\n",
    "Die Sigmoid Funktion ist eine nicht lineare Funktion. Mathamtische wird die Sigmoid Funktion so geschrieben:\n",
    "$$sigmoid(z)= \\frac{1}{1+e^{-z}}$$\n",
    "\n",
    "\n",
    "Um zu verstehen was sie genau macht kann man sich das Beispiel anschauen.\n",
    "\n",
    "<td> <img src='Img/intro_stats/sigmoid.png' alt=\"Drawing\" style=\"width: 250px;\"/> \n",
    "    \n",
    "Auf der x-Achse sind Werte zwischen -6 und 6 **bevor** die Sigmoid Funktion auf diese Werte angewendet wird. Auf der y-Achse befinden sich die selben Werte aber diesmal nachdem die Sigmoid Funktion angewendet worden ist. \n",
    "Alle Werte befinden sich jetzt zwischen 0 und 1. Werte die voher sehr weit entfernt waren von 0 werden sehr nah zu `0` oder `1` gesetzt.\n",
    "    \n",
    "Die Form dieser Funktion passt schon viel besser zu einer binären Klassifizierung.\n",
    "\n",
    "Um eine logistische Regression durchzuführen, können wir schon auf das Gelernte von der linearen Regression bauen.\n",
    "Wir haben die slebe Situation, wir wollen mit Hilfe von unserem Input `x`, eine Vorhersage für `y` machen.     \n",
    "Dafür werden die Werte aus der linearen Regression einfach in die Sigmoid Funktion gesetzt.\n",
    "$$ z = mx+t $$\n",
    "$$\\hat{y} = sigmoid(z) = \\frac{1}{1+e^{-z}} = \\frac{1}{1+e^{-(mx+t)}} $$    \n",
    "\n",
    "Berechnet nun z in dem ihr die reg_treffer auf die Werte Distanz anwendent. Da Sie jetzt numpy benutzen können brauchen Sie keinen for-loop mehr.\n",
    "Für das Beispiel mit dem Basketballer sind folgende Parameter vorgegeben:\n",
    "- `m` = -0.8\n",
    "- `t` = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a91281",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Lösung:</b></summary>\n",
    "    \n",
    "```python\n",
    "def reg_treffer(distanz):\n",
    "    return -0.8*distanz+7\n",
    "```\n",
    "</details>    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e569c647",
   "metadata": {},
   "source": [
    "Berechnet nun `z` in dem ihr die `reg_treffer` auf die Werte Distanz anwendent.\n",
    "Da Sie jetzt `numpy` benutzen können brauchen Sie keinen for-loop mehr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c0dfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = reg(______) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6f5158",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Lösung:</b></summary>\n",
    "\n",
    "```python\n",
    "z = reg_treffer(distanz) \n",
    "```\n",
    "</details>    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575b9507",
   "metadata": {},
   "source": [
    "Als nächstes benötigen Sie die Sigmoid Funkion. Schreiben Sie mit Hilfe von `numpy` eine Funktion in Pythondafür. $e^(x)$ kann mit Hilfe von `numpy` als `np.exp(x)` geschrieben werden.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2adfeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(wert):\n",
    "    return 1/(___________) #Hier den Nenner der sigmoid Funktion einfügen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c88820",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Lösung:</b></summary>\n",
    "    \n",
    "```python\n",
    "def sigmoid(wert):\n",
    "    return 1/(1+np.exp(-wert))\n",
    "```\n",
    "</details>    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ecc74b",
   "metadata": {},
   "source": [
    "Im letzten Schritt berechnen Sie `y_hat` mit Hilfe von `z` und der `sigmoid` Funktion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1884de6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = sigmoid(_____)# welchen Input bracuht die Sigmoid Funktion?\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00c19ce",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Lösung:</b></summary>\n",
    "    \n",
    "```python\n",
    "y_hat = sigmoid(z)\n",
    "```\n",
    "</details>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49826684",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402df842",
   "metadata": {},
   "source": [
    "Wir Sie sehen können befinden sich nun alle Werte zwischen `0` und `1`. Eigentlich wollten wir Werte die `0` oder `1` sind, nicht Werte dazwischen. Tatsächlich können die Werte von `y_hat` als eine Art von Wahrscheinlichkeit verstanden werden. Eine vorhergesagter Wert von `0.99908895` bedeutet, das, laut dem Model, der Basketball zu 0.99% einen Korb macht. Andersrum eine Wert von `0.00135852` zeigt an, das, laut dem Model, nur eine Wahrscheinlichkeit von 0.14% besteht, einen Korb zu werfen.\n",
    "Im folgenden Bild sind die vorhergesagten Werte zusammen mit den vorhergesagten Bildern gezeigt. \n",
    "<img src='Img/intro_stats/log4.png' alt=\"Drawing\" width= \"500px\"/> \n",
    "\n",
    "Normalerweise werden die Wahrscheinlichkeiten so interpretiert, dass ab einen Wert `>0.5` das Model eine `1` vorhersagt und darunter eine `0`.\n",
    "\n",
    "Somit können wir die Genauigkeit des Models an Hand des Prozentsatz an richtig klassifizierten Würfen beurteilen. \n",
    "zunächt runden wir `y_hat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005df027",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.round(y_hat)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1991a172",
   "metadata": {},
   "source": [
    "Sie können auch vergleichen ob `pred` mit der ursprünglichen `y` Variable `körbe` übereinstimmt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ece7429",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred==körbe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c408ba8",
   "metadata": {},
   "source": [
    "Schreiben Sie eine Funktion, die die Accuracy berechnet (prozentualen Anteil von korrekt klassfizierten Würfen). Denken Sie daran, dass `booleans`, also `True` und `False`, auch als `1` und `0` in Python gelten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03708c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    return _____ y_true==y_pred __ / ________ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713040f5",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Lösung:</b></summary>\n",
    "    \n",
    "```python\n",
    "def accuracy(y_true, y_pred):\n",
    "    return np.sum(y_true==y_pred)/len(y_true)\n",
    "```\n",
    "</details> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fe0de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy(körbe, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6251f4c7",
   "metadata": {},
   "source": [
    "## Cross Entropy Loss\n",
    "\n",
    "Eine Accuarcy von 0.73 bedeutet, dass das Model in 73% der Fälle das richtige Ergebnis vorhergesagt hat. Ähnlich wie der RMSE ist eine Metrik um ein zuschätzen wie gut unsere Model ist.\n",
    "\n",
    "Oft wird aber nicht nur eine Metrik benutzt. Der Vorteil der Accuarcy ist, das sie sehr leicht zu interpretieren ist. Aber manche mathematischen Eigenschaften der Accuarcy machen sie ungeignet für bestimmte Prozesse bei machinellen Lernen. Deswegen werden meistens mindesten zwei verschiedenen Metriken angeschaut. \n",
    "\n",
    "Die Metrik die bei Klassifizierung benutzt wird ist der **Cross Entropy** Loss. Im Falle eines binären Klassifizierungsproblem reden wir dann meistens vom  **Binary Cross Entropy** Loss. \n",
    "\n",
    "$$Loss =-\\frac{1}{n}\\sum_{i=0}^n[y_i\\cdot log(\\hat{y}_i) + (1-y_i)\\cdot log(1-\\hat{y}_i)]$$\n",
    "\n",
    "Die Formel sieht zunächst sehr kompliziert aus, ist aber relativ einfach an Hand von Beispielen zu verstehn.\n",
    "Angenommen wir wollen den Loss nur für einen einzigen Datenpunkt berechnen zum Beispiel einen einzigen Wurf des Basketballers. Dann bbrauchen wir zunächst nur diese Formel:\n",
    "\n",
    "\n",
    "$$Loss =-[y_i\\cdot log(\\hat{y}_i) + (1-y_i)\\cdot log(1-\\hat{y}_i)]$$\n",
    "\n",
    "##### Angenommen der Basketballer der Basketballer hat den Wurf nicht getroffen, dann ist $y_i=0$.\n",
    "\n",
    "<img src='Img/intro_stats/bce_1.gif' alt=\"Drawing\" width= \"500px\"/> \n",
    "\n",
    "Daraus resultiert:\n",
    "$$Loss =-0\\cdot log(\\hat{y}_i) + (1-0)\\cdot log(1-\\hat{y}_i)$$\n",
    "$$Loss =-log(1-\\hat{y}_i)$$\n",
    "\n",
    "Das heißt der Loss für diesen Wurf ergibt sich aus dem $log$ der Differenz von 1 und $\\hat{y}$ (der vorhergesagten Wahrscheinlichkeit) \n",
    "\n",
    "Sie können ausprobieren was mit dem Loss passiert für unterschiedliche Wahrscheinlichkeiten. Denken Sie daran, dass der wahre Wert $y_i=0$ ist. Also ein gute Model würde ein geringe Wahrscheinlichkeit vorhersagen, also ist ein geringer Los zu erwarten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287505e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setzen Sie verschieden Wahrscheinlichkeiten in die Formel unten ein und schauen Sie was mit dem Loss passiert.\n",
    "\n",
    "np.log(1 - 0.___ ) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e35621a",
   "metadata": {},
   "source": [
    "Zunächst fäll auf das der Loss immer negativ ist, deswegen ist in der eigentlichen Formlen von oben noch ein minus um den Loss wieder postiv zu machen. \n",
    "\n",
    "Sie können erkennen, dass wenn besonders hohe Wahrscheinlichkeiten vorhergesagten werden  entfernt sich der Loss von Null. Wenn besonders kleine Wahrscheinlichkeiten eingesetzt werden, nähert sich der Loss Null. Das heißt also je \"falscher\" unsere Model ist desto größer wird der Loss, also genau das was wir wollen.\n",
    "\n",
    "##### Angenommen unser Baskebtaller hat den Wurf getroffen, dann ist $y_i=1$\n",
    "<img src='Img/intro_stats/bce_2.gif' alt=\"Drawing\" width= \"500px\"/> \n",
    "$$Loss =-1\\cdot log(\\hat{y}_i) + (1-1)\\cdot log(1-\\hat{y}_i)$$\n",
    "$$Loss =-log(\\hat{y}_i)$$\n",
    "\n",
    "Diesmal bleibt ein andere aber immer noch simpler Teil der Formel übrig.\n",
    "Probieren Sie auch diesem Term mit verschiedene Wahrscheinlichkeiten aus. \n",
    "Diesmal wäre eine Wahrscheinlichkeit nahe 1 richtig, sollte also zu einem geringem Loss führen.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04763e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "-np.log(0.___)# setzen Sie hier verschiedene Wahrscheinlichkeiten ein"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b493840c",
   "metadata": {},
   "source": [
    "Auch hier wird der Loss größer, wenn die Wahrscheinlcihkeit sich vom wahren Wert entfernt. \n",
    "\n",
    "Der Loss ist also nur so komplex um sowohl einen wahren Wert von `1` also auch von `0` abzudecken. Der `log` wird benutzt damit Werte die weiter entfernt vom wahren Wert sind, einen überproportionalen Einfluss auf den Loss haben. Der ursprüngliche Teil $\\frac{1}{n}\\sum_{i=1}^n$ berechnet nur ne Durchschnitt über alle Datenpunkt im Datensatz. \n",
    "Unten wird die Formel für den BCE mit `numpy` definiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd9290c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BCE(y_true, y_hat):\n",
    "    return -np.mean(y_true*np.log(y_hat) +(1-y_true)* np.log(1-y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1165b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "BCE(körbe, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1c723a",
   "metadata": {},
   "source": [
    "## ROC-AUC \n",
    "\n",
    "Als letztes führen wir den ROC-AUC, als eine Alternativem zur Accuracy, ein. Den AUC kennen Sie vielleicht  von einer HPLC oder NMR. Es bezeichnet die *Area under Curve*, also die Fläche unter einer Kurve. In diesem Fall geht es um die Fläche unter der ROC Kurve. \n",
    "\n",
    "Bevor wir uns genauer mit dieser ROC Kurve beschäftigen, klären wir warum wir überhaupt eine Alternative für die Accuarcy benutzen. \n",
    "\n",
    "Angenommen, ihr schreibt ein Programm das zwischen Hunden und Katzen unterscheiden soll.\n",
    "Ihr hab neun Bilder von Hunden und nur eins von einer Katze. \n",
    "\n",
    "<img src='Img/intro_stats/catvdogs.png' alt=\"Drawing\" width= \"500px\"/> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4fba0fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([\"HUND\", \"KATZE\", \"HUND\",\"HUND\",\"HUND\",\"HUND\",\"HUND\",\"HUND\",\"HUND\",\"HUND\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa372ff9",
   "metadata": {},
   "source": [
    "Es gibt eine sehr großen Unterschied zwischen der Anzahl von Katzen zu Hunden im Datensatz. \n",
    "Können Sie eine Möglichkeit finden immer eine Accuracy von 90% zu erhalten ohne die Bilder je gesehen zu haben und diese zufällig angeordnet werden?\n",
    "Die Funktion `shuffle` ordnet die Element jedes mal auf neures in zufälliger Reihenfolge an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2dfb0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle(y) # ordnet die Elemente im Array zufällig an \n",
    "y_pred = np.array([___,____,____,____,_____,_____,____,____,____,_____])# schreiben sie hier ihre Antwort\n",
    "accuracy(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce419c5d",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Lösung:</b></summary>\n",
    "    \n",
    "```python\n",
    "y_pred = np.array([\"HUND\", \"HUND\", \"HUND\",\"HUND\",\"HUND\",\"HUND\",\"HUND\",\"HUND\",\"HUND\", \"HUND\"]) \n",
    "```\n",
    "</details> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7345eb",
   "metadata": {},
   "source": [
    "Wenn Sie einfach jedes Bild als Hund klassifizieren erhalten Sie immer eine Accuracy von 0.9. \n",
    "Das heißt, ohne das ein Modell etwas im Bild erkennt kann es eine Genauigkeit von 0.9 erreichen. \n",
    "Wir können also an Hand der Genauigkeit nicht wirklich erkennen ob unser Model etwas gelernt hat oder einfach immer nur `\"HUNDE\"` sieht. \n",
    "Je größer das Ungleichgewicht zwischen den verscheidenen Klassen (*class inbalance*) ist z.B. `HUND` vs `KATZE`, desto weniger wertvoll ist die Accuracy als eine Metrik. \n",
    "\n",
    "Dafür gibts es alternative Metriken die besser für Klassifizierungen mit *class inbalance* geeignet sind. Dazu gehört auch der ROC-AUC.\n",
    "\n",
    "ROC bezeichnet die Receiver Operator Characteristic, eine Kurve die das Verhältnis von der *True Positive Rate* zur *False Positive Rate* bezeichnet. Der AUC ist die Fläche unter der ROC Kurve.\n",
    "\n",
    "<img src='Img/intro_stats/roc_auc.png' alt=\"Drawing\" width= \"300px\"/> \n",
    "\n",
    "*Was bedeuten True and False Positve Rate?*\n",
    "Angenommen wir hätten Hunde als `1` und Katze als `0` codiert. Dann würde die True Positive Rate (TPR), den Prozentsatz der korrekt identifzierten Hunde Bilder wiedergebem.\n",
    "\n",
    "$$TPR = \\frac{\\textrm{Anzahl korrekt klassifizierete Hunde Bilder}}{\\textrm{Anzahl aller Hunde Bilder }}$$\n",
    "\n",
    "\n",
    "Angenommen das Model erkennt jedes Bild als Hund, was ist die True Positive Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e179fe1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "TPR = ___/___ \n",
    "TPR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589a01f4",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Lösung:</b></summary>\n",
    "    \n",
    "```python\n",
    "TPR = 9/10\n",
    "```\n",
    "</details> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a75b79e",
   "metadata": {},
   "source": [
    "Wir Sie sich denken können ist die False Positive Rate (FPR)sehr ähnlich.  Hier geht es diesmal die Katzen\n",
    "$$FPR= \\frac{\\textrm{Anzahl Katzen die als Hund klassifiziert wurden}}{\\textrm{Anzahl aller Katzen Bilder}}$$\n",
    "Angenommen das Model erkennt jedes Bild als Hund, was ist die True Positive Rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87167b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "FPR = ___/___\n",
    "FPR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3240d2",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Lösung:</b></summary>\n",
    "    \n",
    "```python\n",
    "TPR = 0/1\n",
    "```\n",
    "</details> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364c30e8",
   "metadata": {},
   "source": [
    "Nun etwas förmlicher:  Der ROC-AUC gibt Auskunft über das Verhätnis von wie gut ein Model im Hude erkennen ist versus wie schlecht es im Katzen erkennen ist. Die Berechnung des ROC AUC ist ewtas komplizierter als nur dir FPR und TPR auszurechnen. \n",
    "Aber es ist wichtig über diese Abhängigkeiten bescheid zu wissen. \n",
    "Ein ROC AUC Wert liegt immer zwischen 0 und 1. Eine 1 bedeute eine perfekte Klassifizierung, und eine Wert von 0.5 weißt auf eine rein zufällige Entscheidung hin. \n",
    "Zum berechnen können wir die Funktion `roc_auc_score` von `sklearn` benutzen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5dd87452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "y_true = np.array([1,0,1,1,1,1,1,1,1,1]) # Wir haben diesmal Hunde und Katzen in 1 und 0 umcodiert\n",
    "y_pred = np.array([1,1,1,1,1,1,1,1,1,1])\n",
    "roc_auc_score(y_true ,y_pred )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf69835d",
   "metadata": {},
   "source": [
    "Sie können sehen, dass der ROC AUC Wert nur bei 0.5 liegt also unser Model ist nicht besser als eine zufällige Entscheidung ist.\n",
    "In der Praxis, arbeiten wir aber mit vorhergesagten Wahrscheinlichkeiten, also Werte zwischen 0 und ein 1, anstatt mit nur `0` und `1`. Auch damit kann man den ROC AUC score berechnen.\n",
    "\n",
    "Probieren Sie die Wahrscheinlichkeiten der Katze zu verändern (zweite Position)?\n",
    "Denken Sie daran, dass wir ein Bild ab einem Wert von 0.5 als Hund klassifizieren. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "35c0cdfe",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '____' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_70202/2904341862.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Wir haben diesmal Hunde und Katzen in 1 und 0 umcodiert\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.91\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m____\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.99\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.99\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.99\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.98\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.97\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0my_hat\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name '____' is not defined"
     ]
    }
   ],
   "source": [
    "y_true = np.array([1,0,1,1,1,1,1,1,1,1]) # Wir haben diesmal Hunde und Katzen in 1 und 0 umcodiert\n",
    "y_hat = np.array([0.91,____,0.99,0.99,0.99,0.98,0.8,0.7,0.8,0.97])\n",
    "roc_auc_score(y_true ,y_hat )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6a83e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
