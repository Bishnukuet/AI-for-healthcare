{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Einführung Statistik\n",
    "\n",
    "Wir werden heute ein paar wenige Grundlagen zur Statistik anschauen.\n",
    "Statistik kann uns helfen Daten einfach zu beschreiben und erklären. \n",
    "\n",
    "---\n",
    "\n",
    "### Lernziele\n",
    "* Wiederholung von Mittelwert, Varianz und Standardabweichung in Python\n",
    "* Sie verstehen den Unterschied zwischen eine Regression und einer Klassifikation\n",
    "* Sie verstehen die Funktion einer linearen Regression und was ihre Koeffizienten bedeuten\n",
    "* Sie verstehen den Root Mean Square und die Funktion der Loss Funktion\n",
    "* Sie verstehen die logistische Regression und die Ähnlichkeit zu einer linearen Regression.\n",
    "* Sie verstehen den BCE und Metriken wie die Accuracy und ROC-AUC\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import shuffle\n",
    "%matplotlib inline\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir können uns zum Beispiel die Abiturnoten einer bestimmten Klasse anschauen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abi_klasse = [1.64, 2.35, 1.88, 2.48, 2.16, 3.92, 2.16, 2.  , 1.76, 2.82, 1.81,\n",
    "       2.59, 3.03, 1.7 , 2.87, 3.21, 2.65, 1.97, 1.2, 1.67, 1.77, 1.98,\n",
    "       3.4 , 1.31, 1.72, 2.05, 1.12 , 1.56, 2.01, 2.1 ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Allerdings ist es sehr schwer nur mithilfe der Daten eine Übersicht zubekommen.\n",
    "Einfacher ist es sich die Noten aufzuzeichnen.\n",
    "\n",
    "\n",
    "<img src='Img/intro_stats/noten_1.png'></img>\n",
    "\n",
    "Obwohl Sie jetzt eine bessere gesamt Übersicht haben, könnte es Ihnen schwerfallen zwei Klassen miteinander zu vergleichen.\n",
    "\n",
    "<img src='Img/intro_stats/noten2.1.png'></img>\n",
    "\n",
    "Wir können **density plots** benutzen um die Verteilung einfach Darstellen. Hier wird die y-Achse benutzt, um die Dichte darzustellen. Das heißt je höher der Graph an einem Punkt ist, desto mehr der Datenpunkte befinden sich an dieser Stelle. \n",
    "\n",
    "<img src='Img/intro_stats/noten_3.1.png'></img>\n",
    "Oft reicht eine rein visuelle Inspektion nicht, um eindeutige Entscheidungen zu treffen.\n",
    "Hierfür werden Metriken benötigt, die die Verteilung von Datenpunkten, wie die Abinoten, beschreiben.\n",
    "\n",
    "Am wohl bekanntesten ist der Mittelwert, genauer gesagt das arithmetische Mittel. Es beschreibt den Durchschnitt einer Verteilung von Datenpunkten. \n",
    "Und das arithmetische Mittel zu berechnen wird die Summe aller Werte durch die Anzahl der Werte geteilt.\n",
    "\n",
    "\n",
    "$$\\bar{x} = \\frac{1}{n}\\sum_{i=1}^n x_i$$\n",
    "\n",
    "Der Mittelwert wird oft durch $\\bar{x}$ gekennzeichnet.\n",
    "Berechnen Sie das arithmetische Mittel in Python für die Klasse aus. *Ohne dabei Numpy zu benutzen*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mean_abiklasse = _____________# Formel für den Mittelwert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Lösung:</b></summary>\n",
    "    \n",
    "```python \n",
    "mean_abiklasse = sum(abi_klasse)/len(abi_klasse)\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doch der Mittelwert reicht nicht, um eine Verteilung von Werten adäquate zu beschrieben. Zum Beispiel, haben die beiden [Normal Verteilungen](https://de.statista.com/statistik/lexikon/definition/95/normalverteilung/) im Beispiel den gleichen Mittelwert und trotzdem sind Sie nicht identisch verteilt. \n",
    "<img src='Img/intro_stats/noten_3.png'></img>\n",
    "\n",
    "Wir können sehen, dass die orange Verteilung viel schmaler ist als die blaue. Das heißt die Werte der orangen Gruppe liegen näher an ihrem Durchschnitt als die der blauen Gruppe.\n",
    "Die Breite einer Verteilung wird durch die Varianz gemessen. Die Varianz misst den durchschnittlichen Abstand der Werte zu ihrem Mittelwert. \n",
    "\n",
    "Die Varianz ($s^2$) wird wie folgt berechnet:\n",
    "\n",
    "$$s^2 = \\frac{1}{n}\\sum_{i=1}^n(x_i-\\bar{x})^2$$\n",
    "\n",
    "Beachten Sie, dass nicht die Differenz ($x_i-\\bar{x}$), sondern das Quadrat ($x_i -\\bar{x})^2$ der Differenz summiert wird. Somit haben größere Abstände einen größeren Einfluss auf die Varianz. \n",
    "\n",
    "Berechnen Sie die Varianz der `abi_klasse`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varianz_abiklasse = sum(________________ )/(len(abi_klasse)# Ihr braucht wahrscheinlich einen for-loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Lösung:</b></summary>\n",
    "    \n",
    "```python\n",
    "sum([(x - mean_abiklasse)**2 for x in abi_klasse])/(len(abi_klasse))\n",
    "```\n",
    "</details>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<details>\n",
    "<summary><b>Lösung: for-loop ausgeschrieben</b></summary>\n",
    "\n",
    " ```python\n",
    "quadrate = 0\n",
    "for x in abi_klasse:\n",
    "    quadrate = quadrate +((x-mean_abiklasse)**2)\n",
    "varianz_abiklasse = quadrate/len(abi_klasse) \n",
    "```\n",
    "</details>   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oft wird auch die Standardabweichung als Maß für die *Breite* eine Verteilung benutzt. Die Standardabweichung erhält man durch das Ziehen der Wurzel der Varianz. Damit wird das Maß der Varianz auf die Skala der ursprünglichen Verteilung gebracht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_abiklasse = __________ #Berechnen Sie die Standardabweichung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Lösung:</b></summary>\n",
    "    \n",
    "```python\n",
    "std_abiklasse= varianz_abiklasse**(0.5)\n",
    "```\n",
    "</details>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Natürlich gibt es alle Funktionen auch schon in numpy: `np.mean()`,`np.std()`,`np.var()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print(\"Mittelwert: \", np.mean(abi_klasse))\n",
    "print(\"Varianz: \", np.var(abi_klasse))\n",
    "print(\"Standard Abweichung: \", np.std(abi_klasse))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit dem Maß der Varianz/Standard und dem Mittelwert können wir schon \n",
    "einige Verteilungen beschreiben. Natürlich nicht alle, z.B. bei \n",
    "multimodalen Verteilungen bräuchte man noch mehr Informationen. \n",
    "\n",
    "<img src='Img/intro_stats/noten_4.png'></img>\n",
    "\n",
    "## Inferentielle Statistik \n",
    "\n",
    "Allerdings wollen wir nicht immer nur Daten beschreiben, sondern wir wollen auch Informationen von diesen Daten gewinnen. \n",
    "Mithilfe\n",
    " der Korrelation können wir zum Beispiel den Zusammenhang von \n",
    "Körpergröße zu Gewicht beschrieben. Je größere ein Mensch ist, desto \n",
    "schwerer ist er. Dieses Model ist natürlich nicht perfekt, das \n",
    "Körpergewicht ist natürlich nicht nur von der Körpergröße abhängig. Es \n",
    "gibt große leichte Menschen und kleine schwerere. Aber es gibt eine \n",
    "zugrunde liegende Tendenz. \n",
    "\n",
    "<table><tr>\n",
    "<td> <img src='Img/intro_stats/reg_1.png' alt=\"Drawing\" style=\"width: 250px;\"/> </td>\n",
    "<td> <img src='Img/intro_stats/reg_2.png' alt=\"Drawing\" style=\"width: 250px;\"/> </td>\n",
    "</tr></table>\n",
    "\n",
    "Wir können die Beziehung mit einer linearen Regression beschreiben.\n",
    "Sie kennen vielleicht noch aus der Schule die Geradengleichung $y = mx+t$ (oder $y = ax+b$). \n",
    "<br>\n",
    "\n",
    "\n",
    "\n",
    "- $x$ ist die Input-Variable, in unserem Falle die Körpergröße\n",
    "- $y$ ist die vorherzusagende Variable (Körpergewicht)\n",
    "- $m$ beschreibt die Steigung der Geraden\n",
    "- $t$ gibt den y-Achsenabschnitt an, der Wert von $y$ wenn $x=0$\n",
    "\n",
    "<img src='Img/intro_stats/reg_3.png' alt=\"Drawing\" width=\"500\"/>\n",
    "\n",
    "Angenommen die Gleichung der Regressionsgeraden wäre $y=0,3x+21$ dann wäre zum \n",
    "Beispiel, das Gewicht einer Person mit einer Größe von 180 cm, 75 kg \n",
    "($0,3\\cdot180+21)$.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Der Wert für $m$ ($0,3$) gibt an, um wie viel $y$ steigt, wenn $x$ sich um 1 erhöht.\n",
    "Also laut dem Model steigt das Körpergewicht um 0,3 kg pro 1 cm Größe. \n",
    "\n",
    "Der Wert für $t$ gibt an, wie viele eine Person wiegt, die 0 cm groß ($x=0$) ist. Im Fall der Körpergröße ergibt es wenig Sinn den Wert für $t$ zu interpretieren. Aber angenommen, wir schätzen den Wert eines Hauses anhand der Größe der Terrasse. Der Wert für $t$ gibt den Wert eines Hauses an, wenn die Terrassengröße $0$ ist. Also der Wert ohne Terrasse ist $t$.\n",
    "\n",
    "Zurück zum eigentlichen Beispiel: \n",
    "\n",
    "Natürlich wiegt nicht jede 180 cm große Person 66 kg. Das ist nur der vorhergesagte Wert \n",
    "unsere Regressionsgleichung. Um das eindeutig zu kennzeichnen, schreiben wir $\\hat{y}$ anstatt $y$.\n",
    "Dadurch wird die Geradengleichung zu $\\hat{y}=mx+t$.\n",
    "\n",
    "---\n",
    "\n",
    "Schreiben Sie eine Funktion, die das Gewicht anhand der oben beschriebenen Geradengleichung berechnet.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg(x,m,t):\n",
    "    _________# Was soll diese Funktion ausgeben?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Lösung:</b></summary>\n",
    "    \n",
    "```python\n",
    "def reg(x,m,t):\n",
    "    return m*x+t\n",
    "```\n",
    "</details>    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Variable `x` enthält die Größen in cm von 5 Personen. Für diese fünf Personen berechnen Sie das Gewicht mithilfe der Funktion `reg`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [182,167,198,132,178]\n",
    "y_hat = [reg(__,__,__) for ___ in _____ ]\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Lösung:</b></summary>\n",
    "    \n",
    "```python\n",
    "y_hat = [reg(gewicht,0.3,21) for gewicht in x ]\n",
    "```\n",
    "</details>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Werte sind natürlich nur eine Schätzung des Gewichtes, und weichen von dem tatsächlichen Gewicht der Person ab. Um zu beurteilen, wie gut unsere Model das Gewicht bestimmen kann, brauchen wir auch das tatsächliche gemessene Gewicht der Personen. Diese sind in `y` gegeben. Wir können zum Beispiel die Differenz von `y_hat` und `y` berechnen. Dafür müssen wir aber erst einmal die Listen zu `numpy` Arrays konvertieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([78.2,68.3, 81.0,64.3, 70.1 ])\n",
    "y_hat = np.array(y_hat)\n",
    "residual = y - ___ # was ziehen wir von y ab?\n",
    "residual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diese Differenz zwischen dem tatsächlichen und dem vorhergesagten Wert($y - \\hat{y}$) wird auch als Residuum bezeichnet. Als Symbol für das Residuum wird meisten das kleine Epsilon ($\\epsilon$) verwendet, hiermit wird die Größe des Fehlers (**E**rror) der Vorhersage gemessen. \n",
    "\n",
    "<img src='Img/intro_stats/reg_4.png' alt=\"Drawing\" width=\"500\"/>\n",
    "\n",
    "Um Einschätzen zu können wie gut unsere Model insgesamt ist können wir zum Beispiel die Residuen einfach summieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(residual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie Sie sehen ist der Wert sehr nahe bei null. Eigentlich ein sehr geringer Fehler. Das Problem ist aber, dass Residuen sowohl positiv als auch negativ sein können. Das heißt beim Summieren gleichen Sie sich aus. Man wird immer Werte in der Nähe von null erhalten. Um das zu umgehen, summieren deswegen nicht die Residuen, sondern, wie bei der Varianz, die Quadrate der Residuen. $$\\sum_{i=1}^{n}(y_i-\\hat{y}_i)^2$$ \n",
    "\n",
    "Die Summe alleine, würde aber dazu führen, dass Modelle die mehr Datenpunkte haben, also ein größeres $n$, automatische größere Summen haben werden. Deswegen nehmen wir nicht die Summe, sondern den Mittelwert der Quadrate: $\\frac{1}{n}\\sum_{i=1}^{n}(y_-\\hat{y}_i)^2$. Dieser Wert, *Mean Squared Error* (MSE) genannt, eignet sich, um die Güte der Vorhersagen zu beurteilen. Wenn ein Model einen kleinen MSE hat können Sie daraus schlussfolgern, dass die Residuen klein sein müssen, also die Unterschiede zwischen vorhergesagten um wahren Wert klein sind. \n",
    "\n",
    "So wie bei der Varianz und Standard Abweichung gibt es auch den Root Mean Squared Error (RMSE). Wie Sie sich denken können, wird einfach die Wurzel vom MSE genommen. Schreiben Sie eine Funktion, die den RMSE berechnen kann. Sie dürfen `numpy` benutzen, das heißt Sie brauchen keinen for-loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(y,y_hat):\n",
    "   MSE = np.sum(__________________) /len(_____) #Hier wird der MSE berechnet, \n",
    "   return ___________ # Wir wollen nicht den MSE sonder den RMSE. Konvertieren Sie den MSE zum RMSE\n",
    "RMSE(y, y_hat)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Lösung:</b></summary>\n",
    "    \n",
    "```python\n",
    "def RMSE(y,y_hat):\n",
    "   MSE = np.sum((y-y_hat)**2)/len(y)\n",
    "   return np.sqrt(MSE) \n",
    "```\n",
    "</details>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im maschinellen Lernen, oder allgemein im Feld der Optimierung, werden Funktionen wie den RMSE auch als Loss Funktion bezeichnet. Sie messen wie gut ein Model, dessen Parameter, zu den Daten passen. Den Loss, berechnet durch die Loss Funktion, gilt es zu minimieren. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beispiel\n",
    "\n",
    "Bis jetzt haben Sie immer die Parameter `m` und `t` vorgegeben bekommen. In der Realität müssen Sie diese selber berechnen (lassen). Im folgenden Beispiel werden wir uns mit der Vorhersage von Siedepunkt befassen. Dafür benutzen wir einen Datensatz des amerikanischen *National Institute of Standards and Technology*. Im Datensatz sind die Siedetemperaturen für 72 einfache Alkohole aufgezeichnet. Dazu wird noch das molekulare Gewicht und die Anzahl der Kohlenstoffe angegeben. \n",
    "Der Datensatz befindet sich im Ordner `../data/boilingpoints/`\n",
    "\n",
    "Wir benutzen diesmal `numpy⁣`, um unseren Datensatz einzulesen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.genfromtxt('../data/boilingpoints/bp.csv', delimiter=',', skip_header =True)\n",
    "print(\"Größe der Daten: \",data.shape)\n",
    "data[:10,:] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Datensatz besteht aus 72 Reihen und 3 Spalten. Jede Reihe repräsentiert einen Alkohol und die 3 Spalten sind Deskriptoren. Die erste Spalte enthält die Schmelzpunkte, die zweite das molekulare Gewicht und die dritte Spalte die Anzahl der Kohlenstoffe. \n",
    "\n",
    "Unser Ziel ist es mithilfe des molekularen Gewichtes den Schmelzpunkt vorher zusagen.\n",
    "Zunächst speichern wir die erste Spalte(Schmelzpunkte) in die Variable `y` und die zweite Spalte in die Variable `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[:,0] # y ist unsere zuvorhersagende Variable (Schmelzpunkte)\n",
    "x = data[:,1:2] # Wir könnten auch data[:,1] benutzen, verhält sich leicht anders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data[:5,1])\n",
    "print(data[:5,1:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sie können sehen, dass wir dieselben Werte auswählen, allerdings reduzieren wir die Spalte in der ersten Variante zu einem 1-dimensionales Array der Größe `(72)`. Also einem Vektor der Länge 72. Mancher der Funktionen notwendig für eine lineare Regression erwarten, dass sich unsere `x` Variable in Form eines 2-dimensionalen Array befindet. Deswegen wählen wir die Spalte mit `data[:,1:2]` aus.\n",
    "\n",
    "Sie können die Daten auch grafisch darstellen, dafür benutzen wir die Library `matplotlib`. Mit der `plt.plot()` Funktion können Sie schnell einfache Graphen erstellen. Hierbei müssen Sie nur angeben welche Werte auf die x-Achse angeben (erste Position in der Funktion), dann geben Sie an was auf die y-Achse gehört (zweite Position). Als Letztes können Sie spezifizieren, ob die einzelnen Werte als Punkt `\"o\"` oder mit einer Linie verbunden werden soll `\"-\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(x, y, \"o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir können klar sehen, dass mit steigendem Gewicht auch der Siedepunkt der Alkohole steigt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(x,y) # berechnet die Regressions Gerade\n",
    "m = model.coef_[0] # Wir können m und t aus model() erhalten.\n",
    "t = model.intercept_\n",
    "\n",
    "print(m,t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Berechnen Sie mit den Parametern `y_hat` und anschließend den `RMSE`.\n",
    "Da wir jetzt `numpy` `arrays` benutzen wird kein `for loop` benötigt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_hat = reg(data[:,1], ___ , ____)\n",
    "RMSE(y, ____) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Lösung:</b></summary>\n",
    "    \n",
    "```python\n",
    "y_hat = reg(data[:,1], m , t)\n",
    "RMSE(y, y_hat) \n",
    "```\n",
    "</details>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Können Sie andere Werte für `m` und `t` finden, die zu einen geringer RMSE führen? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = reg(data[:,1], ____  ,  _____  )\n",
    "RMSE(y, y_hat) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tatsächlich geht dies nicht. Wenn wir über eine lineare Regression sprechen, reden wir meisten von einer *ordinary least-square* Regression. Wie Sie dem Namen entnehmen können, minimiert diese Regression die \"Squares\"also den Fehler der Regressionsgerade. Das heißt die Regressionsgerade, ist die optimale Gerade, die für diesen Datensatz gefunden werden kann. Anders gesagt einer OLS Regressionsgerade minimiert den (R)MSE.\n",
    "\n",
    "## Multiple Regression\n",
    "\n",
    "Lineare Regression können auch mit mehr als nur einer $x$ Variable durchgeführt werden. Die Formel erweitert sich auf:\n",
    "\n",
    "$$\\hat{y}= \\beta_0 +\\beta_1x_1 +\\beta_2x_2$$\n",
    "\n",
    "$mx+t$ kenne Sie vielleicht noch aus der Schule, im Allgemeinen hat sich aber die Notation mit $\\beta$ durchgesetzt. Hierbei steht $\\beta_0$ für das $t$ und $\\beta_1$ für den Regressionskoeffizienten der zur ersten Input-Variable $x_1$ gehört.\n",
    "\n",
    "An der Interpretation dieser Koeffizienten ändert sich aber nichts.\n",
    "\n",
    "Wir können sowohl die Anzahl der Kohlenstoffe als auch das Gewicht benutzen, um die Schmelzpunkte vorherzusagen.\n",
    "\n",
    "Damit das klappt, müssen Sie zunächst nicht nur die zweite, sondern auch die dritte Spalte von `data` in `x` auswählen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data[:,1: ___ ] # Welche Spalten nehmen Sie mit nach x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Lösung:</b></summary>\n",
    "    \n",
    "```python\n",
    "x = data[:,1:3]\n",
    "```\n",
    "</details>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sie können jetzt die Regressionskoeffizienten wieder mit `LinearRegression` schätzen lassen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = LinearRegression()\n",
    "model_2.fit(x,y) # berechnet die Regressions Gerade\n",
    "print(model_2.coef_, model_2.intercept_ ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie Sie sehen, erhalten Sie jetzt insgesamt 3 Parameter. Der Regressionskoeffizient für das molekulare Gewicht ist `-4.65` und für die Anzahl der Kohlenstoff `83.18`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat =model.predict(x)\n",
    "RMSE(y, y_hat) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistische Regression\n",
    "\n",
    "Es gibt auch Probleme in denen nicht exakte Werte vorhergesagt werden sollen. Wir wollen zum Beispiel entscheiden, ob ein Patient auf die Intensivstation muss oder nicht. Hierbei muss nur zwischen `JA` oder `NEIN` entschieden werden. In mathematischen Termen würden wir aber von `1` oder `0` sprechen. Wir sprechen von einer binären Klassifizierung, wenn ein Datenpunkt zu einer von zwei Gruppen gehören kann. \n",
    "\n",
    "Hier haben wir ein Beispiel von einem Basketballspieler der auf den Korb aus verschiedenen Distanzen wirft. \n",
    "Macht er einen Korb wird dieser Wurf mit einer `1` gekennzeichnet. Trifft er nicht wird diesem Wurf eine `0` zugeordnet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "körbe = np.array([1,1,1,1,1,1,0,1,0,1,1,0,0,1,1,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0])    \n",
    "distanz = np.array([0.,1.,2.,3.,4.,5.,6.,7.,8.,9.,10.,11.,12.,13.,14.,\n",
    "                    15.,16.,17.,18.,19.,20.,21.,22.,23.,24.,25.,26.,27.,28.,29.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es ist zwar möglich eine simple Regressionsgerade zu berechnen, diese passt aber aufgrund der binären $y$ Variable nicht sehr gut zu den Daten. Eine Lösung ist die logistische Regression. Hier wird \"nach\" der lineare Regression eine Sigmoid Funktion benutzt, um die vorhergesagten Werte zu transformieren. \n",
    "\n",
    "<table><tr>\n",
    "<td> <img src='Img/intro_stats/log1.png' alt=\"Drawing\" style=\"width: 250px;\"/> </td>\n",
    "<td> <img src='Img/intro_stats/log2.png' alt=\"Drawing\" style=\"width: 250px;\"/> </td>\n",
    "<td> <img src='Img/intro_stats/log3.png' alt=\"Drawing\" style=\"width: 250px;\"/> </td>\n",
    "</tr></table>\n",
    "<br>\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "<center>\n",
    "<h2>Sigmoid Funktion</h2>\n",
    "</center>\n",
    "\n",
    "Die Sigmoid Funktion ist eine nicht lineare Funktion. Mathematische wird die Sigmoid Funktion so geschrieben:\n",
    "$$sigmoid(z)= \\frac{1}{1+e^{-z}}$$\n",
    "\n",
    "\n",
    "Um zu verstehen, was sie genau macht, kann man sich das Beispiel anschauen.\n",
    "\n",
    "<td> <img src='Img/intro_stats/sigmoid.png' alt=\"Drawing\" style=\"width: 250px;\"/> \n",
    "    \n",
    "Auf der x-Achse sind Werte zwischen -6 und 6 **bevor** die Sigmoid Funktion auf diese Werte angewendet wird. Auf der y-Achse befinden sich dieselben Werte aber diesmal, nachdem die Sigmoid Funktion angewendet worden ist. \n",
    "Alle Werte befinden sich jetzt zwischen 0 und 1. Werte die vorher sehr weit entfernt waren von 0 werden sehr nah zu `0` oder `1` gesetzt.\n",
    "    \n",
    "Die Form dieser Funktion passt schon viel besser zu einer binären Klassifizierung.\n",
    "\n",
    "Um eine logistische Regression durchzuführen, können wir schon auf das Gelernte von der linearen Regression bauen.\n",
    "Wir haben die selbe Situation, wir wollen mithilfe von unserem Input `x`, eine Vorhersage für `y` machen.     \n",
    "Dafür werden die Werte aus der linearen Regression einfach in die Sigmoid Funktion gesetzt.\n",
    "$$ z = mx+t $$\n",
    "$$\\hat{y} = sigmoid(z) = \\frac{1}{1+e^{-z}} = \\frac{1}{1+e^{-(mx+t)}} $$    \n",
    "\n",
    "Berechnet nun z in dem ihr die reg_treffer auf die Werte Distanz anwendend. Da Sie jetzt NumPy benutzen können, brauchen Sie keinen for-loop mehr.\n",
    "Für das Beispiel mit dem Basketballer sind folgende Parameter vorgegeben:\n",
    "- `m` = -0.8\n",
    "- `t` = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_treffer(___):\n",
    "    return ___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Lösung:</b></summary>\n",
    "    \n",
    "```python\n",
    "def reg_treffer(distanz):\n",
    "    return -0.8*distanz+7\n",
    "```\n",
    "</details>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Berechnet nun `z` indem ihr die `reg` auf die Werte der Distanz anwenden.\n",
    "Da Sie jetzt `numpy` benutzen können brauchen Sie keinen for-loop mehr."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = reg(______) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Lösung:</b></summary>\n",
    "\n",
    "```python\n",
    "z = reg(distanz,-0.8,7) \n",
    "```\n",
    "</details>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als Nächstes benötigen Sie die Sigmoid Funktion. Schreiben Sie mithilfe von `numpy` eine Funktion in Python dafür. $e^x$ kann mithilfe von `numpy` als `np.exp(x)` geschrieben werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(wert):\n",
    "    return 1/(___________) #Hier den Nenner der sigmoid Funktion einfügen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Lösung:</b></summary>\n",
    "    \n",
    "```python\n",
    "def sigmoid(wert):\n",
    "    return 1/(1+np.exp(-wert))\n",
    "```\n",
    "</details>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im letzten Schritt berechnen Sie `y_hat` mithilfe von `z` und der `sigmoid` Funktion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = sigmoid(_____)# welchen Input braucht die Sigmoid Funktion?\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Lösung:</b></summary>\n",
    "    \n",
    "```python\n",
    "y_hat = sigmoid(z)\n",
    "```\n",
    "</details>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie Sie sehen können befinden sich nun alle Werte zwischen `0` und `1`. Eigentlich wollten wir Werte die `0` oder `1` sind, nicht Werte dazwischen. Tatsächlich können die Werte von `y_hat` als eine Art von Wahrscheinlichkeit verstanden werden. Ein vorhergesagter Wert von `0.99908895` bedeutet, das, laut dem Model, der Basketball zu 0.99 % einen Korb macht. Andersrum ein Wert von `0.00135852` zeigt an, das, laut dem Model, nur eine Wahrscheinlichkeit von 0.14 % besteht, einen Korb zu werfen.\n",
    "Im folgenden Bild sind die vorhergesagten Werte zusammen mit den vorhergesagten Bildern gezeigt. \n",
    "<img src='Img/intro_stats/log4.png' alt=\"Drawing\" width= \"500px\"/> \n",
    "\n",
    "Normalerweise werden die Wahrscheinlichkeiten so interpretiert, dass ab einem Wert `>0.5` das Model eine `1` vorhersagt und darunter eine `0`.\n",
    "\n",
    "Somit können wir die Genauigkeit des Models an Hand dem Prozentsatz an richtig klassifizierten Würfen beurteilen. \n",
    "Zunächst runden wir `y_hat`. Dadurch erhalten wir nur `0` und `1` als Vorhersagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.round(y_hat)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sie können auch vergleichen, ob `pred` mit der ursprünglichen `y` Variable `körbe` übereinstimmt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred==körbe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Schreiben Sie eine Funktion, die die Accuracy berechnet (prozentualen Anteil von korrekt klassifizierten Würfen). Denken Sie daran, dass `booleans`, also `True` und `False`, auch als `1` und `0` in Python gelten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    return _____ y_true==y_pred __ / ________ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Lösung:</b></summary>\n",
    "    \n",
    "```python\n",
    "def accuracy(y_true, y_pred):\n",
    "    return np.sum(y_true==y_pred)/len(y_true)\n",
    "```\n",
    "</details> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy(körbe, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Cross Entropy Loss\n",
    "\n",
    "Eine Accuarcy von 0.73 bedeutet, dass das Model in 73 % der Fälle das richtige Ergebnis vorhergesagt hat. Ähnlich wie der RMSE ist eine Metrik um einzuschätzen wie gut unsere Model ist.\n",
    "\n",
    "Oft wird aber nicht nur eine Metrik benutzt. Der Vorteil der Accuarcy ist, dass sie sehr leicht zu interpretieren ist. Aber manche mathematischen Eigenschaften der Accuracy machen sie ungeeignet für bestimmte Prozesse bei maschinellen Lernen. Deswegen werden meistens mindesten zwei verschiedenen Metriken angeschaut. \n",
    "\n",
    "Die Metrik, die bei Klassifizierung benutzt wird, ist der **Cross Entropy** Loss. Im Falle eines binären Klassifizierungsproblems reden wir  meistens vom  **Binary Cross Entropy** Loss. \n",
    "\n",
    "$$Loss =-\\frac{1}{n}\\sum_{i=0}^n[y_i\\cdot log(\\hat{y}_i) + (1-y_i)\\cdot log(1-\\hat{y}_i)]$$\n",
    "\n",
    "Die Formel sieht zunächst sehr kompliziert aus, ist aber relativ einfach an Hand von Beispielen zu verstehen.\n",
    "Angenommen wir wollen den Loss nur für einen einzigen Datenpunkt berechnen, zum Beispiel einen einzigen Wurf des Basketballers. Dann ist $n = 1$ und die Formel oben vereinfacht sich:\n",
    "\n",
    "\n",
    "$$Loss =-[y_i\\cdot log(\\hat{y}_i) + (1-y_i)\\cdot log(1-\\hat{y}_i)]$$\n",
    "\n",
    "##### Angenommen der Basketballer hat den Wurf nicht getroffen, dann ist $y_i=0$.\n",
    "\n",
    "<img src='Img/intro_stats/bce_1.gif' alt=\"Drawing\" width= \"500px\"/> \n",
    "\n",
    "Daraus resultiert:\n",
    "\n",
    "\n",
    "$$\\begin{align}\n",
    "Loss&=-0\\cdot log(\\hat{y}_i) + (1-0)\\cdot log(1-\\hat{y}_i)\\\\\n",
    "&=-log(1-\\hat{y}_i)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "\n",
    "Das heißt der Loss für diesen Wurf ergibt sich aus dem $log$ der Differenz von 1 und $\\hat{y}$ (der vorhergesagten Wahrscheinlichkeit).\n",
    "\n",
    "Sie können ausprobieren was mit dem Loss passiert für unterschiedliche Wahrscheinlichkeiten. Denken Sie daran, dass der wahre Wert $y_i=0$ ist. Also ein gutes Model würde eine geringe Wahrscheinlichkeit vorhersagen, also ist ein geringer Loss zu erwarten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setzen Sie verschieden Wahrscheinlichkeiten in die Formel unten ein und schauen Sie was mit dem Loss passiert.\n",
    "\n",
    "np.log(1 - 0.___ ) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zunächst fällt auf das der Loss immer negativ ist, deswegen ist in der eigentlichen Formeln von oben noch ein minus um den Loss wieder positiv zu machen. \n",
    "\n",
    "Sie können erkennen, dass wenn besonders hohe Wahrscheinlichkeiten vorhergesagten werden,  entfernt sich der Loss von null. Wenn besonders kleine Wahrscheinlichkeiten eingesetzt werden, nähert sich der Loss Null. Das heißt also je \"falscher\" unsere Model ist, desto größer wird der Loss, also genau das was wir wollen.\n",
    "\n",
    "##### Angenommen unser Basketballer hat den Wurf getroffen, dann ist $y_i=1$\n",
    "<img src='Img/intro_stats/bce_2.gif' alt=\"Drawing\" width= \"500px\"/> \n",
    "$$\\begin{align}Loss &=-1\\cdot log(\\hat{y}_i) + (1-1)\\cdot log(1-\\hat{y}_i)\\\\\n",
    "&=-log(\\hat{y}_i)\\end{align}$$\n",
    "\n",
    "Diesmal bleibt ein andere aber immer noch simpler Teil der Formel übrig.\n",
    "Probieren Sie auch diesem Term mit verschiedene Wahrscheinlichkeiten aus. \n",
    "Diesmal wäre eine Wahrscheinlichkeit nahe 1 richtig, sollte also zu einem geringem Loss führen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "-np.log(0.___)# setzen Sie hier verschiedene Wahrscheinlichkeiten ein"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auch hier wird der Loss größer, wenn die Wahrscheinlichkeit sich vom wahren Wert entfernt. \n",
    "\n",
    "Der Loss ist also nur so komplex um sowohl einen wahren Wert von `1` also auch von `0` abzudecken.  `log` wird benutzt damit Werte die weiter entfernt vom wahren Wert sind, einen überproportionalen Einfluss auf den Loss haben. Der ursprüngliche Teil $\\frac{1}{n}\\sum_{i=1}^n$ berechnet nur den Durchschnitt über alle Datenpunkt im Datensatz. \n",
    "Unten wird die Formel für den BCE mit `numpy` definiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BCE(y_true, y_hat):\n",
    "    return -np.mean(y_true*np.log(y_hat) +(1-y_true)* np.log(1-y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BCE(körbe, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC-AUC \n",
    "\n",
    "Als Letztes führen wir den ROC-AUC, als eine Alternativem zur Accuracy, ein. Den AUC kennen Sie vielleicht  von einer HPLC oder NMR. Es bezeichnet die *Area under Curve*, also die Fläche unter einer Kurve. In diesem Fall geht es um die Fläche unter der ROC Kurve. \n",
    "\n",
    "Bevor wir uns genauer mit dieser ROC Kurve beschäftigen, klären wir, warum wir überhaupt eine Alternative für die Accuarcy benutzen. \n",
    "\n",
    "Angenommen, ihr schreibt ein Programm, das zwischen Hunden und Katzen unterscheiden soll.\n",
    "Ihr habt neun Bilder von Hunden und nur eins von einer Katze. \n",
    "\n",
    "<img src='Img/intro_stats/catvdogs.png' alt=\"Drawing\" width= \"500px\"/> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([\"HUND\", \"KATZE\", \"HUND\",\"HUND\",\"HUND\",\"HUND\",\"HUND\",\"HUND\",\"HUND\",\"HUND\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es gibt einen sehr großen Unterschied zwischen der Anzahl von Katzen zu Hunden im Datensatz. \n",
    "Können Sie eine Möglichkeit finden immer eine Accuracy von 90 % zu erhalten, ohne die Bilder je gesehen zu haben und diese zufällig angeordnet werden?\n",
    "Die Funktion `shuffle` ordnet die Elemente jedes Mal auf neues in zufälliger Reihenfolge an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle(y) # ordnet die Elemente im Array zufällig an \n",
    "y_pred = np.array([___,____,____,____,_____,_____,____,____,____,_____])# schreiben sie hier ihre Antwort\n",
    "accuracy(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Lösung:</b></summary>\n",
    "    \n",
    "```python\n",
    "y_pred = np.array([\"HUND\", \"HUND\", \"HUND\",\"HUND\",\"HUND\",\"HUND\",\"HUND\",\"HUND\",\"HUND\", \"HUND\"]) \n",
    "```\n",
    "</details> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wenn Sie einfach jedes Bild als Hund klassifizieren erhalten Sie immer eine Accuracy von 0.9. \n",
    "Das heißt, ohne dass ein Modell etwas im Bild erkennt, kann es eine Genauigkeit von 0.9 erreichen. \n",
    "Wir können also anhand der Genauigkeit nicht wirklich erkennen, ob unser Model etwas gelernt hat oder einfach immer nur `\"HUNDE\"` erkennt. \n",
    "Je größer das Ungleichgewicht zwischen den verschiedenen Klassen (*class inbalance*) ist, z.B. `HUND` vs. `KATZE`, desto weniger wertvoll ist die Accuracy als eine Metrik. \n",
    "\n",
    "Dafür gibts es alternative Metriken die besser für Klassifizierungen mit *class inbalance* geeignet sind. Dazu gehört auch der ROC-AUC.\n",
    "\n",
    "ROC bezeichnet die Receiver Operator Characteristic, eine Kurve die das Verhältnis von der *True Positive Rate* zur *False Positive Rate* beschreibt. Der AUC ist die Fläche unter der ROC Kurve.\n",
    "\n",
    "<img src='Img/intro_stats/roc_auc.png' alt=\"Drawing\" width= \"300px\"/> \n",
    "\n",
    "*Was bedeuten True und False Positve Rate?*<br><br>\n",
    "Angenommen wir hätten Hunde als `1` und Katze als `0` codiert. Dann würde die True Positive Rate (TPR), den Prozentsatz der korrekt identifizierten Hunde Bilder wiedergeben.<br><br>\n",
    "$$TPR = \\frac{\\textrm{Anzahl korrekt klassifizierten Hunde Bilder}}{\\textrm{Anzahl aller Hunde Bilder }}$$\n",
    "\n",
    "Angenommen das Model erkennt jedes Bild als Hund, was ist die True Positive Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TPR = ___/___ \n",
    "TPR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Lösung:</b></summary>\n",
    "    \n",
    "```python\n",
    "TPR = 9/10\n",
    "```\n",
    "</details> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie Sie sich denken können ist die False Positive Rate (FPR) sehr ähnlich.  Hier geht es diesmal die Katzen.\n",
    "\n",
    "$$FPR= \\frac{\\textrm{Anzahl Katzen, die als Hund klassifiziert wurden}}{\\textrm{Anzahl aller Katzen Bilder}}$$\n",
    "\n",
    "Angenommen das Model erkennt jedes Bild als Hund, was ist die True Positive Rate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FPR = ___/___\n",
    "FPR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><b>Lösung:</b></summary>\n",
    "    \n",
    "```python\n",
    "TPR = 0/1\n",
    "```\n",
    "</details> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun etwas förmlicher:  Der ROC-AUC gibt Auskunft über das Verhältnis von wie gut ein Model im Hunde erkennen ist versus wie schlecht es im Katzen erkennen ist. Die Berechnung des ROC AUC ist etwas komplizierter als nur dir FPR und TPR auszurechnen. \n",
    "Aber es ist wichtig über diese Abhängigkeiten Bescheid zu wissen. \n",
    "Ein ROC AUC Wert liegt immer zwischen 0 und 1. Eine 1 bedeute eine perfekte Klassifizierung, und ein Wert von 0.5 weist auf eine rein zufällige Entscheidung hin. \n",
    "Zum Berechnen können wir die Funktion `roc_auc_score` von `sklearn` benutzen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "y_true = np.array([1,0,1,1,1,1,1,1,1,1]) # Wir haben diesmal Hunde und Katzen in 1 und 0 umcodiert\n",
    "y_pred = np.array([1,1,1,1,1,1,1,1,1,1])\n",
    "roc_auc_score(y_true ,y_pred )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sie können sehen, dass der ROC AUC Wert nur bei 0.5 liegt. Das Model ist nicht besser als eine zufällige Entscheidung.\n",
    "In der Praxis, arbeiten wir aber mit vorhergesagten Wahrscheinlichkeiten, also Werte zwischen 0 und ein 1, anstatt nur  mit `0` und `1`. Auch damit kann man den ROC AUC Score berechnen.\n",
    "\n",
    "Probieren Sie die Wahrscheinlichkeiten der Katze zu verändern (zweite Position)?\n",
    "Denken Sie daran, dass wir ein Bild ab einem Wert von 0.5 als Hund klassifizieren. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.array([1,0,1,1,1,1,1,1,1,1]) # Wir haben diesmal Hunde und Katzen in 1 und 0 umcodiert\n",
    "y_hat = np.array([0.91,____,0.99,0.99,0.99,0.98,0.8,0.7,0.8,0.97])\n",
    "roc_auc_score(y_true ,y_hat )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Übungsaufgabe\n",
    "\n",
    "Bitte zur Benotung abgeben!\n",
    "\n",
    "Es gibt auch logistische Regressionen mit mehr als einer `x` Variable. \n",
    "\n",
    "Die Daten basieren auf dem *Iris-Datensatz* \n",
    "[Hier](https://en.wikipedia.org/wiki/Iris_flower_data_set) gibt es mehr Informationen dazu.\n",
    "Das Ziel ist es zwischen zwei Arten von Iris Blumen zu unterscheiden. *Iris setosa* (`0`) vs. *Iris versicolor* (`1`).\n",
    "\n",
    "Die Modellparameter wurden schon geschätzt. In der folgenden Zellen werden drei Regressionkoeffizienten gegeben.\n",
    "\n",
    "Ihre Aufgabe ist es mit diesen Koeffizienten, ob das Model auch funktioniert. Sie bestimmen die Zugehörigkeit von fünf Blumen (`x`). Sie können die Schätzungen des Models mit den wahren Werten in `y` vergleichen \n",
    "\n",
    "`beta_1` gehört natürlich zu der Variable in der ersten Spalte von `x` usw."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_1 = 3.0786959\n",
    "beta_2 = -3.0220097\n",
    "beta_0 = -7.306345489594484\n",
    "\n",
    "\n",
    "x =  np.array([[5.1, 3.5],\n",
    "              [5. , 3.6],\n",
    "              [5.4, 3.4],\n",
    "              [6.7, 3.1],\n",
    "              [5.1, 2.5]])\n",
    "y = np.array([0,0,0,1,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Berechnen Sie zunächst `z`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = beta_0 + ___*____ +_____*______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Konvertieren Sie `z` zu Wahrscheinlichkeiten mit Hilfe der `sigmoid` Funktion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = _____\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Berechnen sie die Genaugigkeit/Accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = _____(y_hat)\n",
    "accuracy(______,____)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als letzes berechnen Sie noch den ROC AUC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
