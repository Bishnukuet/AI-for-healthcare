{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfd225c5",
   "metadata": {},
   "source": [
    "# Recurrent Neural Networks\n",
    "\n",
    "Recurrent Neural Networks(RNNs), sind neben CNNs, eine weitere spezielle Form eines Neural Networks. \n",
    "RNNs werden vor allem bei Sequenzen verwendet, die in festen Reihenfolgen angeordnet sind, und diese Reihenfolge auch die Interpretation der gesamten Sequenz beeinflusst. \n",
    "\n",
    "Sprachen als ein klassisches Beispiel drängt sich sofort auf. Denn der Inhalt eines Satzes hat Einfluss auf die Interpretation der einzelnen Wörter. \n",
    "\n",
    "Zum Beispiel:\n",
    "\n",
    "> Ich bin kein Fan von diesem Film\n",
    "\n",
    "Das Wort „*Fan*“ hat eine positive Konnotation. Doch das „*kein*“ vor dem Wort, dreht die Interpretation um. Das heißt, das Wort „*Fan*“ sollte im Kontext des gesamten Satzes interpretiert werden. \n",
    "Aber auch in der Chemie/Pharmazie können RNN Verwendung finden. Zum Beispiel Smiles Strings oder Protein Sequenzen eignen sich für RNNs. \n",
    "\n",
    " `()` haben einen starken Einfluss darauf, wie einzelne Teile des Smiles interpretiert werden können.\n",
    "\n",
    "`CCCC`|`CC(C)C`\n",
    "------|--------\n",
    "<img src=\"Img/rnn/mol1.png\" width=\"200\"/> |<img src=\"Img/rnn/mol2.png\" width=\"200\"/> \n",
    "\n",
    "\n",
    "Das generelle Konzept eines RNN ist relativ einfach:\n",
    "Wort für Wort (oder auch Zeichen für Zeichen) wird ein Satz (Smiles) durch das Netzwerk geführt. \n",
    "Die Outputlayer wird zunächst komplett ignoriert, sondern nachdem ein Wort durch das Netzwerk geführt wird, werden die Activation der Hidden Layer ($h_1$) gespeichert.\n",
    "\n",
    "Anhand des Beispielsatzes „*Hallo Welt*“ wird es im Bild erklärt. $h_1$ sind hier die Aktivations für das Wort „Hallo“.\n",
    "\n",
    "Im Kontext von Recurrent Neural Networks, bezeichnen wir die Activations der Hidden Layer auch als **Hidden State**. $h_1$ ist der Hidden State für des Wort „*Hallo*“.\n",
    "\n",
    "Als Nächstes wird das zweite Wort durch das Netzwerk geschickt. Wir wollen $h_2$ berechnen, doch zu den regulären Activation des Wortes „Welt“, addieren wir auch noch die Activations $h_1$ dazu. $h_2$ ist also eine Kombination aus den Activations von „Welt“, aber auch Hallo. Das heißt, das Wort „Welt“ wurde zusammen mit dem vorangehenden Wort interpretiert.\n",
    "\n",
    "<img src=\"Img/rnn/rnn_1.svg.png\" width=\"200\"/> \n",
    "\n",
    "Hätten wir ein drittes Wort, würde sich $h_3$ aus den Activations des dritten Wortes und $h_2$ berechnen. Und da $h_2$ sowohl die Informationen vom zweiten als auch vom ersten Wort enthält, haben beide Worte Einfluss auf die Interpretation vom dritten Wort.\n",
    "\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/724/1*1U8H9EZiDqfylJU7Im23Ag.gif\">\n",
    "*Source: Michael Phi - An illustrated Guide to Recurrent Neural Networks*\n",
    "\n",
    "Im GIF erkennen Sie, dass der Einfluss des Hidden States von „*What*“ (schwarz), das erste Wort, immer kleiner wird, je näher wir dem Satzende kommen. Es hat aber dennoch Einfluss auf die Interpretation des letzten Wortes.\n",
    "\n",
    "\n",
    "Der Hidden State des letzten Teils des Satzes („*?* „), im Beispiel $O5$ ($h_5$) genannt, ist eine Kombination aus allen bisherigen Hidden States und den Activations von „*?* „.\n",
    "<img src=\"https://ichi.pro/assets/images/max/724/1*yQzlE7JseW32VVU-xlOUvQ.png\">\n",
    "\n",
    "Diesen Hidden State können wir als Input für ein Netzwerk nutzen, dass anhand dieses letzten Hidden State seine Vorhersage macht.\n",
    "\n",
    "Ähnlich wie ein CNN benutzt wird um ein Bild zu einem Vektor konvertiert, werden RNNs benutzt um Sequenzen zu Vektoren zu konvertieren.\n",
    "\n",
    "# Datenaufbereitung:\n",
    "\n",
    "Bevor wir aber unser RNN trainieren, müssen wir die Daten in das richtige Format bekommen. Buchstaben und Wörter können nämlich nicht einfach so von einem neuronalen Netzwerk gelesen werden.\n",
    "Wie schon mit den Labels vom MNIST Datensatz (0-9), können wir Wörter, oder, im Falle von Smiles, Symbole „one-hot“ kodieren. \n",
    "\n",
    "Angenommen wir haben zwei Smiles:\n",
    "\n",
    "`smiles = [\"CCN=C=O\",\"NC(=O)CC(=O)O\"]`\n",
    "\n",
    "Insgesamt gibt es 6 verschiedene Symbole:\n",
    "`C`, `N`, `=`, `O`, `(`, `)` \n",
    "\n",
    "Wir können ein `C` als einen Vektor der Länge 6 darstellen. Dieser hat an der ersten Position eine `1` und sonst nur Nullen. Ein `N` können wir ebenfalls als Vektordarstellen, nur dass wir die `1` um eine Position verschieben.\n",
    "\n",
    "Dies können wir für alle Symbole in den Smiles machen:\n",
    "\n",
    "```python\n",
    "\"C\" = [1,0,0,0,0,0]\n",
    "\"N\" = [0,1,0,0,0,0]\n",
    "\"=\" = [0,0,1,0,0,0]\n",
    "\"O\" = [0,0,0,1,0,0]\n",
    "\"(\" = [0,0,0,0,1,0]\n",
    "\")\" = [0,0,0,0,0,1]\n",
    "```\n",
    "Diese Symbole werden auch oft **Tokens** genannt.\n",
    "Wir können also einen Smiles String mithilfe dieser Regeln kodieren. Wir brauchen also pro Smiles eine Matrix:\n",
    "\n",
    "```python\n",
    "\"CCN=C=O\" -> np.array([[1,0,0,0,0,0],\n",
    "                      [1,0,0,0,0,0],\n",
    "                      [0,1,0,0,0,0],\n",
    "                      [0,0,1,0,0,0],\n",
    "                      [1,0,0,0,0,0],\n",
    "                      [0,0,1,0,0,0],\n",
    "                      [0,0,0,1,0,0]])\n",
    "```\n",
    "\n",
    "Aus dem String `\"CCN=C=O\"` wird eine Matrix in der jede Reihe ein Symbol ist und jede Spalte an gibt welches Symbole dieser Reihe zugeordnet ist.\n",
    "\n",
    "Mit dem folgenden Code können Sie diese Transformation automatisieren.\n",
    "Viele Funktionen sind vorgeschrieben. Wenn Sie aber dennoch Interesse haben, wie diese Funktionen genau aussehen, finden Sie den Code in `../utils/utils.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69935db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from rdkit.Chem import AllChem as Chem\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "%run ../utils/utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6af1128",
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles = [\"CCN=C=O\",\"NC(=O)CC(=O)O\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b82c34b",
   "metadata": {},
   "source": [
    "Zunächst brauchen wir eine Art Wörterbuch, das alle vorkommenden Symbole speichert und ihnen eine Zahl zuordnet. Diese Zahl gibt auch an, an welche Position die `1` im one-hot Vektor sein wird. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d42eb8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'=': 0, 'N': 1, 'C': 2, 'O': 3, ')': 4, '(': 5}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary = create_dict(smiles)\n",
    "dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b355072c",
   "metadata": {},
   "source": [
    "Sie sehen, dem `=` wird eine `0` zugeordnet und dem `N` eine `1` usw...\n",
    "\n",
    "Mit der Funktion `tokenize()` können Sie die Smiles in eine Zahlenreihe konvertieren. Wir repräsentieren den Smiles String nun, anhand der Zahlen die den Symbolen zugeordnet worden sind. \n",
    "Der Funktion muss nur gesagt werden, welche Smiles sie kodieren soll und welches „Wörterbuch“ es dafür verwenden soll."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b1ea9dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 2, 1, 0, 2, 0, 3], [1, 2, 5, 0, 3, 4, 2, 2, 5, 0, 3, 4, 3]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_smiles = tokenize(smiles,dictionary)\n",
    "tokenized_smiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aab741c",
   "metadata": {},
   "source": [
    "Die Smiles werden jetzt schon mal als einfach Zahlenreihenfolge dargestellt.\n",
    "Diese sind aber noch unterschiedlich lang."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f2e5407",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 13]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(x) for x in tokenized_smiles]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a395b0",
   "metadata": {},
   "source": [
    "Ein Smiles besteht aus 7 Symbolen/Tokens, der andere aber aus 13. Das ist ein Problem, denn ein RNN erwartet, dass jeder Sequenz gleich lang ist. Das ist natürlich unrealistisch, denn größere Moleküle haben mehr Symbole als kleinere. \n",
    "Um das Problem zu lösen, *„padden“* wir alle Sequenzen auf die Länge des längsten Smiles.\n",
    "Das „*padden *“ bedeutet, wir fügen ein neues Symbol unserem Dictionary hinzu: `\"<pad>\"`. Dieses Symbol wird an jeden Smiles string hinzugefügt, bis er dieselbe Länge hat wie der längste Smiles. Das `\"<pad>\"` soll dem Netzwerk „sagen“, dass diese Symbole nicht mehr relevant für den Smiles sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a045f7fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_smiles_length = max([len(x) for x in tokenized_smiles])\n",
    "max_smiles_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfef370b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'=': 0, 'N': 1, 'C': 2, 'O': 3, ')': 4, '(': 5, '<pad>': 6}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary[\"<pad>\"] = len(dictionary)\n",
    "dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b05f9f",
   "metadata": {},
   "source": [
    "Nun haben wir den `pad` Token unserem Wörterbuch hinzugefügt. Als Letztes müssen wir nur noch unserem ersten Smiles `tokenized_smiles[0]` diesen Token anhängen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "785a5360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 2, 1, 0, 2, 0, 3, 6, 6, 6, 6, 6, 6]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_fehlende_tokens = max_smiles_length-len(tokenized_smiles[0])\n",
    "tokenized_smiles[0] += [dictionary[\"<pad>\"]] * num_fehlende_tokens \n",
    "tokenized_smiles[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d40fb4a",
   "metadata": {},
   "source": [
    "Jetzt sind beide Smiles gleich lang:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b874c15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[13, 13]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(x) for x in tokenized_smiles]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53f48a3",
   "metadata": {},
   "source": [
    "Jetzt können wir auch die Smiles zu one-hot Vektoren konvertieren.\n",
    "Dafür brauchen wir die Anzahl verschiedenen Symbole:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6bfd89c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "vocabulary_length = len(dictionary)\n",
    "print(vocabulary_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6425921",
   "metadata": {},
   "source": [
    "Insgesamt befinden sich 7 Symbole in unserem Wörterbuch.\n",
    "Mit der Funktion `token_to_onehot` werden aus den `tokenized_smiles` one-hot Matrizen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24de340f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 0. 1. 0. 0. 0. 0.]\n",
      "  [0. 0. 1. 0. 0. 0. 0.]\n",
      "  [0. 1. 0. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 1. 0. 0. 0. 0.]\n",
      "  [1. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 1. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 0. 1.]\n",
      "  [0. 0. 0. 0. 0. 0. 1.]\n",
      "  [0. 0. 0. 0. 0. 0. 1.]\n",
      "  [0. 0. 0. 0. 0. 0. 1.]\n",
      "  [0. 0. 0. 0. 0. 0. 1.]\n",
      "  [0. 0. 0. 0. 0. 0. 1.]]\n",
      "\n",
      " [[0. 1. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 1. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 1. 0.]\n",
      "  [1. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 1. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 1. 0. 0.]\n",
      "  [0. 0. 1. 0. 0. 0. 0.]\n",
      "  [0. 0. 1. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 0. 1. 0.]\n",
      "  [1. 0. 0. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 1. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 1. 0. 0.]\n",
      "  [0. 0. 0. 1. 0. 0. 0.]]] (2, 13, 7)\n"
     ]
    }
   ],
   "source": [
    "onehot_tokens = token_to_onehot(tokenized_smiles, vocabulary_length)\n",
    "print(onehot_tokens, onehot_tokens.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a76615",
   "metadata": {},
   "source": [
    "`onehot_tokens` ist ein `numpy` Array mit den Dimensionen `2,13,7`. Die erste Dimension sind die Anzahl der Smiles Strings (`2`). Die zweite Dimension ist die Länge der Sequenzen (`13`). Die dritte Dimension gibt die Anzahl der verschiedene Token an (`7`).\n",
    "\n",
    "An sich wären unseren Daten jetzt bereit für ein RNN. Doch anstatt diese one-hot kodierten Vektoren als Input zu nehmen benutzen wir zuvor noch eine *Word Embedding Layer*. \n",
    "\n",
    "# Word Embedding\n",
    "\n",
    "Tatsächlich werden diese one-hot kodierten Vektoren nicht mehr direkt als Input benutzt. Bevor sie in das Netzwerk geführt werden, wird noch eine Embedding Layer benutzt. Diese ersetzt die one-hot kodierten Vektoren mit zunächst zufälligen Zahlen. Um besser zu verstehen, was gemeint ist, schauen wir uns zunächst eine Embedding Layer an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f594d1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.19151945, 0.62210877, 0.43772774, 0.78535858],\n",
       "       [0.77997581, 0.27259261, 0.27646426, 0.80187218],\n",
       "       [0.95813935, 0.87593263, 0.35781727, 0.50099513],\n",
       "       [0.68346294, 0.71270203, 0.37025075, 0.56119619],\n",
       "       [0.50308317, 0.01376845, 0.77282662, 0.88264119],\n",
       "       [0.36488598, 0.61539618, 0.07538124, 0.36882401],\n",
       "       [0.9331401 , 0.65137814, 0.39720258, 0.78873014]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(1234)\n",
    "embedding_layer=np.random.rand(7,4)\n",
    "embedding_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273d33c1",
   "metadata": {},
   "source": [
    "Eine Embedding Layer besteht aus einer einzigen Weight Matrix. Diesen enthält zufällige Zahlen. Die Anzahl der Reihen entspricht exakt der Anzahl der verschiedenen Tokens in unserem Wörterbuch. \n",
    "Eine Embedding Layer tauscht, dementsprechend den Vektor `[1,0,0,0,0,0,0]` mit der ersten Reihe aus der `embedding_layer[0,:]= [0.19151945, 0.62210877, 0.43772774, 0.78535858]` aus.\n",
    "\n",
    "Um das zu erreichen, müssen wir einfach die one-hot kodierten Smiles mit der Embedding Layer multiplizieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01ffab88",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.95813935 0.87593263 0.35781727 0.50099513]\n",
      " [0.95813935 0.87593263 0.35781727 0.50099513]\n",
      " [0.77997581 0.27259261 0.27646426 0.80187218]\n",
      " [0.19151945 0.62210877 0.43772774 0.78535858]\n",
      " [0.95813935 0.87593263 0.35781727 0.50099513]\n",
      " [0.19151945 0.62210877 0.43772774 0.78535858]\n",
      " [0.68346294 0.71270203 0.37025075 0.56119619]\n",
      " [0.9331401  0.65137814 0.39720258 0.78873014]\n",
      " [0.9331401  0.65137814 0.39720258 0.78873014]\n",
      " [0.9331401  0.65137814 0.39720258 0.78873014]\n",
      " [0.9331401  0.65137814 0.39720258 0.78873014]\n",
      " [0.9331401  0.65137814 0.39720258 0.78873014]\n",
      " [0.9331401  0.65137814 0.39720258 0.78873014]]\n"
     ]
    }
   ],
   "source": [
    "token_embeddings = np.matmul(onehot_tokens,embedding_layer)\n",
    "print(token_embeddings[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5a54c3",
   "metadata": {},
   "source": [
    "Sie sehen hier drüber die Embeddings des ersten Smiles.\n",
    "Hier drunter ist die erste Reihe des one-hot kodierten Smiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d42bf7b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_tokens[0,0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39e5783",
   "metadata": {},
   "source": [
    "Dieser hat an der 3 Position (index `2`) eine `1`.\n",
    "Wenn Sie sich jetzt in der Weight Matrix der `embedding_layer` die dritte Reihe (index `2`) anschauen, fällt auf, dass dieser Vektor genau dieselben Werte hat, wie die erste Reihe in der `token_embeddings` Layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cffada21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.95813935, 0.87593263, 0.35781727, 0.50099513])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_layer[2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e729c4d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.95813935, 0.87593263, 0.35781727, 0.50099513])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_embeddings[0,0,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe357913",
   "metadata": {},
   "source": [
    "Einfacher erklärt: \n",
    "Eine Embedding Layer konvertiert one-hot kodierte Vektoren zu Vektoren mit zufälligen Gewichten. \n",
    "\n",
    "*Aber warum wird das gemacht?*\n",
    "\n",
    "Ein Vorteil ist, dass in den meisten Fällen Texte oder auch Smiles aus mehr als nur 7 Symbolen oder Wörtern bestehen. Würden wir zum Beispiel alle Wörter, die in einem Dokument vorkommen, kodieren, würden diese Vektoren sehr lang werden. Durch das „embedden“ der Vektoren, können wir zunächst die Größe dieser Inputvektoren reduzieren.\n",
    "\n",
    "Wichtiger ist aber, dass die Weights in der Embedding Layer gelernt werden können. Das heißt diese Weights werden bei der Backpropagation mit upgedatet.\n",
    "Damit passen sich die Embeddings während des Trainings an. Das ist praktisch, denn man erwartet, dass durch das Training ähnliche Wörter ähnlich Embddings erhalten. Zum Beispiel, die Wörter LKW und Auto sind im Sprachgebrauch ähnlicher als Auto und Strand. \n",
    "Wenn Auto und LKW ähnliche Embeddings haben, also durch ähnliche Vektoren beschrieben werden, dann hat können diese auch leichter im Kontext des Satzes verarbeitet werden.\n",
    "\n",
    "\n",
    "> Ein Auto fährt auf der Straße\n",
    "\n",
    "> Ein LKW fährt auf der Straße\n",
    "\n",
    "Beschreiben zwei sehr ähnlich Situation und wenn auch die numerischen Repräsentationen sich ähneln, fällt es dem Netzwerk leichter diese zu lernen.\n",
    "\n",
    "Im Falle von Smiles kann man argumentieren, dass die Rolle von Stickstoff in einem Molekül ähnlicher zu einen Kohlenstoff ist, als zu einem Fluor. Dies sollte sich vor allem in den Embeddings widerspiegeln.\n",
    "\n",
    "\n",
    "# RNNs\n",
    "\n",
    "Wir haben nun die Smiles in das richtige Format konvertiert. Wir müssen nur noch das `numpy` array zu einem Tensor konvertieren. Achten Sie darauf, dass wir auch die Funktion `.permute` benutzen. `.permute` wird verwendet, um Dimensionen von einem Tensor zu vertauschen. Denn für RNNs erwartetet PyTorch, dass die Tensor wie folgt angeordnet sind:\n",
    "\n",
    "`[Länge des Smiles, Anzahl der Smiles, Embeddinggröße]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3ef6384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 2, 4])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_embeddings_tensor = torch.tensor(token_embeddings, dtype= torch.float).permute(1,0,2)\n",
    "token_embeddings_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87958bdb",
   "metadata": {},
   "source": [
    "Der Tensor `token_embeddings_tensor` hat die oben gelisteten Dimensionen. Jeder Smiles besteht aus `13` Token, unser Batch besteht aus `2` Smiles und jeder Token wird mit `4` Werten beschrieben. \n",
    "\n",
    "Wir können nun ein RNN definieren. Wie auch sonst gibt es ein RNN auch im `torch.nn` Modul.\n",
    "Auch hier müssen Sie beim Definieren der Dimensionen aufpassen. Die erste Dimension ist die Größe des Inputs, also die Embeddingsgröße (`4`). Die zweite Dimension gibt an wie viele Nodes wir in der Hidden Layer haben wollen. Dieser gibt auch an, wie groß die Vektoren des Hidden States werden sollen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cdbb0816",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1234)\n",
    "rnn = nn.RNN(4,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69fa783",
   "metadata": {},
   "source": [
    "Sie können jetzt einfach `token_embeddings_tensor` durch das `rnn` führen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "162ebc78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_rnn = rnn(token_embeddings_tensor)\n",
    "len(output_rnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3f4fda",
   "metadata": {},
   "source": [
    "Der Output des RNN (`output_rnn`) ist eine Liste mit der Länge zwei.\n",
    "Wir schauen uns zunächst das erste Objekt des Outputs an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b81fbbf5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.6540,  0.1824,  0.1200,  0.4636, -0.0831, -0.2290,  0.3849,\n",
      "           0.3114,  0.4953,  0.1924],\n",
      "         [-0.6074,  0.1729,  0.1613,  0.3752, -0.0612, -0.1318,  0.2538,\n",
      "           0.3650,  0.5437,  0.0800]],\n",
      "\n",
      "        [[-0.6201,  0.0397,  0.0467,  0.5561, -0.1582, -0.1902,  0.0533,\n",
      "           0.2024,  0.5232,  0.0419],\n",
      "         [-0.6291,  0.0600,  0.0284,  0.5624, -0.2045, -0.1845,  0.0926,\n",
      "           0.2466,  0.5708,  0.0416]],\n",
      "\n",
      "        [[-0.5073,  0.0867, -0.0092,  0.5796, -0.1643, -0.1114, -0.1150,\n",
      "           0.2933,  0.6187, -0.1547],\n",
      "         [-0.3727,  0.2763, -0.1432,  0.5627, -0.0995, -0.1747, -0.1914,\n",
      "           0.1635,  0.5000, -0.1977]],\n",
      "\n",
      "        [[-0.4378,  0.2924, -0.1356,  0.6046, -0.1448, -0.1848, -0.2003,\n",
      "           0.1723,  0.5326, -0.2877],\n",
      "         [-0.5051,  0.3958, -0.0952,  0.6255, -0.1017, -0.1391, -0.1083,\n",
      "           0.1592,  0.5074, -0.2954]],\n",
      "\n",
      "        [[-0.6462,  0.2525, -0.0672,  0.7318, -0.2121, -0.1398,  0.1564,\n",
      "           0.2445,  0.5865, -0.1372],\n",
      "         [-0.6156,  0.3112, -0.0419,  0.6789, -0.1472, -0.1573,  0.1044,\n",
      "           0.2314,  0.5784, -0.1927]],\n",
      "\n",
      "        [[-0.4655,  0.2639, -0.0796,  0.5992, -0.0296, -0.2127, -0.1722,\n",
      "           0.1193,  0.4869, -0.2999],\n",
      "         [-0.5784,  0.0581,  0.0991,  0.5313, -0.2006, -0.1432, -0.1463,\n",
      "           0.3319,  0.6085, -0.1493]],\n",
      "\n",
      "        [[-0.5986,  0.3265, -0.0642,  0.6934, -0.2047, -0.1442,  0.0893,\n",
      "           0.2485,  0.5776, -0.2094],\n",
      "         [-0.5889,  0.1273, -0.0910,  0.6787, -0.2771, -0.1929,  0.0307,\n",
      "           0.2444,  0.6242, -0.0946]],\n",
      "\n",
      "        [[-0.6446,  0.1189,  0.0052,  0.6866, -0.1375, -0.1475,  0.0833,\n",
      "           0.2333,  0.5975, -0.1707],\n",
      "         [-0.5758,  0.0966, -0.0821,  0.7022, -0.1759, -0.1827,  0.0166,\n",
      "           0.2126,  0.5548, -0.0980]],\n",
      "\n",
      "        [[-0.5973,  0.0860, -0.0338,  0.6887, -0.1848, -0.1692,  0.0470,\n",
      "           0.2732,  0.6080, -0.1727],\n",
      "         [-0.3950,  0.3355, -0.1838,  0.6359, -0.1054, -0.1674, -0.1418,\n",
      "           0.1770,  0.4678, -0.2649]],\n",
      "\n",
      "        [[-0.5953,  0.0725, -0.0511,  0.6974, -0.2013, -0.1537,  0.0168,\n",
      "           0.2597,  0.5906, -0.1785],\n",
      "         [-0.5324,  0.4011, -0.0900,  0.6423, -0.0796, -0.1469, -0.0711,\n",
      "           0.1467,  0.4822, -0.3231]],\n",
      "\n",
      "        [[-0.5898,  0.0740, -0.0585,  0.7012, -0.1909, -0.1606,  0.0198,\n",
      "           0.2615,  0.5912, -0.1824],\n",
      "         [-0.6232,  0.3126, -0.0324,  0.6810, -0.1413, -0.1652,  0.1264,\n",
      "           0.2307,  0.5751, -0.2045]],\n",
      "\n",
      "        [[-0.5925,  0.0773, -0.0599,  0.7043, -0.1948, -0.1560,  0.0221,\n",
      "           0.2627,  0.5868, -0.1854],\n",
      "         [-0.5820,  0.0560,  0.1051,  0.5300, -0.2020, -0.1456, -0.1405,\n",
      "           0.3298,  0.6078, -0.1521]],\n",
      "\n",
      "        [[-0.5935,  0.0763, -0.0591,  0.7040, -0.1913, -0.1583,  0.0249,\n",
      "           0.2617,  0.5862, -0.1860],\n",
      "         [-0.5304,  0.1756, -0.0967,  0.6344, -0.2509, -0.1894, -0.0759,\n",
      "           0.2257,  0.6100, -0.1583]]], grad_fn=<StackBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(output_rnn[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b7c1009b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([13, 2, 10])\n"
     ]
    }
   ],
   "source": [
    "print(output_rnn[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8017bd",
   "metadata": {},
   "source": [
    "Der `output_rnn[0]` hat die Dimensionen `[13, 2, 10]`. Das einzige, was sich, im Vergleich zum Input, verändert hat, ist die letzte Dimension. Anstatt der Größe `4` ist diese jetzt `10`. \n",
    "\n",
    "Der erste Teil des RNN enthält nämlich die Hidden States von jedem Symbol im Smiles.\n",
    "\n",
    "Wenn Sie an das GIF zurückdenken:\n",
    "<img src=\"https://miro.medium.com/max/724/1*1U8H9EZiDqfylJU7Im23Ag.gif\">\n",
    "*Source: Michael Phi - An illustrated Guide to Recurrent Neural Networks*\n",
    "\n",
    "`output_rnn[0]` enthält $O1$ bis $O5$. Bloß da unsere Sequenzen die Länge 13 haben, enthält `output_rnn[0]` eben 13 Hidden States.\n",
    "\n",
    "Doch was enthält `output_rnn[1]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f4f93a53",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.5935,  0.0763, -0.0591,  0.7040, -0.1913, -0.1583,  0.0249,\n",
       "           0.2617,  0.5862, -0.1860],\n",
       "         [-0.5304,  0.1756, -0.0967,  0.6344, -0.2509, -0.1894, -0.0759,\n",
       "           0.2257,  0.6100, -0.1583]]], grad_fn=<StackBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_rnn[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "460ac3e4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 10])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_rnn[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5ba52c",
   "metadata": {},
   "source": [
    "`output_rnn[1]` enthält NUR den letzten Hidden State. Im GIF ist das $O5$, bei uns wäre es $O13$. Dieser Hidden State beschreibt (theoretisch) die komplette Sequenz, und ist deswegen besonders wichtig.\n",
    "\n",
    "Sie können es auch kontrollieren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c7109498",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5935,  0.0763, -0.0591,  0.7040, -0.1913, -0.1583,  0.0249,  0.2617,\n",
      "          0.5862, -0.1860],\n",
      "        [-0.5304,  0.1756, -0.0967,  0.6344, -0.2509, -0.1894, -0.0759,  0.2257,\n",
      "          0.6100, -0.1583]], grad_fn=<SelectBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.5935,  0.0763, -0.0591,  0.7040, -0.1913, -0.1583,  0.0249,\n",
       "           0.2617,  0.5862, -0.1860],\n",
       "         [-0.5304,  0.1756, -0.0967,  0.6344, -0.2509, -0.1894, -0.0759,\n",
       "           0.2257,  0.6100, -0.1583]]], grad_fn=<StackBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(output_rnn[0][-1])\n",
    "output_rnn[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431ddd4e",
   "metadata": {},
   "source": [
    "\n",
    "Um genauer zu verstehen, was passiert, werden wir das PyTorch RNN selber nochmal programmieren.\n",
    "\n",
    "\n",
    "Angenommen wir haben einen Satz `satz = [\"Hello\", \"World\"]`. Diesen haben wir als zwei Wörter in einer Liste gespeichert. \n",
    "\n",
    "Wir definieren auch zwei einfache Linear Layers.  Die eine mappt den Input von `4` Buchstaben auf `10` Dimensionen. Die andere Layer mappt von `10` auf `10`.\n",
    "\n",
    "Durch das erste Netzwerk schicken wir das erste Wort `satz[0]` und speichern den Hidden State in `output_1`\n",
    "\n",
    "```python\n",
    "satz = [\"Hello\", \"World\"]\n",
    "\n",
    "lin_1 = nn.Linear(4,10) \n",
    "\n",
    "lin_2 = nn.Linear(10,10)\n",
    "\n",
    "output_1 =rnn(satz[0])\n",
    "```\n",
    "Als Nächstes führen wir auch das zweite Wort „World“ durch das `lin_1`. Doch im Anschluss addieren wir auch den `lin_2(output_1)` dazu. \n",
    "\n",
    "```python\n",
    "satz = [\"Hello\", \"World\"]\n",
    "\n",
    "lin_1 = nn.Linear(4,10) \n",
    "\n",
    "lin_2 = nn.Linear(10,10)\n",
    "\n",
    "output_1 = lin_1(satz[0])\n",
    "\n",
    "output_2 = lin_1(satz[1]) + lin_2(output_1)\n",
    "```\n",
    "\n",
    "Das heißt, der Hidden State `output_2` wird nicht alleine durch das Wort „`World`“ bestimmt, sondern der Hidden State zuvor hat auch Einfluss. Tatsächlich fügen wir auch noch eine nicht-lineare Aktivierungsfunktion hinzu. In RNNs wird per Default eine Tanh-Funktion anstatt einer ReLU-Funktion benutzt.\n",
    "\n",
    "```python\n",
    "satz = [\"Hello\", \"World\"]\n",
    "\n",
    "lin_1 = nn.Linear(4,10) \n",
    "\n",
    "lin_2 = nn.Linear(10,10)\n",
    "\n",
    "output_1 = lin_1(satz[0])\n",
    "\n",
    "output_2 = torch.tanh(lin_1(satz[1]) + lin_2(output_1))\n",
    "```\n",
    "\n",
    "Hätten wir noch ein drittes Wort im Satz (`satz[2]`), dann würde sich der Schritt wiederholen. Wir addieren diesmal, aber nicht `output_1`, sondern `output_2` hinzu:\n",
    "\n",
    "```python\n",
    "satz = [\"Hello\", \"World\"]\n",
    "\n",
    "lin_1 = nn.Linear(4,10) \n",
    "\n",
    "lin_2 = nn.Linear(10,10)\n",
    "\n",
    "output_1 = lin_1(satz[0])\n",
    "\n",
    "output_2 = torch.tanh(lin_1(satz[2]) + lin_2(output_1))\n",
    "```\n",
    "\n",
    "\n",
    "Um dies zu kontrollieren, schreiben wir dafür ein eigenes Programm.\n",
    "Zunächst speichern wir die Weights des `rnn`. Diese können wir nun selber benutzen.\n",
    "Denken Sie daran, dass `nn.Linear()` nicht anderes macht als: `torch.mm(X,W.t())+b`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d7db5be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_1=list(rnn.parameters())[0]\n",
    "w_2=list(rnn.parameters())[1]\n",
    "b_1=list(rnn.parameters())[2]\n",
    "b_2=list(rnn.parameters())[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7ca4f2",
   "metadata": {},
   "source": [
    "Mit diesen Weights können Sie nun den Hidden State für das erste Symbol in der Smiles Sequenz berechnen (`lin_1`). Diese befinden sich in `token_embeddings_tensor[0]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "04298d1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '____' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_508/2374541560.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mactivations_jetzt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken_embeddings_tensor\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m____\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0m____\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mactivations_jetzt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name '____' is not defined"
     ]
    }
   ],
   "source": [
    "activations_jetzt = torch.mm(token_embeddings_tensor[0],____)+____\n",
    "activations_jetzt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0311e2",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary><b>Lösung:</b></summary>\n",
    "\n",
    "```python\n",
    "activations_jetzt = torch.mm(token_embeddings_tensor[0],w_1.t())+b_1\n",
    "activations_jetzt\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bdeb2d",
   "metadata": {},
   "source": [
    "Als Nächstes transformieren wir noch den Hidden State des vorherigen Tokens (`lin_2`). \n",
    "Allerdings sind wir doch momentan beim erstem Wort/Token. Wir haben also noch keinen Hidden State von einem vorherigen Token. Dieser Teil wurde im Text vorher unterschlagen. Tatsächlich fangen wir mit einem Hidden State an, bei dem alle Werte Null sind. `h0 = torch.zeros(2,10)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "b27ac3da",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '____' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1036305/2459661265.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mh0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mactivations_vorher\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m___\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m____\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0m____\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name '____' is not defined"
     ]
    }
   ],
   "source": [
    "h0 = torch.zeros(2,10)\n",
    "\n",
    "activations_vorher = torch.mm(___,____)+____"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358399d0",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary><b>Lösung:</b></summary>\n",
    "\n",
    "```python\n",
    "h0 = torch.zeros(2,10)\n",
    "\n",
    "activations_vorher = torch.mm(h0,w_2.t())+b_2\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b510093a",
   "metadata": {},
   "source": [
    "Im letzten Schritt werden die beiden Activations addiert und eine `torch.tanh` Aktivierungsfunktion angewandt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "570ac57d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6540,  0.1824,  0.1200,  0.4636, -0.0831, -0.2290,  0.3849,  0.3114,\n",
       "          0.4953,  0.1924],\n",
       "        [-0.6074,  0.1729,  0.1613,  0.3752, -0.0612, -0.1318,  0.2538,  0.3650,\n",
       "          0.5437,  0.0800]], grad_fn=<TanhBackward>)"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tanh(___________+_____________)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5a8f7a",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary><b>Lösung:</b></summary>\n",
    "\n",
    "```python\n",
    "torch.tanh(activations_jetzt+activations_vorher)\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068d8ebc",
   "metadata": {},
   "source": [
    "Das ist der Hidden State für den ersten Token/erstes Symbol vom Smiles.\n",
    "Wir können die Richtigkeit auch mit dem von `nn.RNN` berechneten Hidden States vergleichen und sehen, dass diese identisch sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7bc21280",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6540,  0.1824,  0.1200,  0.4636, -0.0831, -0.2290,  0.3849,  0.3114,\n",
       "          0.4953,  0.1924],\n",
       "        [-0.6074,  0.1729,  0.1613,  0.3752, -0.0612, -0.1318,  0.2538,  0.3650,\n",
       "          0.5437,  0.0800]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_rnn[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bfad97",
   "metadata": {},
   "source": [
    "Wir wollen die Hidden States nicht nur für den ersten Token berechnen, sondern für alle Token im Smiles. Deswegen brauche wir einen for-loop. \n",
    "\n",
    "Wir initialisieren zunächst wieder den ersten Hidden State mit Nullen. Und schreiben dann einen for_loop der durch alle 13 Tokens iteriert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "8cad1a56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5935,  0.0763, -0.0591,  0.7040, -0.1913, -0.1583,  0.0249,  0.2617,\n",
       "          0.5862, -0.1860],\n",
       "        [-0.5304,  0.1756, -0.0967,  0.6344, -0.2509, -0.1894, -0.0759,  0.2257,\n",
       "          0.6100, -0.1583]], grad_fn=<TanhBackward>)"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h0 = torch.zeros(2,10)\n",
    "for i in range(max_smiles_length):\n",
    "    activations_jetzt =  # achten Sie bei der Berechnung darauf immer das i Element aus den Input auszuwählen\n",
    "    activations_vorher = \n",
    "    h0 = torch.tanh(activations_jetzt+activations_vorher) # <-- Der output wird als h0 gespeichert, \n",
    "h0                                                        #     um ihn in der nächsten Iteration als neues h0\n",
    "                                                          #     zuverwenden              "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a139140",
   "metadata": {},
   "source": [
    "`h0` enthält jetzt den finalen Hidden State. Auch hier können wir wieder kontrollieren, ob unser Ergebnis mit dem vom PyTorch `rnn` übereinstimmt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7a605f",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary><b>Lösung:</b></summary>\n",
    "\n",
    "```python\n",
    "h0 = torch.zeros(2,10)\n",
    "for i in range(max_smiles_length):\n",
    "    activations_jetzt = torch.mm(token_embeddings_tensor[i],w_1.t())+b_1\n",
    "    activations_vorher = torch.mm(h0,w_2.t())+b_2\n",
    "    h0 = torch.tanh(activations_jetzt+activations_vorher) \n",
    "h0                                                     \n",
    "```                                                          \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c4063d03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.5935,  0.0763, -0.0591,  0.7040, -0.1913, -0.1583,  0.0249,\n",
       "           0.2617,  0.5862, -0.1860],\n",
       "         [-0.5304,  0.1756, -0.0967,  0.6344, -0.2509, -0.1894, -0.0759,\n",
       "           0.2257,  0.6100, -0.1583]]], grad_fn=<StackBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_rnn[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253ad519",
   "metadata": {},
   "source": [
    "Natürlich ist einfacher PyTorchs vorgeschriebene Funktion zu benutzen. \n",
    "Aber das Selbstprogrammieren sollte Ihnen beim Verständnis helfen. \n",
    "\n",
    "Darüber hinaus veranschaulicht der Code, die größte Schwäche von RNNs: der `for-loop`.\n",
    "Wir können einen Satz/Smiles nicht auf einmal durch das Netzwerk führen. \n",
    "Sondern jedes Wort/Symbol, muss einzeln hintereinander durch das \n",
    "Netzwerk geführt werden. Das macht RNNs extrem langsam.\n",
    "\n",
    "# PyTorch RNN\n",
    "\n",
    "PyTorch\n",
    " stellt uns nicht nur RNNs zur Verfügung, sondern auch `nn.Embedding` \n",
    "Layers. Das ist praktisch. Zum einen erleichtert uns das die \n",
    "Backpropagation. Zum anderen müssen wir dadurch auch nicht erst die \n",
    "one-hot kodierten Vektoren berechnen. PyTorch nimmt sofort als Input die\n",
    " durch Token ersetzten Smiles. `tokenized_smiles`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c80476f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 2, 1, 0, 2, 0, 3, 6, 6, 6, 6, 6, 6],\n",
       " [1, 2, 5, 0, 3, 4, 2, 2, 5, 0, 3, 4, 3]]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2932a162",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = nn.Embedding(7,4, padding_idx = dictionary[\"<pad>\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f861edd",
   "metadata": {},
   "source": [
    "Oben wurde eine `torch` Embedding Layer definiert. Sie nimmt als Input die Anzahl der unterschiedlichen Symbole/Tokens in unserem Datensatz. Bei uns wären das `7`. Der zweite Parameter gibt die Größe der Embeddingvektoren an. Wir bleiben bei der Größe `4`. Als Letztes können wir PyTorch mitteilen welcher Token, also welcher Zahl für das Padding steht. PyTorch setzt darauf hin die Embeddings für diese Token auf null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "15e3d871",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 13, 4])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb(torch.tensor(tokenized_smiles)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ca07a0",
   "metadata": {},
   "source": [
    "Der Output dieser Embedding Layer ist noch nicht im richtige Format. Wir müssen noch die Dimensionen des Tensors mithilfe von `Permute` ändern. \n",
    "Wir können all diese Schritte, wie auch zuvor in ein `nn.Sequential()` Modul packen. \n",
    "\n",
    "*Im Pytorch `nn` Modul gibt es kein Permute, diese wurde von uns angepasst damit sie auch in `nn.Sequential` funktioniert. Deswegen brauchen wir auch kein \"nn.\" vor dem Permute.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2d178166",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Embedding(7, 4, padding_idx=6)\n",
       "  (1): Permute()\n",
       "  (2): RNN(4, 10)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model =nn.Sequential(nn.Embedding(7,4, padding_idx = dictionary[\"<pad>\"]),\n",
    "                     Permute(1,0,2),\n",
    "                     nn.RNN(4,10))\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9183b8a",
   "metadata": {},
   "source": [
    "Die `tokenized_smiles` können jetzt durch das `model` geführt werden. `[1][0,:,:]` wird benutzt, um die finalen Hidden States im richtigen Format zu extrahieren. Diese können wir direkt in eine Linear Layer führen. Da wir den Output mit `[1][0,:,:]` indizieren müssen, können wir die Linear Layers nicht direkt im selben `nn.Sequential()` Model benutzten. Sondern wir brauchen in zweites Model, dass den `output_rnn` als Input nimmt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9c5b30b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_rnn= model(torch.tensor(tokenized_smiles))[1][0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "75f3870f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ll = nn.Sequential(nn.Linear(10,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "25dfccd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1583],\n",
       "        [0.0377]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_ll(output_rnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f442b8b",
   "metadata": {},
   "source": [
    "Ein Problem gibt es noch mit dem `nn.RNN`. Im GIF ist klar zuerkennen, dass je länger der Satz wird, desto weniger Einfluss haben die ersten Wörter im Satz.  Das kann gerade ein Problem werden, wenn Sätze oder Smiles besonders lang werden. Gerade wenn Nebensätze, oder im Fall von Smiles extra Ringe, in den String eingeschoben werden, kann es passieren, dass der Anfang des Satzes oder Smiles vom Netzwerk vergessen wurde.\n",
    "\n",
    "Deswegen werden in der Regel komplexere RNN Layers benutzt. Diese erlaubt es Netzwerken, über längere String, Informationen zu erhalten.\n",
    "\n",
    "Eine beliebte Alternative ist die \"Gated Recurrent Unit\" (GRU). Das Kombinieren von Hidden States ist um einiges komplexer als bei vanilla RNNs, aber in PyTorch können `nn.RNN` einfach mit `nn.GRU` ausgetauscht werden, ohne dass irgendetwas anderes geändert werden muss.\n",
    "\n",
    "RNN   |GRU\n",
    "------|--------\n",
    "<img src=\"https://miro.medium.com/max/332/0*eRJCRsikdGGu8ffA.png\" width=\"200\"/> |<img src=\"https://miro.medium.com/max/700/1*RiOzdOVaaeKrUotY7-1a2A.png\" width=\"300\"/> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a84b073",
   "metadata": {},
   "source": [
    "# Übungsaufgabe:\n",
    "\n",
    "In der Übungsaufgabe werden wir uns mit einem neuen Datensatz befassen. Der Blood-Brain Barrier Penetration (BBBP) Datensatz erfasst für 2000 Moleküle, ob sie durch die Blut-Hirn-Schranke diffundieren können.\n",
    "\n",
    "Die meisten Medikamente und Neurotransmitter können die Blut-Hirnschranke nicht überwinden. Doch gerade dies ist wichtig für Medikamente, die im Zentralen Nerven System wirken sollen. Deswegen ist von präzise Vorhersage dieser Eigenschaften vom großen Interesse.\n",
    "Der originale Datensatz wurde 2012 veröffentlicht. Wir verwenden aber einen leicht veränderten Datensatz. Hierbei wurden alle Informationen zu Stereochemie aus den Smiles entfernt. Auch enthält der Datensatz nur SMILES die aus weniger als 75 Symbolen bestehen.\n",
    "\n",
    "> Martins, Ines Filipa, et al. “A Bayesian approach to in silico blood-brain barrier penetration modeling.” Journal of Chemical Information and Modeling 52.6 (2012): 1686-1697.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "068875d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from rdkit.Chem import AllChem as Chem\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from matplotlib import pyplot as plt\n",
    "%run ../utils/utils.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79385bb8",
   "metadata": {},
   "source": [
    "Sie könnnen zunächste den Datensatz einlesen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "43bd505e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/bbbp/bbbp_clean.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_508/1919247210.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata_bbbp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../data/bbbp/bbbp_clean.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdata_bbbp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ml\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ml\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ml\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ml\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ml\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             )\n\u001b[0;32m   1039\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ml\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ml\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \"\"\"\n\u001b[1;32m--> 222\u001b[1;33m         self.handles = get_handle(\n\u001b[0m\u001b[0;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\ml\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    700\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/bbbp/bbbp_clean.csv'"
     ]
    }
   ],
   "source": [
    "data_bbbp = pd.read_csv(\"../data/bbbp/bbbp_clean.csv\")\n",
    "data_bbbp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f97371d",
   "metadata": {},
   "source": [
    "Die `smiles` sind zusammen mit dem `target` angeben. Eine `1` bedeutet, dass diese Moleküle durch die BBB diffundieren kann. In der folgenden Zelle berechnen wir den Prozentsatz der Moleküle, die diese Eigenschaft besitzen, in dem Datensatz besitzen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1031,
   "id": "d7aae951",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78.88548057259713"
      ]
     },
     "execution_count": 1031,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(data_bbbp.target)/data_bbbp.shape[0]*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71977cdf",
   "metadata": {},
   "source": [
    "Wegen des großen Ungleichgewichtes bietet sich als Metrik vor allem der ROC-AUC an.\n",
    "Doch bevor wir uns dem Training zuwenden können, müssen wir erst die Daten aufbereiten.\n",
    "Erstellen Sie zunächst einen `dictionary`, der allen Symbolen im Smiles Zahlen zuordnet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1033,
   "id": "ddd8c78c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dictionary = create_dict(data_bbbp.smiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "id": "8aa446ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'N': 0,\n",
       " '(': 1,\n",
       " '2': 2,\n",
       " 'c': 3,\n",
       " 'O': 4,\n",
       " ')': 5,\n",
       " '1': 6,\n",
       " 'C': 7,\n",
       " '=': 8,\n",
       " 'Cl': 9,\n",
       " '3': 10,\n",
       " 'n': 11,\n",
       " 'F': 12,\n",
       " 'o': 13,\n",
       " '-': 14,\n",
       " 'S': 15,\n",
       " 'H': 16,\n",
       " ']': 17,\n",
       " '[': 18,\n",
       " '4': 19,\n",
       " 's': 20,\n",
       " 'Br': 21,\n",
       " '#': 22,\n",
       " 'I': 23,\n",
       " '+': 24,\n",
       " '5': 25,\n",
       " 'P': 26,\n",
       " '6': 27,\n",
       " 'B': 28}"
      ]
     },
     "execution_count": 834,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf08aa9",
   "metadata": {},
   "source": [
    "Mit diesem Dictionary, konvertieren Sie nun die eigentlichen Symbole der Smiles zu zahlen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1034,
   "id": "097335ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokenized_smiles = tokenize(data_bbbp.smiles,dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2766a0",
   "metadata": {},
   "source": [
    "Das Problem ist, wie auch schon im Beispiel, dass die Moleküle und damit die Smiles unterschiedlich lang sind:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1035,
   "id": "45a48131",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([27, 36, 48, ..., 43, 56, 49])"
      ]
     },
     "execution_count": 1035,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length_ll = np.array([len(x) for x in tokenized_smiles])\n",
    "length_ll"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b63be8",
   "metadata": {},
   "source": [
    "Sie müssen deswegen erst alle `tokenized_smiles` auf die gleiche Länge bringen. Und zwar auf die des längsten Smiles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1036,
   "id": "f1344c9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 1036,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length = max(length_ll)\n",
    "max_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a11edb4e",
   "metadata": {},
   "source": [
    "Allen Smiles, die aus weniger als 74 Tokens bestehen, fügen wir so lange extra Tokens hinzu, bis sie 74 Tokens lang sind.\n",
    "Der Token, der beigefügt wird, ist `<pad>`. Wir ordnen ihm den Wert `len(dictionary)` zu, da dieser die nächste ungenutzte Zahl ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1038,
   "id": "251d8545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29\n"
     ]
    }
   ],
   "source": [
    "print(len(dictionary))\n",
    "dictionary[\"<pad>\"]= len(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e3b4ad",
   "metadata": {},
   "source": [
    "Der folgende Code hängt diesen Paddingtoken an alle Smiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1041,
   "id": "8b708699",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, tok_smi in enumerate(tokenized_smiles):\n",
    "    tokenized_smiles[i] = tok_smi+ [dictionary[\"<pad>\"]]*(max_length - length_ll[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1042,
   "id": "53f2bd2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " 74,\n",
       " ...]"
      ]
     },
     "execution_count": 1042,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length_ll = [len(x) for x in tokenized_smiles]\n",
    "length_ll"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3253ea1e",
   "metadata": {},
   "source": [
    "Nun sind alle `tokenized_smiles` gleich lang und im richtigen Format. Sie müssen aber zuvor wieder die Daten in Trainings- und Testdatensatz teilen. \n",
    "Davor fügen wir zuvor die `tokenized_smiles` und Targets aus dem `data_bbbp` zusammen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1044,
   "id": "c68e8485",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.,  7.,  1., ..., 29., 29.,  1.],\n",
       "       [ 7.,  7.,  1., ..., 29., 29.,  1.],\n",
       "       [ 7.,  7.,  6., ..., 29., 29.,  1.],\n",
       "       ...,\n",
       "       [ 7.,  7.,  1., ..., 29., 29.,  1.],\n",
       "       [ 7.,  7.,  3., ..., 29., 29.,  1.],\n",
       "       [18.,  0., 14., ..., 29., 29.,  1.]])"
      ]
     },
     "execution_count": 1044,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_bbbp_tokenized = np.hstack([np.array(tokenized_smiles), data_bbbp.iloc[:,1:2]])\n",
    "data_bbbp_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 892,
   "id": "ddc850eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test=train_test_split(data_bbbp_tokenized,test_size=0.2,train_size=0.8, random_state=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcad9cb3",
   "metadata": {},
   "source": [
    "Nun separieren Sie die Input und Outputs wieder von einander. Wichtig hierbei: Die targets befinden sich in der letzen Spalte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8466d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = torch.tensor(train[:,:-1], dtype=torch.long )\n",
    "train_y = torch.tensor(train[:,-1], dtype=torch.float)\n",
    "test_x = torch.tensor(test[:,:-1], dtype=torch.long)\n",
    "test_y = torch.tensor(test[:,-1], dtype=torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d61613",
   "metadata": {},
   "source": [
    "Erstellen Sie jetzt den Trainings Dataloader, damit wir mit Minibatches trainieren können. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 893,
   "id": "dba649b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(train_x, train_y)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32)\n",
    "\n",
    "test_dataset = TensorDataset(test_x, test_y)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d465c5",
   "metadata": {},
   "source": [
    "Jetzt definieren Sie das Model.\n",
    "Wir brauchen eine Embedding Layer, eine Permute Layer und ein RNN. Hierfür verwenden wir ein GRU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1075,
   "id": "38ad8ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1111)\n",
    "model =nn.Sequential(nn.Embedding(len(dictionary),32, padding_idx = dictionary[\"<pad>\"]),\n",
    "                     Permute(1,0,2),\n",
    "                     nn.GRU(32,64))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a132db6",
   "metadata": {},
   "source": [
    "Auch brauchen Sie eine Linear Layer, die eine anhand des Outputs des GRU eine Prediction macht. \n",
    "Dafür erstellen wir ein zweites Model Names `pred_ll`.\n",
    "\n",
    "Warum brauchen wir ein zweites Model?\n",
    "\n",
    "Das liegt daran, dass alle RNNs in PyTorch mehr als einen Output haben. Einmal alle Hidden States und einmal die finalen Hidden States. Das `nn.Sequential` Netzwerk, weiß in diesem Fall nicht welchen Output es vom RNN weiter in die Linear Layer führen soll.\n",
    "\n",
    "Darum brauchen wir ein zweites Model `pred_ll`. Hier benutzen wir Batchnorm, und Dropout. Achten Sie dabei darauf, dass die Dimensionen von `BatchNorm1d` und `Linear`, der Outputdimension des `GRU` entsprechen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1076,
   "id": "88f41d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1111)\n",
    "pred_ll = nn.Sequential(nn.BatchNorm1d(64),nn.Dropout(0.2),nn.Linear(64,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699aa79c",
   "metadata": {},
   "source": [
    "Auch definieren Sie wieder eine Lossfunktion und einen Optimizer. Denken Sie daran, dass wir eine Binary Klassifikation haben.\n",
    "Da wir zwei Netzwerke haben, die wir zusammen updaten wollen, können wir die Parameter, der beiden Netzwerke, in einer List kombinieren und dem Optimizer zur Verfügung stellen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1077,
   "id": "5d4b59d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_funktion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(list(model.parameters()) + list(pred_ll.parameters()), lr =0.001) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1078,
   "id": "75037c0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.657 Training AUC: 0.706 | Test Loss: 0.663 Test AUC: 0.665\n",
      "Training Loss: 0.670 Training AUC: 0.732 | Test Loss: 0.699 Test AUC: 0.720\n",
      "Training Loss: 0.851 Training AUC: 0.735 | Test Loss: 0.859 Test AUC: 0.719\n",
      "Training Loss: 0.560 Training AUC: 0.746 | Test Loss: 0.606 Test AUC: 0.733\n",
      "Training Loss: 0.687 Training AUC: 0.770 | Test Loss: 0.740 Test AUC: 0.745\n",
      "Training Loss: 0.466 Training AUC: 0.782 | Test Loss: 0.537 Test AUC: 0.732\n",
      "Training Loss: 0.679 Training AUC: 0.778 | Test Loss: 0.734 Test AUC: 0.692\n",
      "Training Loss: 0.508 Training AUC: 0.791 | Test Loss: 0.649 Test AUC: 0.716\n",
      "Training Loss: 0.403 Training AUC: 0.807 | Test Loss: 0.537 Test AUC: 0.708\n",
      "Training Loss: 0.666 Training AUC: 0.817 | Test Loss: 0.749 Test AUC: 0.700\n",
      "Training Loss: 0.431 Training AUC: 0.828 | Test Loss: 0.551 Test AUC: 0.707\n",
      "Training Loss: 0.406 Training AUC: 0.847 | Test Loss: 0.537 Test AUC: 0.723\n",
      "Training Loss: 0.485 Training AUC: 0.865 | Test Loss: 0.589 Test AUC: 0.743\n",
      "Training Loss: 0.487 Training AUC: 0.888 | Test Loss: 0.581 Test AUC: 0.787\n",
      "Training Loss: 0.320 Training AUC: 0.898 | Test Loss: 0.476 Test AUC: 0.803\n",
      "Training Loss: 0.310 Training AUC: 0.906 | Test Loss: 0.467 Test AUC: 0.809\n",
      "Training Loss: 0.294 Training AUC: 0.914 | Test Loss: 0.459 Test AUC: 0.808\n",
      "Training Loss: 0.308 Training AUC: 0.918 | Test Loss: 0.481 Test AUC: 0.820\n",
      "Training Loss: 0.262 Training AUC: 0.924 | Test Loss: 0.429 Test AUC: 0.820\n",
      "Training Loss: 0.266 Training AUC: 0.926 | Test Loss: 0.436 Test AUC: 0.827\n",
      "Training Loss: 0.258 Training AUC: 0.934 | Test Loss: 0.435 Test AUC: 0.827\n",
      "Training Loss: 0.247 Training AUC: 0.938 | Test Loss: 0.449 Test AUC: 0.825\n",
      "Training Loss: 0.232 Training AUC: 0.942 | Test Loss: 0.447 Test AUC: 0.817\n",
      "Training Loss: 0.231 Training AUC: 0.946 | Test Loss: 0.486 Test AUC: 0.819\n",
      "Training Loss: 0.215 Training AUC: 0.950 | Test Loss: 0.486 Test AUC: 0.834\n",
      "Training Loss: 0.240 Training AUC: 0.952 | Test Loss: 0.481 Test AUC: 0.842\n",
      "Training Loss: 0.197 Training AUC: 0.957 | Test Loss: 0.485 Test AUC: 0.826\n",
      "Training Loss: 0.193 Training AUC: 0.960 | Test Loss: 0.504 Test AUC: 0.831\n",
      "Training Loss: 0.200 Training AUC: 0.964 | Test Loss: 0.537 Test AUC: 0.840\n",
      "Training Loss: 0.172 Training AUC: 0.966 | Test Loss: 0.543 Test AUC: 0.823\n",
      "Training Loss: 0.158 Training AUC: 0.970 | Test Loss: 0.543 Test AUC: 0.834\n",
      "Training Loss: 0.183 Training AUC: 0.969 | Test Loss: 0.617 Test AUC: 0.826\n",
      "Training Loss: 0.171 Training AUC: 0.972 | Test Loss: 0.584 Test AUC: 0.824\n",
      "Training Loss: 0.168 Training AUC: 0.973 | Test Loss: 0.609 Test AUC: 0.828\n",
      "Training Loss: 0.163 Training AUC: 0.975 | Test Loss: 0.592 Test AUC: 0.829\n",
      "Training Loss: 0.159 Training AUC: 0.975 | Test Loss: 0.662 Test AUC: 0.825\n",
      "Training Loss: 0.176 Training AUC: 0.975 | Test Loss: 0.702 Test AUC: 0.828\n",
      "Training Loss: 0.186 Training AUC: 0.977 | Test Loss: 0.758 Test AUC: 0.828\n",
      "Training Loss: 0.188 Training AUC: 0.980 | Test Loss: 0.795 Test AUC: 0.827\n",
      "Training Loss: 0.303 Training AUC: 0.982 | Test Loss: 0.918 Test AUC: 0.833\n"
     ]
    }
   ],
   "source": [
    "for i in range(40):\n",
    "    pred_ll.train()\n",
    "    for input_, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        rnn_output = model(input_)[1][0]\n",
    "        output = pred_ll(rnn_output).flatten()\n",
    "        \n",
    "        loss = loss_funktion(output, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    pred_ll.eval()\n",
    "    \n",
    "    rnn_output = model(train_x)[1][0]    \n",
    "    output = pred_ll(rnn_output).flatten()\n",
    "    loss_train = loss_funktion(output, train_y)\n",
    "    auc_train = roc_auc_score(train_y.numpy(),torch.sigmoid(output).detach().clone().numpy())\n",
    "    \n",
    "    rnn_output = model(test_x)[1][0]    \n",
    "    output = pred_ll(rnn_output).flatten()\n",
    "    loss_test = loss_funktion(output, test_y)\n",
    "    auc_test = roc_auc_score(test_y.numpy(),torch.sigmoid(output).detach().clone().numpy())\n",
    "    \n",
    "    print(\"Training Loss: %.3f Training AUC: %.3f | Test Loss: %.3f Test AUC: %.3f\"\n",
    "        % (loss_train.item(), auc_train,loss_test.item(), auc_test ))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935d8fd0",
   "metadata": {},
   "source": [
    "Sie sehen auch, mit einem RNN können Sie genaue Vorhersagen machen. In der Realität, funktionieren aber gerade bei kleinen Datensätzen ECFP und klassischen neuronale Netzwerke besser, da diese nicht so komplex sind. \n",
    "Als Letztes schauen wir uns noch die erlernten Embeddings an. \n",
    "Dafür speichern wir die Weight Matrix der Embedding Layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1096,
   "id": "76107e54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.1 ,  0.15,  0.16,  0.52,  0.11, -0.66,  0.41, -1.08, -0.06,\n",
       "        -2.17, -1.12, -2.25,  0.19, -1.83, -0.78,  0.77,  1.77,  1.97,\n",
       "         0.08, -0.27, -0.54, -0.62, -0.59, -0.18, -1.64,  1.33,  2.32,\n",
       "        -0.64, -0.19, -0.38,  1.32, -1.01],\n",
       "       [ 0.2 , -0.97,  1.19,  0.46, -0.55,  2.33, -0.18,  0.38, -0.18,\n",
       "         0.01, -0.09,  1.23, -0.18, -0.07, -1.49, -0.77,  0.34,  0.3 ,\n",
       "        -0.69, -0.76, -0.43,  2.85, -0.7 ,  1.21,  0.15,  0.28, -0.88,\n",
       "        -0.69, -1.21,  1.14,  0.73, -0.45],\n",
       "       [ 1.47,  0.87,  0.17, -0.94, -0.62,  1.41,  0.28,  0.55,  0.58,\n",
       "        -0.03, -0.56, -1.36, -0.55, -0.42,  1.27, -0.56, -0.72, -1.86,\n",
       "        -0.1 ,  1.46,  0.29,  0.01,  0.43, -0.25,  0.95, -2.44, -0.43,\n",
       "        -0.1 ,  0.69, -1.47, -1.45, -0.3 ],\n",
       "       [-0.71, -0.15, -0.47,  0.12, -1.03,  0.19, -0.91, -1.52,  0.37,\n",
       "         0.28, -2.  ,  0.21, -0.28,  0.17, -0.96,  0.46,  1.57, -0.67,\n",
       "        -0.56, -0.04,  0.4 , -1.72, -0.84, -0.02, -0.32,  1.48,  0.84,\n",
       "        -0.94, -0.21, -0.89, -0.58,  0.34],\n",
       "       [-0.47, -1.35,  0.74,  0.26, -2.68,  1.01,  1.85,  0.18, -0.8 ,\n",
       "        -0.8 ,  1.53, -1.  , -1.13,  0.77, -1.12, -2.01,  0.66,  0.41,\n",
       "         1.34,  2.1 , -1.01,  0.43,  0.23,  0.22, -0.61,  0.7 ,  0.68,\n",
       "        -1.07, -0.5 , -2.08, -0.62,  0.45],\n",
       "       [-1.2 , -1.02, -0.93, -1.45, -0.87,  0.26, -0.06,  0.31, -0.02,\n",
       "         0.5 ,  0.42,  0.9 , -1.55,  0.84, -1.89, -0.36,  0.46,  2.02,\n",
       "         2.65,  1.92,  0.73,  0.07,  0.07, -0.06,  0.83,  1.3 ,  1.54,\n",
       "        -1.13,  0.5 , -0.07,  0.2 ,  0.53],\n",
       "       [-1.28,  1.08, -0.42,  0.28, -1.04,  0.86,  0.95, -0.51,  0.53,\n",
       "        -0.85,  0.6 , -0.41,  0.84, -0.51, -0.  ,  0.83,  0.25,  0.3 ,\n",
       "         0.45, -0.16,  0.68, -0.03, -1.59,  0.19, -1.79, -0.34, -0.69,\n",
       "        -0.65, -0.61,  0.52, -0.67, -1.78],\n",
       "       [-1.09, -0.27,  0.2 , -0.35, -0.2 , -0.85,  0.89,  1.29, -0.16,\n",
       "        -0.88, -0.69,  0.06, -1.09,  0.64,  0.26,  0.29, -0.45,  1.18,\n",
       "         1.61,  0.18, -0.96, -0.63, -0.25, -0.15, -1.82,  0.51,  1.42,\n",
       "        -1.04, -1.13, -2.22, -0.9 , -1.95],\n",
       "       [-0.59,  1.17, -0.43,  0.39,  0.92,  0.58, -0.03, -0.45, -0.1 ,\n",
       "        -1.47,  1.91,  0.76,  0.18,  0.2 , -0.13,  0.06,  1.18,  0.14,\n",
       "        -0.05,  0.05, -0.31,  0.85, -0.64, -0.58,  1.34,  1.23,  1.81,\n",
       "         0.02,  0.31, -0.38,  0.14,  0.61],\n",
       "       [-0.63, -0.25, -0.38, -0.51,  0.35,  1.35, -2.14, -0.44,  0.46,\n",
       "        -0.57, -1.95,  0.96, -1.47, -1.65,  1.6 , -2.09, -1.62, -0.92,\n",
       "         0.4 ,  0.02,  1.2 ,  1.13, -1.11,  0.01,  0.6 , -0.96,  0.42,\n",
       "        -0.29,  0.03, -1.94,  0.7 ,  1.66],\n",
       "       [ 1.05, -1.55, -1.11,  1.16, -0.97, -0.87,  0.74,  0.12, -1.75,\n",
       "         0.83,  0.72, -1.42,  1.73,  1.01, -0.78, -0.79,  0.01,  1.77,\n",
       "         0.78, -0.47,  1.02,  2.36,  2.59,  1.56,  0.21,  0.57,  0.26,\n",
       "        -0.32,  1.01, -0.33, -0.35, -0.32],\n",
       "       [-0.95,  1.99,  0.33,  0.11,  1.03,  0.5 , -1.97,  0.95, -0.8 ,\n",
       "         0.6 ,  0.49,  1.07, -0.8 ,  0.66, -1.25,  0.61,  0.23, -1.08,\n",
       "        -0.27,  1.06, -0.58, -0.75, -1.66,  0.17,  2.03,  1.12, -1.2 ,\n",
       "         0.5 , -0.41,  0.12,  1.35, -0.76],\n",
       "       [-0.07,  0.29,  0.32, -0.79, -0.01, -0.11,  0.17, -0.64,  1.57,\n",
       "        -0.54,  1.1 ,  0.17,  0.19, -1.83, -0.3 ,  0.46, -0.43,  1.07,\n",
       "         0.04, -1.52, -0.57, -0.78, -0.34, -0.75, -0.1 ,  1.46,  0.05,\n",
       "         1.15,  0.23,  0.71,  0.34, -0.6 ],\n",
       "       [-0.53, -0.99,  1.53, -0.39, -0.08,  0.32, -2.01,  0.42,  0.59,\n",
       "        -0.73,  1.26,  0.77, -1.85,  1.44, -2.12, -0.58,  2.1 , -0.18,\n",
       "        -0.69, -0.9 , -1.91,  0.08, -0.75, -1.02, -1.48, -0.69,  1.24,\n",
       "         1.1 ,  0.86,  1.03,  0.66, -1.07],\n",
       "       [-0.98,  2.52,  1.1 ,  1.07,  1.57, -0.64, -0.54,  0.33, -0.87,\n",
       "         1.87, -1.17, -0.25,  0.03,  0.47, -2.06, -1.43, -0.34, -2.05,\n",
       "        -0.61,  3.27, -0.53,  0.49, -0.06,  1.23,  1.76,  0.52,  0.13,\n",
       "         2.12,  1.51, -0.19, -0.14,  0.49],\n",
       "       [ 0.63, -1.2 , -0.03,  0.58, -0.19,  1.13,  0.42, -1.19,  0.58,\n",
       "         0.8 , -0.9 ,  0.2 , -0.95, -0.35, -1.35,  0.58, -0.37,  2.52,\n",
       "        -0.08, -0.8 ,  0.05,  1.04,  1.24, -1.92,  0.71, -0.51, -0.28,\n",
       "        -2.57,  1.16, -0.02, -0.45, -1.63],\n",
       "       [ 0.02, -0.41,  1.29, -1.14, -0.03,  0.79,  1.15, -2.13, -1.27,\n",
       "        -0.01, -0.23,  0.36,  0.65,  1.62, -0.58,  0.94, -1.2 , -1.49,\n",
       "         0.2 , -1.19, -0.78,  0.68,  0.12, -0.39,  0.71, -0.08,  0.88,\n",
       "        -0.94,  0.09,  0.13,  0.53, -0.13],\n",
       "       [-1.69, -0.92, -0.57, -0.46,  0.33,  0.41,  0.66,  0.65, -1.2 ,\n",
       "        -0.53,  1.21, -0.64, -0.07,  0.34, -0.54,  0.36, -0.78, -1.52,\n",
       "         0.52, -0.48,  1.36,  0.25, -0.32, -0.87, -1.77, -0.47,  0.84,\n",
       "         0.8 , -1.08,  0.28, -0.71, -1.73],\n",
       "       [-0.41, -0.24,  0.04,  0.12, -0.17,  0.07,  0.47,  0.68, -1.27,\n",
       "         0.88, -0.72, -1.  ,  0.35,  0.35,  0.83, -0.17,  0.65,  0.21,\n",
       "        -1.19, -0.66, -0.24,  1.77,  0.41, -0.07,  0.12, -0.44,  0.54,\n",
       "         0.43, -0.32,  0.65, -1.6 , -0.98],\n",
       "       [-0.8 , -1.36,  0.43,  0.73,  0.95,  0.51,  0.43,  0.94,  0.57,\n",
       "        -0.06, -1.08,  1.59,  0.49,  1.57,  2.01, -1.11,  0.84, -0.22,\n",
       "         0.77,  0.52, -0.04,  1.68, -1.33,  1.69, -1.09,  0.3 , -0.39,\n",
       "         0.04,  0.1 ,  1.08, -2.17,  0.34],\n",
       "       [ 0.07,  0.47,  0.46, -1.6 ,  0.51, -0.08,  1.91, -0.42,  0.1 ,\n",
       "         1.55, -0.96, -1.49,  1.05,  0.3 ,  1.02,  2.94,  0.4 ,  0.8 ,\n",
       "         0.76,  1.75,  0.74, -0.19,  1.16, -0.21, -0.68,  0.39, -0.23,\n",
       "        -0.5 , -1.92, -0.6 , -0.97, -1.16],\n",
       "       [-0.29,  0.67,  0.72, -1.25,  1.39,  0.3 , -1.24, -0.74,  0.78,\n",
       "        -1.1 ,  2.27, -0.71, -1.48, -1.42, -0.22, -0.32, -0.63,  1.24,\n",
       "         0.01, -1.02,  0.25, -0.63,  0.07,  2.12,  0.46,  0.61,  0.53,\n",
       "         0.07,  0.86, -0.52,  0.66, -0.58],\n",
       "       [-0.65,  1.27,  1.27, -1.54,  0.28,  0.47, -0.75,  0.53, -0.15,\n",
       "         0.92,  1.1 , -1.11,  0.8 ,  0.94,  0.17,  0.19, -1.61,  0.73,\n",
       "        -0.23,  0.5 , -0.25,  0.5 ,  2.28, -0.67,  0.55, -1.91, -0.58,\n",
       "        -0.68,  0.76,  1.23,  0.2 ,  0.4 ],\n",
       "       [-0.66, -0.58, -0.32, -0.45, -0.5 ,  0.81, -0.44,  0.03, -0.8 ,\n",
       "         0.59, -0.71,  0.89, -0.82,  0.82,  1.16,  0.73, -0.48, -0.72,\n",
       "        -2.58,  0.6 , -1.41, -0.62,  2.39,  0.93,  0.5 , -2.3 ,  1.28,\n",
       "        -0.01,  0.8 ,  2.2 ,  0.88, -0.18],\n",
       "       [ 0.37, -0.28,  0.24, -0.51,  0.25, -0.83,  0.31,  1.98, -0.64,\n",
       "        -0.81,  2.09,  0.57,  0.41, -0.95, -0.2 , -0.04,  1.09,  0.91,\n",
       "        -1.  , -1.32, -0.53, -0.15, -0.13, -0.95, -0.25, -0.82, -0.99,\n",
       "        -0.07,  1.64, -0.6 , -0.11,  0.6 ],\n",
       "       [ 0.75, -0.9 , -1.03,  2.88,  0.74,  0.93, -0.22, -0.05, -0.5 ,\n",
       "        -0.84, -0.05,  1.14, -0.15, -0.03, -1.23, -0.12,  0.36,  1.13,\n",
       "         0.65, -0.2 ,  1.11, -1.32,  0.15,  1.05, -1.22,  1.08,  0.54,\n",
       "        -0.45,  1.12,  0.33, -0.35, -1.98],\n",
       "       [-0.32, -0.28,  0.78, -0.06,  2.5 , -0.04, -0.6 ,  0.99, -0.01,\n",
       "         0.65,  0.23,  0.38,  1.86, -0.82,  0.52, -0.08, -0.8 ,  0.26,\n",
       "         0.63, -1.01, -0.44, -0.81,  1.25,  2.05,  1.72,  0.47,  0.62,\n",
       "        -1.37,  0.  , -0.91, -0.87, -1.35],\n",
       "       [-1.72, -0.43,  1.79, -0.09,  0.52,  1.43,  0.01, -0.24, -1.55,\n",
       "        -1.15,  0.53, -0.2 ,  0.26,  0.66, -0.32, -0.94,  2.11,  0.71,\n",
       "        -0.43, -0.94, -0.08,  0.26, -0.01, -1.79,  0.77, -0.72, -0.09,\n",
       "        -0.74,  0.09,  0.31,  0.71, -0.03],\n",
       "       [-1.03,  0.47, -0.42, -0.1 ,  1.39,  1.54, -0.7 ,  0.76, -0.19,\n",
       "        -0.63, -0.18,  1.05,  1.22, -1.57,  0.35, -0.12, -0.4 , -0.99,\n",
       "         1.64,  1.22,  1.56, -1.97,  0.13,  0.25, -0.81,  0.58,  1.  ,\n",
       "        -0.66,  0.03, -0.15,  1.87,  1.53],\n",
       "       [ 0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "         0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "         0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
       "         0.  ,  0.  ,  0.  ,  0.  ,  0.  ]], dtype=float32)"
      ]
     },
     "execution_count": 1096,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_weights = list(model[0].parameters())[0].detach().clone().numpy()\n",
    "embedding_weights.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c159c15",
   "metadata": {},
   "source": [
    "Eine Möglichkeit die Embeddings zu analysieren, ist die Ähnlichkeit verschiedener Token über die `cosine_similarity` vergleichen. Tokens mit ähnlicher Funktion sollten ähnlicher Embeddings erhalten.\n",
    "\n",
    "Als Beispiel berechnen wir die Ähnlichkeit der Embeddings von einem Stickstoff in einem aromatischen Ring (`n`).\n",
    "Dafür finden wir im Dictionary welche Zahl zu `\"n\"` gehört, und damit auch den Index der Reihe in der Embedding Matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1105,
   "id": "0e762c40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 1105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_n = dictionary[\"n\"]\n",
    "dictionary[\"n\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c50e20c",
   "metadata": {},
   "source": [
    "Wir berechnen die Similarity von dieser Embedding zu allen andere Embeddings. Im Anschluß wird ein Barchart erstellt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1108,
   "id": "2ba8d15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_N = cosine_similarity(embedding_weights[idx_n:idx_n+1,:],embedding_weights)[0]\n",
    "labels = [x for x in dictionary]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1109,
   "id": "a1ae8574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='symbol'>"
      ]
     },
     "execution_count": 1109,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sorted_values=pd.DataFrame({\"symbol\": labels, \"similarity\":similarity_N}).sort_values(\"similarity\", ascending =False)\n",
    "sorted_values.plot.bar(\"symbol\", \"similarity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b7e203",
   "metadata": {},
   "source": [
    "Das Problem bei einem so kleinen Datensatz ist, dass die Embeddings extrem stark vom Datensatz abhängig sind. Trotzdem können generelle Trends erkannt werden. `n` ist ähnlicher zu aromatischen Atomen `o` oder `c` als zu Atomen außerhalb eines aromatischen Rings `C`, `N` und `O`. Die genauen Embeddings können aber auch extrem von Training zu Training variieren.\n",
    "\n",
    "Sie können auch andere Symbole vergleichen, indem Sie hier:\n",
    "\n",
    "`idx_n = dictionary[\"n\"]`\n",
    "\n",
    "Ein anderes Symbol auswählen."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
