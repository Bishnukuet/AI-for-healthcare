{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "978f8a26",
   "metadata": {},
   "source": [
    "# Autoencoders\n",
    "\n",
    "\n",
    "---\n",
    "**Lernziele**\n",
    "\n",
    "- Sie verstehen das Konzept eines Autoencoders\n",
    "- Sie verstehen wie ein RNN Smiles generieren kann\n",
    "- Sie können ein Netzwerk auch als PyTorch Klasse definieren\n",
    "- Sie verstehen die Bedeutung der `<sos>`/`<eos>` Token \n",
    "---\n",
    "Im heutigen Notebook beschäftigen wir uns mit den sogenannten **Autoencodern**.\n",
    "Autoencoder werden meisten in durch Selfsupervised Training trainiert.\n",
    "Als Erinnerung, Selfsupervised Training bezeichnet das Training von neuronalen Netzwerke, bei dem der Input und Output identisch sind. Das Ziel ist es also den Input wiederherzustellen. \n",
    "\n",
    "Doch welchen Mehrwert hat es ein Netzwerk, welches nur den Input wiederherstellt.\n",
    "Tatsächlich interessieren wir uns nicht unbedingt für den Output eines Autoencoder. Uns interessiert mehr, was in der Mitte des Netzwerkes passiert. \n",
    "Denn das eigentliche Ziel von Autoencodern ist, die Daten zu komprimieren, also möglichst effektiv darzustellen.\n",
    "\n",
    "Im Beispielbild wird zum Beispiel ein Autoencoder für Bilder dargestellt:\n",
    "\n",
    "<img src=\"https://d3i71xaburhd42.cloudfront.net/b1786e74e233ac21f503f59d03f6af19a3699024/2-Figure1-1.png\" >\n",
    "\n",
    "*Yifei Zhang - A Better Autoencoder for Image: Convolutional Autoencoder * **2018**\n",
    "\n",
    "Ein Autoencoder besteht aus zwei Netzwerken, einem **Encoder** und einem **Decoder**. Der Output des Encoder wird als Input für den Decoder genutzt. Der Encoder soll lernen, möglichst effektiv,  die Daten in einem niedrig dimensionalen Raum (latent Space) darzustellen. Diese Darstellung ist in der Regel einfach ein Vektor, welcher auch als **latent Vector** beschrieben wird. Der Deocder wird trainiert, um anhand dieses latent Vectors den originalen Input wieder herzustellen. \n",
    "\n",
    "Wir können selber bestimmen, wie groß der latent Vector werden soll. Meistens wird eine besonders kleine Größe gewählt, um eine größere Kompression zu gewährleisten.\n",
    "Nach erfolgreichem Training sollte der *latent Vector*, trotz seiner geringen Größe, genug Information enthalten, um das Bild vollständig wieder auszugeben. Das bedeutet, dass dieser Vector ausreichend informativ ist, um das komplette Bild zu beschreiben. Tatsächliche Anwendungen gehen über die einfach Rekonstruktion hinaus.\n",
    "\n",
    "Zum Beispiel werden Autoencoder benutzt und die Qualität von Bilder zu verbessern. Hierfür werden als Input niedrig auflösende Bilder benutzt und der Output ist dasselbe Bild in seiner regulären (höher) Auflösung. So werden Netzwerke trainiert, die später schlecht aufgelöste Bilder schärfen können. \n",
    "\n",
    "\n",
    "<img src=\"https://assets-global.website-files.com/5d7b77b063a9066d83e1209c/60bcd0b7b750bae1a953d61d_autoencoder.png\" width =\"400px\">\n",
    "\n",
    "*Hmrishav Bandyopadhyay - An Introduction to Autoencoders: Everything You Need to Know* **2021**\n",
    "\n",
    "Autoencoder gibt es aber nicht nur für Bilder, sondern auch für Text. Hierfür werden RNNs verwedent. \n",
    "Im letztes Notebook haben wir bereits besprochen, dass der letzte Hidden State eines Recurrent Neural Netzwerk ein Zusammenfassung der gesamten Inputsequenz ist. In dem Besipeil der Hidden State $O_5$\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/724/1*1U8H9EZiDqfylJU7Im23Ag.gif\">\n",
    "\n",
    "*Michael Phi - An illustrated Guide to Recurrent Neural Networks*\n",
    "\n",
    "Der Output $O_5$ ist quasi schon eine kompremierete Version unseres Satzes. Der Hidden State $O5$ ist also der latent Vector der unseren Satz beschreibt. Dementsprechend ist auch das Netzwerk, das diesen Vektor erzeugt hat unsere Encoder. Für unseren Autoencoder fehlt nur noch der Decoder, der den originalen Satz aus dem latent Vector wieder herstellen kann. Wie das genau funktiert besprechen wir an Hand eines Beispiel mit Smiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ca11da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit.Chem.Draw import MolsToGridImage\n",
    "from rdkit.Chem import AllChem as Chem\n",
    "from rdkit import DataStructs\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "%run ../utils/utils.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd2d9e1",
   "metadata": {},
   "source": [
    "Diese Woche benutzen wir einen Datensatz der Firma Enamine. Und zwar die [High Fidelity Fragment Library](https://enamine.net/compound-libraries/fragment-libraries/high-fidelity-library). Dieser Datensatz besteht aus Fragmenten, die, aufgrund ihrer physikochemischen Eigenschaften, sich besonders gut für den Bereich MedChem eignen. Für uns ist vor allem wichtig, dass die Moleküle nicht zu groß werden. Denn aus dem Latent Vector einen validen Smiles zu kreieren ist schwierig . Je länger der Smiles wird, desto komplexer wird die Aufgabe für das Netzwerk.\n",
    "\n",
    "Diese Woche kommen die Moleküle auch in einem anderen Dateiformat. Der `.sdf` Format speichert die Moleküle mit mehr Detail. So können hier z.B. auch Informationen zu der Konformation gespeichert werden. \n",
    "\n",
    "Ein einzelnes Molekül wird wie folgt dargestellt:\n",
    "```\n",
    "\n",
    "  Mrv0541 07182119162D          \n",
    "\n",
    " 12 12  0  0  0  0            999 V2000\n",
    "    0.7145    2.0625    0.0000 C   0  0  0  0  0  0  0  0  0  0  0  0\n",
    "    0.7145    1.2375    0.0000 C   0  0  0  0  0  0  0  0  0  0  0  0\n",
    "    1.4289    0.8250    0.0000 C   0  0  0  0  0  0  0  0  0  0  0  0\n",
    "    1.4289   -0.0000    0.0000 C   0  0  0  0  0  0  0  0  0  0  0  0\n",
    "    2.1434   -0.4125    0.0000 F   0  0  0  0  0  0  0  0  0  0  0  0\n",
    "    0.7145   -0.4125    0.0000 C   0  0  0  0  0  0  0  0  0  0  0  0\n",
    "    0.7145   -1.2375    0.0000 C   0  0  0  0  0  0  0  0  0  0  0  0\n",
    "    1.4289   -1.6500    0.0000 O   0  0  0  0  0  0  0  0  0  0  0  0\n",
    "   -0.0000   -1.6500    0.0000 O   0  0  0  0  0  0  0  0  0  0  0  0\n",
    "    0.0000    0.0000    0.0000 C   0  0  0  0  0  0  0  0  0  0  0  0\n",
    "   -0.7145   -0.4125    0.0000 F   0  0  0  0  0  0  0  0  0  0  0  0\n",
    "    0.0000    0.8250    0.0000 C   0  0  0  0  0  0  0  0  0  0  0  0\n",
    "  1  2  1  0  0  0  0\n",
    "  2  3  4  0  0  0  0\n",
    "  3  4  4  0  0  0  0\n",
    "  4  5  1  0  0  0  0\n",
    "  4  6  4  0  0  0  0\n",
    "  6  7  1  0  0  0  0\n",
    "  7  8  2  0  0  0  0\n",
    "  7  9  1  0  0  0  0\n",
    "  6 10  4  0  0  0  0\n",
    " 10 11  1  0  0  0  0\n",
    " 10 12  4  0  0  0  0\n",
    "  2 12  4  0  0  0  0\n",
    "M  END\n",
    ">  <Catalog ID>\n",
    "Z1255462241\n",
    "\n",
    ">  <PlateID>\n",
    "1225133-R3-01\n",
    "\n",
    ">  <Well>\n",
    "A02\n",
    "\n",
    ">  <MW (desalted)>\n",
    "172.129\n",
    "\n",
    ">  <CLogP>\n",
    "2.082\n",
    "\n",
    ">  <HBD>\n",
    "1\n",
    "\n",
    ">  <TPSA>\n",
    "37.300\n",
    "\n",
    ">  <RotBonds>\n",
    "1\n",
    "\n",
    "```\n",
    "Sie sehen auch zusätzliche Informationen wie TPSA oder LogP können gleich mit gespeichert werden.\n",
    "\n",
    "Um so eine `.sdf` Datei in Python einzulesen brauchen wir einen sogenannten `MolSupplier` von `rdkit`. Ein Supplier stellt die Verbindung zwischen unsere Datein und Python her. Mit einem `for-loop` können dann die einzelnen Smiles aus dem SDF-File generiert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bb138f",
   "metadata": {},
   "outputs": [],
   "source": [
    "suppl = Chem.SDMolSupplier(\"../data/high_fidelity/Enamine_High_Fidelity_Fragment_Library_plated_1920cmds_20210718.sdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec71ed05",
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles = []\n",
    "for mol in suppl:\n",
    "    smiles.append(Chem.MolToSmiles(mol)) \n",
    "smiles[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdbfa9c",
   "metadata": {},
   "source": [
    "Sie sehen, auch so können wir Smiles aus den `.sdf` Dateien generieren. Auch können wir uns die Strukturen einmal anzeigen lassen, um ein besseres Gefühl für die Art von Fragmenten zu bekommen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1984e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MolsToGridImage([Chem.MolFromSmiles(x)for x in smiles[:9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddb44b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(smiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5619c39e",
   "metadata": {},
   "source": [
    "Insgesamt haben wir 1920 Moleküle im Datensatz."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73af29b3",
   "metadata": {},
   "source": [
    "Wenn Sie sich die Smiles genau anschauen fällt Ihnen etwas auf?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46d9c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be70b608",
   "metadata": {},
   "source": [
    "Ein Problem ist, dass noch Stereoinformation in den Smiles enthalten sind. Zum Beispiel das `@` Symbol. Ein weiteres Problem ist der `.`. Dieser markiert den Beginn eines weiteren Moleküls. In unserem Fall sind es aber eigentlich nur `Cl` Atome, die noch in manchen Smiles sind. \n",
    "Zum Beispiel Moleküle 27."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1642e7ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Chem.MolFromSmiles(smiles[26])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3547f368",
   "metadata": {},
   "source": [
    "Wir können sowohl Stereoinformation, als auch die \"extra\" Moleküle mit  Stringmanipulationen entfernen.\n",
    "\n",
    "`string.replace(\"@\", \"\")`\n",
    "\n",
    "sucht im `string` nach dem Zeichen `@` und falls es welche findet werden sie mit `\"\"` ersetzt. Also einfach gelöscht.\n",
    "\n",
    "`string.split(\".\")`\n",
    "\n",
    "teilt den `string` bei jedem `\".\"`. Die Funktion gibt die einzelnen Substrings als Liste aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35edf4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Schoko.l@de\".replace(\"@\", \"\").split(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07972f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_molecules = []\n",
    "for smile in smiles:\n",
    "    smile = smile.replace(\"@\", \"\")\n",
    "    smile = smile.replace(\"\\\\\", \"\")\n",
    "    sub_molecules.append(smile.split(\".\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175e7da1",
   "metadata": {},
   "source": [
    "Im nächsten Schritte müssen wir nur noch durch die Moleküllisten durch iterieren. Wenn ein Smiles aus mehreren Molekülen bestand, wählen wir einfach das größte Molekül als das richtige aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b97a07d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "filtered_smiles =[]\n",
    "for mol_list in sub_molecules:\n",
    "    filtered_smiles.append(mol_list[np.argmax([len(x) for x in mol_list])])\n",
    "    \n",
    "Chem.MolFromSmiles(filtered_smiles[26])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b429d79",
   "metadata": {},
   "source": [
    "Das 27 Moleküle hat jetzt nicht mehr die zusätzlichen `HCl`s."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bac998",
   "metadata": {},
   "source": [
    "Die Smiles sind jetzt \"sauber\" und wir können beginnen sie für das RNN aufzubereiten. Also einen Dictionary zu erstellen und die Smiles durch Tokens zu ersetzen. Zunächst benutzen wir wieder die `creat_dict` Funktion, um einen Dictionary für unsere Daten zu erstellen. Doch diesmal benutzten wir auch den Parameter `add_tokens = True`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3047333c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dictionary = create_dict(filtered_smiles, add_tokens =True)\n",
    "dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad4917b",
   "metadata": {},
   "source": [
    "Es wurden 3 Tokens hinzugefügt, die nicht in den Smiles vorkommen.\n",
    "\n",
    "- `<pad>` kennen Sie bereits, dieser wird benutzt, um alle Smiles auf dieselbe Länge zu bekommen.\n",
    "\n",
    "- `<sos>` ist ein Token, der den Anfang eines Smiles ankündigt. \"Start of Sentence\". Dieser Token wird **vor** jeden Smiles gestellt.\n",
    "\n",
    "- `<eos>` kündigt das Ende des Smiles an. Nachdem der eigentliche Smiles zu Ende ist foglt der `<eos>` Token und dann die Paddingtokens\n",
    "\n",
    "Unsere Smiles sollen also wie folgt aussehen:\n",
    "\n",
    "```python\n",
    "\"<sos>OCc1ccc2occc2c1<eos><pad><pad>\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375bb0b0",
   "metadata": {},
   "source": [
    "Warum ist das nötig? Wieso werden diese besonderen Tokens benötigt?\n",
    "\n",
    "Das liegt daran, wie ein Decoder für ein RNN funktioniert. \n",
    "\n",
    "Nochmal als Erinnerung, so sieht unser Model aus:\n",
    "\n",
    "<img src=\"Img\\rnn\\auto_1.png\" width =\"400px\">\n",
    "\n",
    "Den Encoder haben wir quasi letzte Woche geschrieben, wir müssen uns nur noch auf den Decoder konzentrieren.\n",
    "Die Grundidee eines Decoder RNN ist es, dass der SMILES Token für Token hintereinander generiert.\n",
    "\n",
    "Ein Beispiel:\n",
    "\n",
    "Der Decoder bekommt den latent Vector vom Encoder:\n",
    "Darauf generiert ein `C`. Jetzt kann der Decoder mithilfe des Latent Vector und dem bereits generierten `C` ein weiteres `C` generieren. Darauf hin ist unsere momentane SMILES `CC`. Jetzt wiederholt sich der Schritt wieder, mit dem Wissen vom latent Vector und den bereits zwei `CC`.\n",
    "Mit dem Wissen kann der Decoder jetzt z.B. ein `=` generieren: `CC=` usw...\n",
    "Theoretisch könnte das unendlich so weiter gehen. Deswegen gibt es einen `<eos>` Token. Dieser erlaubt es dem Netzwerk den Smiles zu beenden, wenn es denkt dieser ist komplett.\n",
    "\n",
    "Ein bisschen theoretischer wird es im Folgenden:\n",
    "\n",
    "Um es genauer zu verstehen, wiederholen wir noch einmal schnell wie ein RNN funktioniert.\n",
    "\n",
    "Ein RNN hat immer zwei Inputs. Einmal den normalen Input, also der momentane Token (Smiles Symbol) für den es eine Vorhersage zu machen gilt.\n",
    "Zusätzlich wird ein Hidden State vom vorherigen Schritt genommen. Also der Output des RNNs für den vorherigen Token.\n",
    "\n",
    "Durch den Encoder erhalten wir schon den latent Vector, welcher unser initialer Hidden State sein wird. \n",
    "<img src=\"Img\\rnn\\auto_3.png\" width =\"400px\">\n",
    "\n",
    "Doch was ist unser initialer Input?\n",
    "\n",
    "<img src=\"Img\\rnn\\auto_4.png\" width =\"400px\">\n",
    "\n",
    "Das Problem ist, wenn wir den tatsächlich ersten Token des originalen Smiles als ersten Token für das Netzwerk verwenden, ist es relativ leicht diesen richtig zu vorhersagen. Deswegen benutzen wir zunächst den `<sos>` Token. Dieser enthält nämlich keine Informationen über den Smiles. Das heißt, der erste Token wird nur auf Basis des Hidden States bzw. der latent Vectors vorhergesagt. Wichtig ist auch das der Output des RNN (der neue Hidden State) erst noch durch eine Linear Layer geführt wird, die den richtigen Token vorhersagt.\n",
    "<img src=\"Img\\rnn\\auto_6.png\" width =\"400px\">\n",
    "\n",
    "Im nächsten Schritt, ersetzt der neue Hidden State den latent Vector, als Input für den nächsten Schritt. Auch wird jetzt nicht mehr ein Token des originalen Smiles als Input benutzt, sondern der Token, der im vorangegangen Schritt vorhergesagt worden ist. \n",
    "Das heißt, auch wenn der Decoder am Anfang einen Fehler macht, dann rechnet er auch mit diesem Fehler weiter.\n",
    "<img src=\"Img\\rnn\\auto_7.png\" width =\"400px\">\n",
    "\n",
    "\n",
    "Wir wiederholen, dass so lange bis wir die Länge des längsten Smiles in unserm Datensatz erreicht haben. Natürlich sind die meisten Smiles nicht so lange, deswegen können wir den `<eos>` gebrauchen. Mit dem kann der Smiles schon vorher als fertig erkannt werden. \n",
    "<img src=\"Img\\rnn\\auto_8.png\" width =\"400px\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760abc3c",
   "metadata": {},
   "source": [
    "Wenn wir in der Funktion `tokenize` ` (..., add_tokens=True)` benutzen werden automatisch die `<sos>` und `<eos` zu jedem Smiles hinzugefügt. Das ist die `0` die im `dictionary` für `<sos>` steht und die `1` für `<eos>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe1840b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_smiles = tokenize(filtered_smiles,dictionary, add_tokens =True)\n",
    "tokenized_smiles[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2157fd4b",
   "metadata": {},
   "source": [
    "Noch sind die Smiles alle unterschiedlich lang. Wir berechnen zu nächst die Anzahl der Tokens in jedem Smiles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba76b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_lengths = np.array([len(x) for x in tokenized_smiles])\n",
    "max_length=max(token_lengths)\n",
    "max_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61d941b",
   "metadata": {},
   "source": [
    "Wir können die Anzahl der Tokens auch mit einem Histogramm darstellen. Das Problem ist nämlich, dass je mehr Tokens ein Smiles hat, desto schwieriger wird es für den Decoder den kompletten Smiles zu entschlüsseln."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b22d62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.hist(token_lengths, bins=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73df0d1f",
   "metadata": {},
   "source": [
    "Zum Beispiel könnten wir alle Moleküle aus dem Datensatz werfen, die aus mehr 26 Tokens bestehen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4683ef65",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(token_lengths>26)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f16c132",
   "metadata": {},
   "source": [
    "Das sind genau 291 Moleküle. Das ist natürlich nicht ideal, aber hilt uns im Training. gerade mit so wenig Daten ist es schwierig ein Autoencoder zu trainieren. Wir werfen diese großen Moleküle zunächst aus dem Datensatz. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da40f8db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filtered_smiles=np.array(filtered_smiles)[token_lengths<=26].tolist()\n",
    "len(filtered_smiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f6c028",
   "metadata": {},
   "source": [
    "Mit den reduzierten Daten erstellen wir einen neuen Dictionary und tokenizen unsere Daten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9ef97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = create_dict(filtered_smiles, add_tokens =True)\n",
    "tokenized_smiles = tokenize(filtered_smiles,dictionary, add_tokens =True)\n",
    "tokenized_smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a339d6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_lengths = np.array([len(x) for x in tokenized_smiles])\n",
    "max_length=max(token_lengths)\n",
    "max_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decca5bc",
   "metadata": {},
   "source": [
    "Alle unsere Smiles bestehen jetzt aus maximal 26 Tokens. Als letzten Schritt müssen wir noch die Smiles die nicht aus 26 Tokens bestehen auf die richtige Länge bringen. Dazu benutzen wir den `<pad>` Token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0cdfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, tok_smi in enumerate(tokenized_smiles):\n",
    "    tokenized_smiles[i] = tok_smi+ [dictionary[\"<pad>\"]]*(max_length - token_lengths[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51c6cde",
   "metadata": {},
   "source": [
    "Im letzten Schritt konvertieren, wir die Listen von Tokens zu einem Tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea1188a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_smiles=torch.tensor(tokenized_smiles, dtype=torch.long)\n",
    "tokenized_smiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da119cd9",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "Heute werden wir das erstmal nicht `nn.Sequential` benutzen, um unsere Model zu erstellen. Bei einfache Architekturen, bietet sich  `nn.Sequential` an, dass es schnell zu definieren ist. Allerdings ist es nicht sehr flexibel. \n",
    "Deswegen werden meisten Netzwerke mit PyTorch \"von Hand\" geschrieben.\n",
    "\n",
    "Wie das geht, schauen wir uns heute an:\n",
    "\n",
    "Zwei Prozesse muss ein Netzwerk in PyTorch erledigen:\n",
    "\n",
    "1. Es muss die nötigen Weights initialisieren \n",
    "2. Es muss den Input durch das Netzwerk führen\n",
    "\n",
    "Das Initialisieren bei `nn.Sequential()` wird beim `model` erstellen automatisch gemacht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89fa752",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Linear(10,20), nn.ReLU(), nn.Dropout(0.2), nn.Linear(20,1))\n",
    "model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53d3d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(model.parameters())[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab11033",
   "metadata": {},
   "source": [
    "So haben wir bis jetzt unsere Netzwerke definiert. Jede Layer wird automatisch\n",
    "`model = nn.Sequential(nn.Linear(10,20), nn.ReLU(), nn.Dropout(0.2), nn.Linear(20,1))` durch diesen Schritt erstellt und die Weight zufällig initialisiert.\n",
    "\n",
    "Wir können, aber auch unser eigenes Netzwerk selber definieren.\n",
    "Dafür müssen wir ein PyTorch Klasse erstellen. Klassen in Python ähneln ein wenig Funktionen. Nur können Klassen auch Eigenschaften und eigene Funktionen enthalten. Auf die genauen Funktionen von Klassen werden wir hier nicht ein gehen.\n",
    "\n",
    "Wichtig ist, dass wir auch Klassen erstellen können, die sich wie PyTorch Klassen verhalten.\n",
    "Dafür schreiben wir zunächst folgenden Code:\n",
    "\n",
    "``` python\n",
    "class einfaches_nn(nn.Module):\n",
    "```\n",
    "\n",
    "Damit legen wir fest, dass die Klasse `einfaches_nn` eine Klasse, die zu `nn.Module` gehört. Also wie andere Layer oder Modelle in PyTorch zu `nn` gehören soll.\n",
    "\n",
    "Als Nächstes folgt die Initialisierung \n",
    "\n",
    "``` python\n",
    "class einfaches_nn(nn.Module):\n",
    "    def __init__(self,input_dim, hid_dim, out_dim, dropout):\n",
    "        super().__init__()\n",
    "```\n",
    "\n",
    "`def __init__(self,input_dim, hid_dim, out_dim, dropout):` ist eine Funktion, die beim Initialisieren des Netzwerkes aufgerufen werden soll. Wichtig ist, dass neben den Dimensionen, die die Größe des Netzwerkes festlegen, auch ein `self` als Input aufgeführt ist.\n",
    "\n",
    "`self` \"enthält\" alle Informationen, die für diese Klasse gespeichert werden. Diese können auch über die Funktion hinaus benutzt werden. Das sollte in ein paar Minuten deutlicher werden.\n",
    "\n",
    "`super().__init__()` ist Teil des Codes der wichtig für PyTorch Klassen ist. Dieser Teil darf nicht in der Initialisierung fehlen.\n",
    "\n",
    "Als Nächstes können wir unsere linear Layers und Dropout in `self` \"speichern\":\n",
    "\n",
    "``` python\n",
    "class einfaches_nn(nn.Module):\n",
    "    def __init__(self,input_dim, hid_dim, out_dim, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.ln1 = nn.Linear(input_dim, hid_dim)\n",
    "        self.ln2 = nn.Linear(hid_dim, out_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "```\n",
    "\n",
    "`self.ln1 = nn.Linear(input_dim, hid_dim)` erlaubt es uns, später in andere Funktionen die erste linear Layer mit `self.ln1` auszuwählen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ddbcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class einfaches_nn(nn.Module):\n",
    "    def __init__(self,input_dim, hid_dim, out_dim, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.ln1 = nn.Linear(input_dim, hid_dim)\n",
    "        self.ln2 = nn.Linear(hid_dim, out_dim)\n",
    "        self.dropout = nn.Dropout(dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9499aaea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_2 = einfaches_nn(input_dim=10,hid_dim= 20, out_dim=1, dropout=0.2)\n",
    "model_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2cbf64",
   "metadata": {},
   "source": [
    "Wir können sehen, dass das Netzwerk auch aus den richtigen Layers besteht, aber in falscher Reihenfolge. Außerdem fehlt die ReLU Funktion. Das ist bis jetzt auch nicht weiter schlimm, denn die `__init__` Funktion soll ja nur das Model initialisieren, also erst einmal nur die Layers und deren Weights kreieren. ReLU hat keine Weights und muss deswegen nicht \"initialisiert\" werden.\n",
    "\n",
    "Hier ist auch der Beweis, dass das Netzwerke `model_2` jetzt zufällige Weights hat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c430e4dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list(model_2.parameters())[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03703992",
   "metadata": {},
   "source": [
    "Wir können auch probieren, ob die Model von einem Input (`fake_input` enthält zufällige Zahlen) einen Output generieren kann."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbe3136",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_input = (torch.rand(10))\n",
    "\n",
    "model(fake_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1610dcef",
   "metadata": {},
   "source": [
    "Für das `nn.Sequential` kein Problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919c7720",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_input = (torch.rand(10))\n",
    "\n",
    "model_2(fake_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1ec394",
   "metadata": {},
   "source": [
    "Der Fehler \n",
    "```python\n",
    "raise NotImplementedError\n",
    "```\n",
    "\n",
    "wird ausgegeben. Das bedeutet wir haben dieser Teil des Modells nicht implementiert, also noch nicht geschrieben.\n",
    "Bis jetzt kann `einfaches_nn` nur Weight initialisieren. Es weiß aber noch nicht, wie es den Input durch das Netzwerk führen soll.\n",
    "In `nn.Sequentual` wird das automatisch gemacht. Der Input wird einfach nacheinander durch die Layers geführt. Die Reihenfolge ergibt sich aus der Reihenfolge der Layers bei der Initialisierung. \n",
    "\n",
    "Für unsere eigene Klasse brauchen wir noch eine weitere Funktion Namens \n",
    "\n",
    "```python\n",
    "def forward(self, x):\n",
    "```\n",
    "`forward` ist, wie der Name andeutet, für die Forward Propagation zuständig. Es legt fest in welcher Reihnfolge Input `x` durch die zuvor definierten Layers geführt wird.\n",
    "Wichtig ist hier auch das neben `x` auch wieder `self` ein Input ist. `self` enthält alle Informationen, die wir bereits in der `__ìnit__` definiert haben.\n",
    "\n",
    "```python\n",
    "class einfaches_nn(nn.Module):\n",
    "    def __init__(self,input_dim, hid_dim, out_dim, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.ln1 = nn.Linear(input_dim, hid_dim)\n",
    "        self.ln2 = nn.Linear(hid_dim, out_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.ln1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        output = self.ln2(x)\n",
    "        return output\n",
    "```\n",
    "\n",
    "Hier geben wir Schritt für Schritt an was mit dem originalen Input passiert. Im ersten Schritt wird `x`durch die erste Linear Layer geführt. Diese ist in `self.ln1` gespeichert. Nur für die Activationfunktion brauchen wir kein `self` da diese ja auch nicht initialisiert wurde.\n",
    "\n",
    "---\n",
    "**Wichtig ist auch, dass wir jetzt nicht mehr** `nn.ReLU` **verwenden können, sondern wir müssen ** `.nn.functional.relu()` **benutzen**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d3d1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class einfaches_nn(nn.Module):\n",
    "    def __init__(self,input_dim, hid_dim, out_dim, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.ln1 = nn.Linear(input_dim, hid_dim)\n",
    "        self.ln2 = nn.Linear(hid_dim, out_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.ln1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = nn.functional.relu(x)\n",
    "        output = self.ln2(x)\n",
    "        return output\n",
    "    \n",
    "model_2 = einfaches_nn(input_dim=10,hid_dim= 20, out_dim=1, dropout=0.2)\n",
    "model_2    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd40ce1",
   "metadata": {},
   "source": [
    "An der Initialisierung hat sich nichts geändert, aber wir können jetzt Input durch das Netzwerk führen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee781af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2(fake_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877679b1",
   "metadata": {},
   "source": [
    "So können wir also auch komplexere Netzwerke schreiben, die nicht nur einen Input haben."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c483f16c",
   "metadata": {},
   "source": [
    "## Encoder\n",
    "\n",
    "Jetzt zurück zu unserem Autoencoder.\n",
    "Zunächst definieren wir den Encoder.\n",
    "Wir haben eine `nn.Embedding` Layer  und eine `nn.GRU` Layer. Der Encoder ist eigentlich genau der gleiche wie im letzten Notebook unser RNN, nur das wir es hier selber explizit schreiben.\n",
    "\n",
    "Schauen Sie sich die `forward` Funktion an. Als Input nimmt es die eine `input_seq`, also eine Reihenfolge von Tokens. Ausgeben wird der letzte `hidden` State des Netzwerkes. Dieser beschreibt den kompletten Smiles und ist gleichzeitig unser latent Vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5a4ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hid_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.hid_dim = hid_dim \n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim) \n",
    "        self.rnn = nn.GRU(emb_dim, hid_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, input_seq):\n",
    "        embedded = self.dropout(self.embedding(input_seq))\n",
    "        outputs, hidden = self.rnn(embedded) \n",
    "        return hidden\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0293a76",
   "metadata": {},
   "source": [
    "## Decoder \n",
    "\n",
    "Der Decoder ist schon durchaus komplexer.  Wenn Sie hier eventuell nicht den kompletten Code verstehen, ist das in Ordnung. So lange Sie dem allgemeinen Konzept folgen können.\n",
    "Auch hier haben wir wieder eine `Embedding` Layer und eine `GRU` Layer, zusätzlich gibt es noch eine Linear Layer. Diese trifft die Vorhersage, welcher Token jetzt folgt basierend auf dem  Output des GRUs.\n",
    "\n",
    "Im `forward` Schritt gibt es zwei Inputs, einmal der `Input`, das ist der letzten Token der vorhergesagt worden ist. Oder am Anfang eben der `<sos>` Token. `hidden` ist der Hidden State des GRU aus dem vorherigen Schritt.\n",
    "`forward` gibt sowohl die `prediction`, der vorhergesagte Token, als auch `hidden`, den neuen Hidden State, aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bea1239",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hid_dim, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hid_dim = hid_dim\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        self.rnn = nn.GRU(emb_dim, hid_dim)\n",
    "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        \n",
    "        input = input.unsqueeze(0)\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        output, hidden = self.rnn(embedded, hidden)\n",
    "        prediction = self.fc_out(output[0])\n",
    "        \n",
    "        return prediction, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81eba0ee",
   "metadata": {},
   "source": [
    "Als Letztes bringen wir beide Komponenten in einem `Autoencoder` zusammen. Als Input nimmt dieses Model einen Decoder und einen Encoder.  Der Autoencoder hat auch einen eigenen `forward` pass. Zunächst wird der Input durch den Encoder geschickt. Der Encoder gibt uns den hidden state `hidden` aus. Dieser Hidden State wird dann im einmalig im for loop für den Decoder verwendet. Auch nehmen wir die erste Reihe der `output_seq` als den ersten Input für den Decoder. Diese Reihe besteht aus den `<sos>` Tokens.\n",
    "\n",
    "Wir benutzen auch Teacher Forcing. Teacher Forcing wird im Training verwendet, damit es dem Decoder leichter fällt den kompletten Smiles wieder herzustellen. Schlägt der Decoder am Anfang eines Smiles schon den falschen Token vor, muss der Decoder mit diesem falschen Token als Input weite rechnen. Das kann gerade am Anfang das Training ein Problem sein, da hier noch viele Fehler gemacht werden. Das Teacher Forcing ersetzt zwischendurch die vorhergesagten Tokens mit korrekten Tokens. Somit kann der Decoder mit den richtigen Tokens weiter rechnen. Beim Evaluieren, wird das Teacher Forcing dann ausgeschaltet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c80c55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "        \n",
    "    def forward(self, input_seq, output_seq, teacher_forcing_ratio = 0.5):\n",
    "        \n",
    "        # speichern von Parametern\n",
    "        batch_size = output_seq.shape[1]\n",
    "        trg_len = output_seq.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size)\n",
    "        \n",
    "        \n",
    "        # Eigentlicher ForwardPass\n",
    "        \n",
    "        # Der Encoder berechnet den Hidden State/Latent Vector\n",
    "        hidden = self.encoder(input_seq)\n",
    "        \n",
    "        # Als initialen Input für den Decoder wählen wir die <sos> tokens aus\n",
    "        input = output_seq[0,:]\n",
    "        \n",
    "        # Der for-loop wird benutzt, um nacheinander die Tokens zu generieren.\n",
    "        for t in range(1, trg_len):\n",
    "\n",
    "            output, hidden = self.decoder(input, hidden)\n",
    "            outputs[t] = output\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "\n",
    "            top1 = output.argmax(1) \n",
    "\n",
    "            input = output_seq[t] if teacher_force else top1\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bf2808",
   "metadata": {},
   "source": [
    "Wie gegesagt, es ist okay wenn Sie in diesem Fall nicht alles verstehen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25b4c7b",
   "metadata": {},
   "source": [
    "Zunächst können wir unsere Model definieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34add64c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "enc = Encoder(len(dictionary), 128, 256, 0.2)\n",
    "dec = Decoder(len(dictionary),128,256,0.2)\n",
    "model = Autoencoder(enc, dec)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570433ac",
   "metadata": {},
   "source": [
    "Sie können deutlich die unterschiedlichen Einheiten des Autoencoders erkennen.\n",
    "Auch erstellen wir jetzt einen `DataLoader`. Dieser nimmt als $x$ und $y$ die selbe Sequenz, da wir ja einen Autoencoder trainieren wollen. Auch speichern wir einen Beispielbatch `ex_in` und `ex_out`.\n",
    "\n",
    "Da wir sowenig Daten haben, benutzen wir keinen Testdatensatz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5b32f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(tokenized_smiles, tokenized_smiles)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "ex_in= ex_out = tokenized_smiles[:16,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea60add1",
   "metadata": {},
   "source": [
    "Wir definieren unsere Optimizer und unsere Loss Funktion, hier können wir auch festhalten, dass der Index `2` ignoriert werden soll, bei der Berrechnung des Loss. Dieser ist nämlich der Index für den `<pad>` token. Und diese ist nicht wichtig für die Prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43e39a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf63c22",
   "metadata": {},
   "source": [
    "Als letztes kommt der Trainings Loop. An sich ein normaler Loop, allerdings benutzen wir den Transpose der `input_seq` und der `output_seq`. Da so die Funktionen der Netzwerke leichter in einander übergehen. Das Netzwerk ist auch schon gespeichert, dauert das Training zu lange können sie einfach das vortrainierte Netzwerk in der nächsten Zelle laden.  \n",
    "\n",
    "Im Trainings Loop selber wird alle 5 Epochs auch die Qualität der generierten Smiles evaluiert. Wie viele Smiles sind valide Smiles und wie viele Smiles sind identisch zum Input.\n",
    "\n",
    "Das wird von der Funktion `evaluate()` gemacht, die für Sie vorgeschrieben wurde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2fac53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for epoch in range(100):\n",
    "    epoch_loss = 0\n",
    "\n",
    "    model.train()\n",
    "    for input_seq, output_seq in train_loader:\n",
    "        optimizer.zero_grad()        \n",
    "        \n",
    "        input_seq = input_seq.t()\n",
    "        output_seq = output_seq.t()\n",
    "\n",
    "\n",
    "        output = model(input_seq, output_seq, 0.2)\n",
    "        \n",
    "        \n",
    "        output_dim = output.shape[-1]\n",
    "        output = output[1:].reshape(-1, output_dim)\n",
    "        output_seq =  output_seq[1:].reshape(-1)\n",
    "        \n",
    "        loss = criterion(output,  output_seq)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "    if (epoch%5==0):\n",
    "        valid, correct=evaluate(model, train_loader, dictionary)\n",
    "        print(f\"Epoch {epoch}: Loss: {epoch_loss /len(train_loader)} % Valid: {valid.round(2)} % Correct: {correct.round(2)} \")\n",
    "    else:\n",
    "        print(f\"Epoch {epoch}: Loss: {epoch_loss /len(train_loader)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1149d99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = Encoder(len(dictionary), 128, 256, 0.2)\n",
    "dec = Decoder(len(dictionary),128,256,0.2)\n",
    "model = Autoencoder(enc, dec)\n",
    "\n",
    "model.load_state_dict(torch.load(\"..\\data\\high_fidelity\\\\trained_model.pt\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9505c0",
   "metadata": {},
   "source": [
    "Jetzt können wir schauen, wie gut unser Model wirklich ist. Denn während des Trainings benutzen wir Teacher Forcing. Das wird während der Evaluierung ausgeschaltet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e4a117",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model,train_loader, dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bbac836",
   "metadata": {},
   "source": [
    "83% die unser Autoencoder generiert sind tatsächlich valide Smiles. 69% der generierten Smiles sind auch tatsächlich identisch zu den Inputsmiles.\n",
    "\n",
    "Autoencoder sind schwierig zu trainieren, besonders für Sprachen oder auch SMILES. Die Grammatik von SMILES muss erst erlernt werden. Dafür brauch es eigentlich viel mehr Daten. Darüber hinaus, benutzen wir ein sehr simples Model. Trotzdem können wir und das Netzwerk ein wenig genauer anschauen.\n",
    "\n",
    "Wir können uns zum Beispiel die Vorhersagen für unseren `ex_in` Batch anschauen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a886c48",
   "metadata": {},
   "source": [
    "Wir lassen uns die vorhergesagten Token für die ersten beide Smiles im Batch aus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc0f177",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "pred = model(ex_in.t(), ex_out.t(), 0)\n",
    "pred_tokens =pred.argmax(2).t().detach().numpy()\n",
    "\n",
    "pred_tokens[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577bb038",
   "metadata": {},
   "source": [
    "Im Vergleich dazu sind die orignalen Daten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636e9923",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ex_out[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6c3c8d",
   "metadata": {},
   "source": [
    "Die Funktion `token_to_smiles` konvertiert die Tokens wieder zurück in Smiles:\n",
    "So sehen die vorhergesagten Smiles aus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ad4972",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_smiles = tokens_to_smiles(pred_tokens,dictionary )\n",
    "true_smiles = tokens_to_smiles(ex_out.detach().numpy(), dictionary)\n",
    "pd.DataFrame({\"true\":true_smiles, \"pred\": pred_smiles })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57084ab4",
   "metadata": {},
   "source": [
    "Tatsächlich sind die meisten SMILES identisch zu dem originalen. Aber es gibt auch abweichende Smiles. Der Smiles mit dem Index 8 ist nicht identisch und ist noch nicht einmal ein valider Smiles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6f44c8",
   "metadata": {},
   "source": [
    "# Neue Molkeüle generieren\n",
    "\n",
    "Wir haben einen Decoder der aus unseren Hidden States bzw. Latent Vector valide Moleküle generieren kann. Bis jetzt erhalten wir die latent Vectors in dem wir bekannte SMILES durch den Encoder schicken. Was hält uns aber davon ab, zufällige Latent Vectoren zu generieren und zu gucken, was der Decoder daraus macht? Unsere Hidden States/Latent Vectors haben diese Größe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b06875a",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_vectors =  model.encoder(ex_in.t()).detach().numpy()\n",
    "latent_vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5694f87f",
   "metadata": {},
   "source": [
    "Wir können einfach einen alternativen Latent Vector Tensor erstellen. Diesen füllen wir mit zufälligen Zahlen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a22313a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(5489786)\n",
    "hidden = torch.randn(1,16,256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537374c5",
   "metadata": {},
   "source": [
    "Diesen benutzen wir an Stelle der ursprünglichen latenten Vectoren, als Input für den Decoder.\n",
    "Dieser sollte jetzt probieren aus diesen zufälligen Daten neue Smiles zu generieren. Da der Hidden State zufällig gewählt worden ist, sollten es Moleküle sein, die bis jetzt noch nicht in unsrem Datensatz sind. So könnte De-novo Design funktionieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e12797e",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = torch.zeros(26, 16, len(dictionary))\n",
    "input_ = ex_out.t()[0,:] #<- [\"<sos>\"] Tokens\n",
    "for t in range(1, 26):\n",
    "    output, hidden = model.decoder(input_, hidden)\n",
    "    outputs[t] = output\n",
    "    input_ = output.argmax(1) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c9168b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_tokens = outputs.argmax(2).t().detach().numpy()\n",
    "new_smiles = tokens_to_smiles(pred_tokens, dictionary)\n",
    "new_smiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe78e16",
   "metadata": {},
   "source": [
    "Tatsächlich ist keines diese Moleküle in unsrem Datensatz, weil es als keine validen Moleküle sind. Außer `\"Cl\"`.\n",
    "Das Problem ist vor allem, dass der Latent Space, also der Raum der insgesamt von unserem Laten Vectoren beschrieben werden kann, viel zu groß ist. Es wird sehr schwierig sein durch Zufall Zahlen zu finden, die ein valides Moleküle erzeugen.\n",
    "\n",
    "Um wirklich effektiv Moleküle durch Autoencoder zu generieren, brauchen wir deutlich mehr Daten. So kann die Grammatik von Smiles besser gelernt werden. Zweitens werden meisten sogenannte Variational Autoencoder (VAE) benutzt. Diese \"zwingen\" die latent Vectoren in fest definierte Größe. Wählt man dann zufällige Zahlen, die den selben definierten Größen entsprechen ist die Wahrscheinlichkeit höher, dass es ein valides Molekül ist."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca00569",
   "metadata": {},
   "source": [
    "# Übungsaufgabe\n",
    "\n",
    "In der heutigen Übungsaufgabe soll es nicht, um Autoencoder gehen. Sondern die Aufgabe besteht darin ein `nn.Sequential` Model in einer funktionieren PyTorch Klasse umzuschreiben.\n",
    "\n",
    "Das Model sieht wie folgt aus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bb4370",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_1 =nn.Sequential(nn.Linear(20,100),\n",
    "              nn.BatchNorm1d(100),\n",
    "              nn.ReLU(),\n",
    "              nn.Dropout(0.2),\n",
    "              nn.Linear(100,100),\n",
    "              nn.BatchNorm1d(100),\n",
    "              nn.ReLU(),\n",
    "              nn.Linear(100,10))\n",
    "model_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10514f78",
   "metadata": {},
   "source": [
    "Schreiben Sie das Model um. Beachten Sie, dass `nn.ReLU` nicht im `forward` funktioniert. Hier bitte `nn.functional.relu()` verwenden. Auch ist wichtig zu wissen, dass `__init__` so viele Input-Parameter haben kann wie es mag, sie können zum Beispiel\n",
    "`__init__(self, input_dim, hid1_dim, hid2_dim, ________)` nutzen um mehrere hidden Layers zu initialisieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed85fe6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class simple_nn(________):\n",
    "    def __init__(self, ___________________________________________):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e156b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = simple_nn(______________________________)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec9b50d",
   "metadata": {},
   "source": [
    "Testen Sie, ob ihr Model einen Output generiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775626b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(213)\n",
    "test_data = torch.randn(100,20)\n",
    "\n",
    "model_2(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c039484",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
