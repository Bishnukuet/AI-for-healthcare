{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb6c2e50",
   "metadata": {},
   "source": [
    "# Ein Überblick\n",
    "\n",
    "---\n",
    "Lernziel\n",
    "\n",
    "- Der Zusammenhang von (logistischer Regression) und Neuronalen Netzwerken\n",
    "---\n",
    "\n",
    "Im letzten Notebook werden wir uns noch ein letztes Mal mit verschieden Netzwerk-Architekturen auseinandersetzen und wie diese zusammen hängen.\n",
    "\n",
    "Dafür werden wir noch einmal mit dem MNIST Datensatz arbeiten. Zunächst laden wir wieder die Daten und normalisieren diese. Wir kodieren die Target-Variable auch wieder zu One-Hot Vektoren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8ace8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "def min_max(x):\n",
    "    return (x - np.min(x)) / (np.max(x) - np.min(x))\n",
    "def one_hot(x):\n",
    "    \"\"\"Die Labels der Bilder müssen noch in Vektoren von Länge 10 codiert werden\"\"\"\n",
    "    dod = len(set(x)) # Checkt wie viele verschieden Ziffern es im Datennsatz gibt\n",
    "    target = np.zeros([x.shape[0], dod]) # Eine Matrix aus Nullen wird erstellt\n",
    "    for i in range(x.shape[0]): # Der for-loop setzt eine 1 in die Matrix abhängig davon welches Label das Bild hat\n",
    "        target[i, x[i]] = 1\n",
    "\n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81def756",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.genfromtxt('../data/mnist/mnist_train.csv', delimiter=',', skip_header =False) #genfromtxt liest .txt Datein, mit delimiter =\",\" können auch .csv (comma seperated values) Datein einglesen werden  \n",
    "test_data=np.genfromtxt('../data/mnist/mnist_test.csv', delimiter=',', skip_header =False) # hier lesen wir die Test Daten ein\n",
    "\n",
    "train_labels=train_data[:,0].astype(int) \n",
    "train_images = train_data[:,1:]\n",
    "\n",
    "test_labels=test_data[:,0].astype(int)\n",
    "test_images = test_data[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e041a17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_targets=one_hot(train_labels)\n",
    "test_targets = one_hot(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2935155f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = min_max(train_images)\n",
    "test_images = min_max(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc937fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(train_images[0].reshape([28, 28]), cmap=\"gray\")\n",
    "print(\"Correct Label: %s\" % train_labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e54a43",
   "metadata": {},
   "source": [
    "# Lineare Regression\n",
    "\n",
    "Wir beginnen mit einer simplen Regression. Eine lineare Regression kann man auch als neuronales Netzwerk darstellen.\n",
    "\n",
    "<img src=\"Img/summary/lin_reg.png\" width =\"450px\">\n",
    "\n",
    "Der Output setzt sich aus der gewichteten Summe der Pixelwerte zusammen. Das heißt, jedem Pixel ist ein Gewicht zugeordnet. *Das Neuron kann auch noch ein Bias haben, diese ist aber nicht dargestellt*. \n",
    "\n",
    "Da wir nur ein Output Neuron haben, können wir auch nur eine Predicition. Das bedeutet wir können  nur eine binäre Klassifizierung machen. Zum Beispiel: Ist auf dem Bild eine Fünf zu sehen oder nicht?\n",
    "\n",
    "Wir können  diese lineare Regression auch in Python durchführen.\n",
    "Dafür benutzen wir die `train_images` als Input und die Spalte der `train_targets`. In dem Fall ist das die fünfte Spalte `train_targets[:,5]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97faed1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "linear_reg_model = LinearRegression()\n",
    "linear_reg_model.fit(train_images, train_targets[:,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd898602",
   "metadata": {},
   "source": [
    "Wir können uns die Gewichte mit `linear_reg_model.coef_` ausgeben lassen. Insgesamt gibt es 784 Gewichte, für jeden Pixel einen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed115ac2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "linear_reg_model.coef_[:5], linear_reg_model.coef_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a832de9",
   "metadata": {},
   "source": [
    "Um zu schauen, wie gut unsere Model funktioniert, können  wir die `.predict()` Funktion benutzen, um die Wert für unseren Test Datensatz vorherzusagen. Denken Sie daran, dass wir nur Nullen oder Einsen vorhersagen wollen.\n",
    "\n",
    "`1` = \"Fünf\"\n",
    "\n",
    "`0` = \"Keine Fünf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37e6db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = linear_reg_model.predict(test_images)\n",
    "pred_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d851eb70",
   "metadata": {},
   "source": [
    "Diese Werte sind weder `0` noch `1`. Wir müssen diese erst noch runden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303b62c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_y = np.round(pred_y)\n",
    "pred_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e2aab8",
   "metadata": {},
   "source": [
    "Jetzt können wir auch die Accuracy berrechen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a94f265",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(pred_y== test_targets[:,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818d6b9d",
   "metadata": {},
   "source": [
    "`0.9456` ist gar nicht so schlecht. Denken Sie aber daran, dass nur ungefähr 10% der Bilder eine `5` zeigen. Das heißt, auch das 90% der Bilder keine `5` zeigen. Für diese 90% Prozent müsste unere Model eine `0` vorhersagen, um Korekkt zu sein. Wenn das Modell einfach für alle Bilder eine `0` vorhersagt, würde es auch schon auf eine Accuracy von `0.90` kommen. Dementsprechened ist unsere Accuracy vielleicht weniger spektakulär als angenommen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbe7450",
   "metadata": {},
   "source": [
    "Aber ein Problem haben wir noch.Schaeun Sie sich einmal die Vorhersagen für `pred_y[1677]` oder `pred_y[1162]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6ae3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y[1677],pred_y[1162]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8340240b",
   "metadata": {},
   "source": [
    "Diese Werte sind weder `1` noch `0`. Wie konnte das passieren?\n",
    "In einer linearen Regression benutzen wir keine Aktivierungsfunktionen. Deswegen kann der Output einer linearen Regression unbegrenzte Werte annehmen. Wenn die Werte außerhalb von `[-1.5, 1.5]` fallen, werden Sie nicht mehr auf die richtigen Werte gerundet.\n",
    "\n",
    "Das ist erstmal kein Problem,  wir könnten diesen Werten auch manuell `0`en oder `1`en zuordnen. Aber das Problem, bleibt im Grundsatz bestehen: Wri erlauben es dem Modell Werte Vorherzusagen, die außerhalb des möglichen Bereichs liegen. \n",
    "\n",
    "Eine `sigmoid` Funktion verhindert das. Sie transformierte alle Werte in eine Weise, dass Sie dannach zwischen 0 und 1 liegen. Wir können also einfach an die lineare Regression eine `sigmoid` Funktioon \"hängen\". So würde das Problem gelöst werden. Und genau das passiert bei der logistischen Regression.\n",
    "\n",
    "<img src=\"Img/summary/log_reg.png\" width=\"450px\">\n",
    "\n",
    "Auch diese können wir in Python berechnen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4a8784",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_model = LogisticRegression(solver = 'lbfgs', max_iter=1000,  random_state=134)\n",
    "log_reg_model.fit(train_images, train_targets[:,5])\n",
    "log_reg_model.coef_[0,256:261], log_reg_model.coef_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbceea4",
   "metadata": {},
   "source": [
    "Wir erhalten wieder `784` Gewichte. Für jeden Pixel eins. Wir sehene auch, dass unsere Vorhersagen für den Testdatensatz jetzt schon gerundet werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f174864c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = log_reg_model.predict(test_images)\n",
    "pred_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85190e3d",
   "metadata": {},
   "source": [
    "Auch hier berechnen wir wieder die Accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07aa814",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(pred_y == test_targets[:,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c328659d",
   "metadata": {},
   "source": [
    "Durch das Benutzen einer logistischen Regression konnten wir also die Accuracy steigern. Doch bisher unterscheiden wir nur \"Fünf\" vs. \"keine Fünf\". Wir wollen aber eigentlich jede Ziffer erkennen können. Auch das geht mit der logistischen Regression.\n",
    "\n",
    "Das heißt wir haben mehrere Outputs Nodes. Insgesamt 10 für jede Prediciton eine. \n",
    "\n",
    "<img src=\"Img/summary/log_reg_2.png\" width=\"540px\">\n",
    "\n",
    "Es wird jetzt die `softmax` Funktion  benutzt. Anders als die `sigmoid` Funktion stellt, die `softmax` Funktion sicher, dass die Summe der Activations über die 10 Outputs nicht größere als `1` wird. Würden wir die `sigmoid` Funktion benutzten, könnte es passieren, dass ein Bild als eine fünf und eine eins erkannt wird. \n",
    "\n",
    "\n",
    "Für diese logistische Regression müssen wir jetzt die komplette `train_labels` Matrix hinzufügen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c3aa69",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_model_alle = LogisticRegression(solver = 'lbfgs', max_iter=1000,  random_state=134)\n",
    "log_reg_model_alle.fit(train_images, train_labels)\n",
    "log_reg_model_alle.coef_[0,256:261], log_reg_model_alle.coef_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7152f511",
   "metadata": {},
   "source": [
    "Die Weightmatrix `log_reg_model_alle.coef_` hat nun die Größe `[10,784]`. Also pro Outputneuron 784 Weights.\n",
    "\n",
    "Auch jetzt erhalten wir Vorhersagen, diese enthält die vom Model erkannte Zahl. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5432398e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_y = log_reg_model_alle.predict(test_images)\n",
    "pred_y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d15d07b",
   "metadata": {},
   "source": [
    "Wir berechnen erneut die Accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628ce0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(pred_y==test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84c600a",
   "metadata": {},
   "source": [
    "92,5 % der Ziffer kann dieses Model richtig erkennen. Natürlich schlechter als vorher, aber diesmal ist die Aufgabe viel komplexer, denn es geht nicht nur um eine Ziffer, sondern es gilt alle Zahlen richtig zu erkennen. \n",
    "Mit einer einfachen logistischen Regression können wir also eine relativ gute Genauigkeit erreichen. \n",
    "\n",
    "Wofür brauchen wir dann noch neuronale Netzwerke? Diese können uns auch die letzten Prozentpunkte in Performance bringen. Der Unterschied zu unserem jetzigen Model und einem neuronalen Netzwerk ist das Fehlen der Hidden Layer. \n",
    "\n",
    "<img src=\"Img/summary/nn1.png\" width=\"450px\">\n",
    "\n",
    "Auch das werden wir mit PyTorch nachbauen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514cd1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_images =torch.tensor(train_images, dtype = torch.float32)\n",
    "test_images =torch.tensor(test_images, dtype = torch.float32)\n",
    "\n",
    "train_labels =torch.tensor(train_labels, dtype = torch.long)\n",
    "test_labels =torch.tensor(test_labels, dtype = torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404a7ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_nn = nn.Sequential(nn.Linear(784,10),nn.ReLU() ,nn.Linear(10,10))\n",
    "loss_funktion = nn.CrossEntropyLoss()\n",
    "updater = optim.Adam(simple_nn.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b6d3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1234)\n",
    "for epoch in range(135):\n",
    "    updater.zero_grad()\n",
    "    output = simple_nn(train_images)\n",
    "    loss = loss_funktion(output, train_labels)\n",
    "    loss.backward()\n",
    "    updater.step()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cae5cfb",
   "metadata": {},
   "source": [
    "Der Code sollte Ihnen mittlerweile bekannt sein. Wenn wir uns die Accuracy anschauen sehen wir aber, dass das neuronale Netzwerk eine Accuracy hat, die vergleichbar zur Accuracy der logistische Regression ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b00c8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y=torch.argmax(simple_nn(test_images),1).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e5c07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(pred_y==test_labels.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c48b226",
   "metadata": {},
   "source": [
    "Das kann mehrere Gründe haben. Grundsätzlich müssen neuronale Netzwerke nicht besser funktionieren als einfachere Modelle.\n",
    "In dem Fall liegt es aber wahrscheinlich an unserem Modell selber. Wir können mehr oder größere Layers benutzen. Wir können den Optimizer ändern oder auch die Lernrate.\n",
    "\n",
    "\n",
    "# Übungsaufgabe\n",
    "\n",
    "Das heute Notebook ist kürzer als sonst, somit haben Sie mehr Zeit für die Übungsaufgabe. \n",
    "In der heutigen Übungsaufgabe geht es darum, das gelernte in noch einmal auf den MNIST Datensatz anzuwenden. \n",
    "\n",
    "Sie erhalten drei Datensätze (durchmischt):\n",
    "\n",
    "- Trainingsdaten: benutzen Sie zum Trainieren\n",
    "- Testdaten: benutzen Sie, um  das trainierte Netzwerk zu evaluieren\n",
    "- Externer Testdatensatz: Nur Bilder, kein Label → Sie schicken mir die Predictions für diesen Datensatz.\n",
    "\n",
    "Der Externe Datensatz hat keine Lösungen (zumindest keine, die Sie einsehen können). \n",
    "Mit der Übungsaufgabe geben Sie auch **Ihre** Vorhersagen für den Externen Datensatz.\n",
    "\n",
    "Wir werden dann Ihre Prediction mit den wahren Werten vergleichen. \n",
    "*Wer von Ihnen erstellt das beste Modell?*\n",
    "\n",
    "Einen Anfangsmodell wurde vorgeschrieben.\n",
    "Sie können von da aus anfangen ihr Netzwerk zu verbessern.\n",
    "\n",
    "Sie haben verschiedene Möglichkeiten ihr Netzwerk besser zu machen:\n",
    "Hier  ein paar Beispiele.\n",
    "- Hyperparameter anpassen z.B. Anzahl Epoch, Batchgröße, Learning Rate oder Anzahl der Hidden Layers\n",
    "- Batchnorm und Dropout\n",
    "- CNN\n",
    "- Optimzer\n",
    "\n",
    "Passen Sie darauf auf, dass Sie nicht auf den Testdatensatz overfitten. Auch das kann passieren.\n",
    "\n",
    "Am Ende des Codes ist eine Zelle, mit der Sie die Prediction für den Testdatensatz erstellen und speichern können. \n",
    "Dieser wird im Ordner `data` als `meine_prediction.csv` gespeichert.\n",
    "\n",
    "Bitte reichen Sie sowohl ihre Prediction als auch das Notebook.\n",
    "\n",
    "# Daten \n",
    "\n",
    "Laden Sie zunächst alle Daten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc2eec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils import data\n",
    "import pandas as pd\n",
    "\n",
    "def min_max(x):\n",
    "    return (x - 0.) / (255. - 0.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cecd01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.genfromtxt('../data/mnist/mnist_train.csv', delimiter=',', skip_header =False) #genfromtxt liest .txt Datein, mit delimiter =\",\" können auch .csv (comma seperated values) Datein einglesen werden  \n",
    "\n",
    "train_labels=train_data[:,0].astype(int) \n",
    "train_images = min_max(train_data[:,1:])\n",
    "del train_data \n",
    "\n",
    "test_data=np.genfromtxt('../data/mnist/mnist_test.csv', delimiter=',', skip_header =False) # hier lesen wir die Test Daten ein\n",
    "test_labels=test_data[:,0].astype(int)\n",
    "test_images = min_max(test_data[:,1:])\n",
    "\n",
    "del test_data \n",
    "external_images=min_max(np.genfromtxt('../data/mnist/external.csv', delimiter=',', skip_header =False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b4079d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images =torch.tensor(train_images, dtype = torch.float32)\n",
    "test_images =torch.tensor(test_images, dtype = torch.float32)\n",
    "\n",
    "train_labels =torch.tensor(train_labels, dtype = torch.long)\n",
    "test_labels =torch.tensor(test_labels, dtype = torch.long)\n",
    "\n",
    "external_images = torch.tensor(external_images, dtype = torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49e5d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=data.TensorDataset(train_images, train_labels) # input sind unsere Tensors die einmal die Bilder und einmal die Labels beinhalten\n",
    "loader = data.DataLoader(train_data, batch_size = 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc0c6e8",
   "metadata": {},
   "source": [
    "##  Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3179f953",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_nn = nn.Sequential(nn.Linear(784,10),nn.ReLU() ,nn.Linear(10,10))\n",
    "loss_funktion = nn.CrossEntropyLoss()\n",
    "updater = optim.Adam(simple_nn.parameters(), lr = 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ffd5fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(1234)\n",
    "for epoch in range(20):\n",
    "    simple_nn.train()\n",
    "    for images, labels in loader:\n",
    "        updater.zero_grad()\n",
    "        output = simple_nn(images)\n",
    "        loss = loss_funktion(output, labels)\n",
    "        loss.backward()\n",
    "        updater.step()\n",
    "    \n",
    "    simple_nn.eval()\n",
    "    # EVALUATE #\n",
    "    # Train\n",
    "    output = simple_nn(train_images)\n",
    "    loss = loss_funktion(output, train_labels)\n",
    "    prediction = torch.argmax(output,1).detach().numpy()\n",
    "    acc  = np.mean(prediction == train_labels.detach().numpy()  )\n",
    "    # Tets\n",
    "    output = simple_nn(test_images)\n",
    "    test_loss = loss_funktion(output, test_labels)\n",
    "    prediction = torch.argmax(output,1).detach().numpy()\n",
    "    test_acc  = np.mean(prediction == test_labels.detach().numpy()  )\n",
    "    print(f\"Epoch {epoch} | Trainings Loss: {loss:.3f} Training Acc: {acc:.3f} | Test Loss: {test_loss:.3f} Test Acc:  {test_acc:.3f}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3baff30",
   "metadata": {},
   "source": [
    "# Externe Daten "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d391273",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_nn.eval()\n",
    "externe_pred = torch.argmax(simple_nn(external_images),1).detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8261ba",
   "metadata": {},
   "source": [
    "Die nächste Zelle generiert eine `.csv` Datein mit euren Vorhersagen. Diese reicht Ihr bitte mit dem Notebook ein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f8fe2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(externe_pred.reshape(10000,1)).to_csv(\"../data/meine_prediction.csv\", index =False,header =False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
